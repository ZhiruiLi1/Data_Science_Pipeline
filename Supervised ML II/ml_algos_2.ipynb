{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudcard\n",
    "- **why is only the second column of predict_proba being used to find the best critical probability?**\n",
    "    - You can use either column but be careful of how you convert the critical probability to a predicted class\n",
    "    - If you use the first column, that's class 0 predicted probability. If it is larger than 50%, you need to predict class 0.\n",
    "    - If you use the second column, that's class 1 predicted probability. If it is larger than 50%, you need to predcit class 1.\n",
    "- **For decision trees and random forest, will we need to do the steps that we did during the quiz? Or is that what python will do for us?**\n",
    "    - slearn optimizes the decision tree for you and it also aggregates the votes of trees if you use a random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Supervised ML algorithms\n",
    "By the end of this week, you will be able to\n",
    "- Summarize how decision trees, random forests, and support vector machines work\n",
    "- Describe how the predictions of these techniques behave in classification and regression\n",
    "- Describe which hyper-parameters should be tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A decision tree in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(10)\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "X = np.random.rand(n_samples)\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_new = np.linspace(0, 1, 1000)\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=1,max_depth=1)\n",
    "reg.fit(X[:, np.newaxis],y)\n",
    "y_new = reg.predict(X_new[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  For a comparison between tree-based ensemble models see the example\n",
      " |  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"},             default=\"squared_error\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"squared_error\" for the mean squared error, which is equal to\n",
      " |      variance reduction as feature selection criterion and minimizes the L2\n",
      " |      loss using the mean of each terminal node, \"friedman_mse\", which uses\n",
      " |      mean squared error with Friedman's improvement score for potential\n",
      " |      splits, \"absolute_error\" for the mean absolute error, which minimizes\n",
      " |      the L1 loss using the median of each terminal node, and \"poisson\" which\n",
      " |      uses reduction in Poisson deviance to find splits.\n",
      " |      Training using \"absolute_error\" is significantly slower\n",
      " |      than when using \"squared_error\".\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |         Poisson criterion.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=1.0\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None or 1.0, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. note::\n",
      " |          The default of 1.0 is equivalent to bagged trees and more\n",
      " |          randomness can be achieved by setting smaller values, e.g. 0.3.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to 1.0.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool or callable, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      By default, :func:`~sklearn.metrics.r2_score` is used.\n",
      " |      Provide a callable with signature `metric(y_true, y_pred)` to use a\n",
      " |      custom metric. Only available if `bootstrap=True`.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.DecisionTreeRegressor`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      " |  sklearn.ensemble.ExtraTreesRegressor : Ensemble of extremely randomized\n",
      " |      tree regressors.\n",
      " |  sklearn.ensemble.HistGradientBoostingRegressor : A Histogram-based Gradient\n",
      " |      Boosting Regression Tree, very fast for big datasets (n_samples >=\n",
      " |      10_000).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=1.0`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._forest.RandomForestRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestRegressor\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._forest.RandomForestRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestRegressor\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aa5e437c91421c9f8975c5dc9c3743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='n_estimators', options=(1, 3, 10, 30), value=1), SelectionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "# HUGE thanks to Drew Solomon and Yifei Song (DSI alumni) \n",
    "# for preparing the visualizations in this lecture!\n",
    "#############################################################\n",
    "# check out helper_functions.ipynb for more details\n",
    "%run ./helper_functions.ipynb\n",
    "\n",
    "\n",
    "# x < 0.35\n",
    "# yes: y = 0.7\n",
    "# no: y = -0.75\n",
    "hyperparameters = {\n",
    "    'n_estimators': [1, 3, 10, 30],\n",
    "    'max_depth': [1, 2, 3, 10, 30]\n",
    "}\n",
    "\n",
    "vis(X, y, RandomForestRegressor, hyperparameters, X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to avoid overfitting with random forests?\n",
    "- tune some (or all) of following hyperparameters:\n",
    "   - max_depth\n",
    "   - max_features\n",
    "- With sklearn random forests, **do not tune n_estimators**!\n",
    "   - the larger this value is, the better the forest will be\n",
    "   - set n_estimators to maybe 100 while tuning hyperparameters\n",
    "   - increase it if necessary once the best hyperparameters are found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|<font color='red'>so so</font> |<font color='red'>constant</font>|<font color='red'>yes</font>|<font color='red'>max_features,  max_depth</font>| <font color='red'>no</font>|<font color='red'>so so</font>|\n",
    "| random forest classification \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|\n",
    "| SVM rbf regression               \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|\n",
    "| SVM rbf classification           \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A random forest in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, n_estimators=1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, n_estimators=1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, n_estimators=1, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# create the data\n",
    "X,y = make_moons(noise=0.2, random_state=1,n_samples=200)\n",
    "# set the hyperparameters\n",
    "clf = RandomForestClassifier(n_estimators=1,max_depth=3,random_state=0)\n",
    "# fit the model\n",
    "clf.fit(X,y)\n",
    "# predict new data\n",
    "#y_new = clf.predict(X_new)\n",
    "# predict probabilities\n",
    "#y_new = clf.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  For a comparison between tree-based ensemble models see the example\n",
      " |  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      " |      Note: This parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool or callable, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      By default, :func:`~sklearn.metrics.accuracy_score` is used.\n",
      " |      Provide a callable with signature `metric(y_true, y_pred)` to use a\n",
      " |      custom metric. Only available if `bootstrap=True`.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : DecisionTreeClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      " |  sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
      " |      tree classifiers.\n",
      " |  sklearn.ensemble.HistGradientBoostingClassifier : A Histogram-based Gradient\n",
      " |      Boosting Classification Tree, very fast for big datasets (n_samples >=\n",
      " |      10_000).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(...)\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._forest.RandomForestClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestClassifier\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._forest.RandomForestClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestClassifier\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2caab2f45544415a271ac4df7c6ad6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='n_estimators', options=(1, 3, 10, 30), value=1), SelectionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce943fb021fe44e98f4997a91f3f9e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorbar': {'title': {'text': 'predicted probability'}},\n",
       "              'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n",
       "                             [0.2, 'rgb(214,96,77)'], [0.3, 'rgb(244,165,130)'],\n",
       "                             [0.4, 'rgb(253,219,199)'], [0.5, 'rgb(247,247,247)'],\n",
       "                             [0.6, 'rgb(209,229,240)'], [0.7, 'rgb(146,197,222)'],\n",
       "                             [0.8, 'rgb(67,147,195)'], [0.9, 'rgb(33,102,172)'],\n",
       "                             [1.0, 'rgb(5,48,97)']],\n",
       "              'contours': {'end': 1, 'size': 0.05, 'start': 0},\n",
       "              'type': 'contour',\n",
       "              'uid': '07ed00ef-7799-45ed-ad7e-603e4027844f',\n",
       "              'x': array([-1.64483117, -1.62483117, -1.60483117, ...,  2.75516883,  2.77516883,\n",
       "                           2.79516883]),\n",
       "              'y': array([-1.44154690e+00, -1.42154690e+00, -1.40154690e+00, -1.38154690e+00,\n",
       "                          -1.36154690e+00, -1.34154690e+00, -1.32154690e+00, -1.30154690e+00,\n",
       "                          -1.28154690e+00, -1.26154690e+00, -1.24154690e+00, -1.22154690e+00,\n",
       "                          -1.20154690e+00, -1.18154690e+00, -1.16154690e+00, -1.14154690e+00,\n",
       "                          -1.12154690e+00, -1.10154690e+00, -1.08154690e+00, -1.06154690e+00,\n",
       "                          -1.04154690e+00, -1.02154690e+00, -1.00154690e+00, -9.81546901e-01,\n",
       "                          -9.61546901e-01, -9.41546901e-01, -9.21546901e-01, -9.01546901e-01,\n",
       "                          -8.81546901e-01, -8.61546901e-01, -8.41546901e-01, -8.21546901e-01,\n",
       "                          -8.01546901e-01, -7.81546901e-01, -7.61546901e-01, -7.41546901e-01,\n",
       "                          -7.21546901e-01, -7.01546901e-01, -6.81546901e-01, -6.61546901e-01,\n",
       "                          -6.41546901e-01, -6.21546901e-01, -6.01546901e-01, -5.81546901e-01,\n",
       "                          -5.61546901e-01, -5.41546901e-01, -5.21546901e-01, -5.01546901e-01,\n",
       "                          -4.81546901e-01, -4.61546901e-01, -4.41546901e-01, -4.21546901e-01,\n",
       "                          -4.01546901e-01, -3.81546901e-01, -3.61546901e-01, -3.41546901e-01,\n",
       "                          -3.21546901e-01, -3.01546901e-01, -2.81546901e-01, -2.61546901e-01,\n",
       "                          -2.41546901e-01, -2.21546901e-01, -2.01546901e-01, -1.81546901e-01,\n",
       "                          -1.61546901e-01, -1.41546901e-01, -1.21546901e-01, -1.01546901e-01,\n",
       "                          -8.15469010e-02, -6.15469010e-02, -4.15469010e-02, -2.15469010e-02,\n",
       "                          -1.54690100e-03,  1.84530990e-02,  3.84530990e-02,  5.84530990e-02,\n",
       "                           7.84530990e-02,  9.84530990e-02,  1.18453099e-01,  1.38453099e-01,\n",
       "                           1.58453099e-01,  1.78453099e-01,  1.98453099e-01,  2.18453099e-01,\n",
       "                           2.38453099e-01,  2.58453099e-01,  2.78453099e-01,  2.98453099e-01,\n",
       "                           3.18453099e-01,  3.38453099e-01,  3.58453099e-01,  3.78453099e-01,\n",
       "                           3.98453099e-01,  4.18453099e-01,  4.38453099e-01,  4.58453099e-01,\n",
       "                           4.78453099e-01,  4.98453099e-01,  5.18453099e-01,  5.38453099e-01,\n",
       "                           5.58453099e-01,  5.78453099e-01,  5.98453099e-01,  6.18453099e-01,\n",
       "                           6.38453099e-01,  6.58453099e-01,  6.78453099e-01,  6.98453099e-01,\n",
       "                           7.18453099e-01,  7.38453099e-01,  7.58453099e-01,  7.78453099e-01,\n",
       "                           7.98453099e-01,  8.18453099e-01,  8.38453099e-01,  8.58453099e-01,\n",
       "                           8.78453099e-01,  8.98453099e-01,  9.18453099e-01,  9.38453099e-01,\n",
       "                           9.58453099e-01,  9.78453099e-01,  9.98453099e-01,  1.01845310e+00,\n",
       "                           1.03845310e+00,  1.05845310e+00,  1.07845310e+00,  1.09845310e+00,\n",
       "                           1.11845310e+00,  1.13845310e+00,  1.15845310e+00,  1.17845310e+00,\n",
       "                           1.19845310e+00,  1.21845310e+00,  1.23845310e+00,  1.25845310e+00,\n",
       "                           1.27845310e+00,  1.29845310e+00,  1.31845310e+00,  1.33845310e+00,\n",
       "                           1.35845310e+00,  1.37845310e+00,  1.39845310e+00,  1.41845310e+00,\n",
       "                           1.43845310e+00,  1.45845310e+00,  1.47845310e+00,  1.49845310e+00,\n",
       "                           1.51845310e+00,  1.53845310e+00,  1.55845310e+00,  1.57845310e+00,\n",
       "                           1.59845310e+00,  1.61845310e+00,  1.63845310e+00,  1.65845310e+00,\n",
       "                           1.67845310e+00,  1.69845310e+00,  1.71845310e+00,  1.73845310e+00,\n",
       "                           1.75845310e+00,  1.77845310e+00,  1.79845310e+00,  1.81845310e+00,\n",
       "                           1.83845310e+00,  1.85845310e+00,  1.87845310e+00]),\n",
       "              'z': array([[0.86597938, 0.86597938, 0.86597938, ..., 0.86597938, 0.86597938,\n",
       "                           0.86597938],\n",
       "                          [0.86597938, 0.86597938, 0.86597938, ..., 0.86597938, 0.86597938,\n",
       "                           0.86597938],\n",
       "                          [0.86597938, 0.86597938, 0.86597938, ..., 0.86597938, 0.86597938,\n",
       "                           0.86597938],\n",
       "                          ...,\n",
       "                          [0.16504854, 0.16504854, 0.16504854, ..., 0.16504854, 0.16504854,\n",
       "                           0.16504854],\n",
       "                          [0.16504854, 0.16504854, 0.16504854, ..., 0.16504854, 0.16504854,\n",
       "                           0.16504854],\n",
       "                          [0.16504854, 0.16504854, 0.16504854, ..., 0.16504854, 0.16504854,\n",
       "                           0.16504854]])},\n",
       "             {'marker': {'color': array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "                                         0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "                                         1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "                                         1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "                                         1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "                                         0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "                                         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "                                         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "                                         1, 1, 0, 1, 1, 0, 1, 0]),\n",
       "                         'colorscale': [[0, 'rgb(255,0,0)'], [1, 'rgb(0,0,255)']],\n",
       "                         'line': {'width': 1},\n",
       "                         'size': 8},\n",
       "              'mode': 'markers',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c14b4b5f-c778-44f8-9a1a-077a7f03388c',\n",
       "              'x': array([-0.31410929,  0.39443922,  0.48606504, -0.12805768,  1.73330291,\n",
       "                           2.08500896, -1.08258853,  1.46899598,  0.54077095,  2.04624573,\n",
       "                           1.26754011,  0.84766004,  1.12118285, -0.78670168,  0.00903277,\n",
       "                           0.44164301,  1.43162307,  0.42529121,  0.47635606, -0.21866384,\n",
       "                          -0.08003084,  0.89546191,  0.22021464, -0.86869386,  0.720033  ,\n",
       "                           1.13779598,  0.8517701 ,  0.78598197,  1.9446092 ,  0.57102512,\n",
       "                          -0.0874615 ,  1.36354658,  2.01180011,  1.74821345,  2.02576178,\n",
       "                          -1.01470657,  1.66026241, -0.95942153, -0.69886079,  1.69148155,\n",
       "                           0.1386857 , -0.08753717,  2.30359131,  0.89058213, -0.18985218,\n",
       "                           0.87929191, -0.18902626,  0.62843809,  1.98598879,  0.42815849,\n",
       "                          -0.76592918, -0.1766055 , -0.16502413,  0.09064031,  0.58215419,\n",
       "                           1.59947816,  1.46796344,  0.07718396,  2.05560682,  0.45951857,\n",
       "                           0.14430234, -0.46286897, -0.75771806,  0.31091269,  0.44194998,\n",
       "                           0.95163996,  0.4400647 ,  0.087738  , -0.19010962, -0.91944812,\n",
       "                          -0.04820292, -0.77905887,  1.82882388,  1.24333486,  1.85387971,\n",
       "                          -0.04940048,  0.8753758 , -0.12773072, -0.97433768, -0.04547499,\n",
       "                           1.30029351, -1.14483117, -1.00043214,  0.53227789,  2.18759633,\n",
       "                           1.18059461, -0.60654542,  0.28976789,  2.0755619 ,  0.36715992,\n",
       "                          -0.70800052,  0.50273757,  1.65490162,  1.84352533,  1.30164148,\n",
       "                           0.22470731,  1.94238198,  2.03105931,  0.82243733,  1.85498244,\n",
       "                          -0.85944022,  0.48924579, -1.09621553,  1.09430083,  0.9242366 ,\n",
       "                          -0.59077915, -0.78977567,  0.95483132,  0.90948993, -0.11689905,\n",
       "                           1.23484548,  1.38018566, -0.57539165, -0.22204826, -0.37269637,\n",
       "                           1.51305089, -1.05739763,  0.3571857 , -0.12866277, -0.10547563,\n",
       "                          -0.53502926, -0.91608495,  0.9249523 ,  1.25270494,  0.95080015,\n",
       "                          -0.84234887,  1.53095717,  0.78535597,  1.59884341,  0.99957283,\n",
       "                           0.64464005, -1.0699057 ,  2.00213519, -0.40614721,  0.33469936,\n",
       "                           0.65214022,  0.03407413,  0.96458548,  1.6415562 , -0.02042865,\n",
       "                           0.91079629,  0.51978855, -0.08485074,  2.01666972, -0.19347125,\n",
       "                           1.00515377,  0.35275976,  1.31814843,  0.18031667, -0.10900477,\n",
       "                          -0.02504993,  0.74639483, -0.70470324,  0.18864587,  0.77469984,\n",
       "                           1.12402685,  1.86928319, -0.04793449,  0.96031217,  0.39875679,\n",
       "                           1.73646864,  0.44796085,  0.53978437, -0.10049249,  1.733278  ,\n",
       "                           1.19167168, -0.05156596,  0.26728811,  1.04684185, -0.23701974,\n",
       "                           0.80800707, -0.08867949, -0.7399108 ,  1.35458806,  2.1841648 ,\n",
       "                           0.85739515, -0.723131  , -0.73175367, -0.79048783, -0.16666084,\n",
       "                           0.94541406,  1.09982239,  1.1253117 ,  0.61537428,  0.95447778,\n",
       "                          -0.14118295,  0.85190312,  1.41971143,  0.65454195,  0.57056522,\n",
       "                          -0.8452877 ,  0.33104374,  0.61072908,  1.81211192, -0.55011263,\n",
       "                           0.59224252,  0.75936198, -0.97647202,  0.98687934,  0.3016817 ]),\n",
       "              'y': array([ 8.95676502e-01,  1.30271685e+00,  9.76101642e-01,  2.80754689e-01,\n",
       "                           1.66286038e-01,  4.83073987e-01,  2.47423182e-01,  1.01815788e-01,\n",
       "                           8.57912687e-01, -3.95794592e-01, -1.39296564e-01,  5.79894859e-01,\n",
       "                          -8.49468200e-02,  5.48867708e-01,  1.65797662e-01, -3.23969818e-01,\n",
       "                          -6.09361126e-01,  8.62038970e-01, -3.02042473e-01,  1.39728522e+00,\n",
       "                           1.05710297e+00,  4.46290153e-01,  1.01588641e+00, -1.12110147e-01,\n",
       "                           8.55213463e-01, -1.02457679e-01,  8.67682891e-01,  7.94216700e-01,\n",
       "                           4.59400469e-01,  7.56741666e-01,  9.20982998e-01, -1.64729837e-01,\n",
       "                           4.72726656e-01,  3.73867195e-02, -1.23232491e-01, -3.04171205e-01,\n",
       "                          -2.04263083e-01,  1.13052981e+00,  1.01221924e+00, -7.09509758e-02,\n",
       "                           1.31825405e-01,  3.07844103e-01,  3.04118060e-02,  4.77480270e-01,\n",
       "                           1.04646340e+00,  8.11853040e-01,  2.41093668e-01,  1.04966761e+00,\n",
       "                           1.86882595e-01, -1.07540976e-01, -2.10770022e-01, -3.46502525e-01,\n",
       "                          -3.76075277e-01,  6.92055325e-01,  8.53930735e-01,  2.84801371e-02,\n",
       "                          -2.15304911e-01,  3.57049546e-01,  6.38006337e-01, -6.04515343e-01,\n",
       "                           2.46243758e-01,  1.11798900e+00,  9.65635921e-01,  1.26746270e+00,\n",
       "                           4.22991878e-01,  3.13781170e-02, -3.52662177e-01,  4.91608299e-01,\n",
       "                           1.04758959e+00,  7.76299277e-01,  7.10105796e-01,  4.08723519e-01,\n",
       "                           8.97416399e-02, -4.93166179e-01, -3.66669160e-01, -5.52977376e-02,\n",
       "                           5.93118901e-01,  1.04503159e-01, -1.29355939e-03, -1.08716725e-01,\n",
       "                          -5.25859404e-02,  3.62101610e-01,  6.84687315e-01, -1.22552202e-01,\n",
       "                           2.71883094e-01,  5.97562281e-01,  6.06191800e-01, -1.73247735e-01,\n",
       "                          -1.41934849e-01,  8.72540820e-01, -5.56155777e-02,  9.17276323e-01,\n",
       "                           8.54102820e-02, -8.43174348e-02, -5.64113827e-01,  6.27124515e-01,\n",
       "                           1.07722614e-01,  4.42084952e-01, -6.51429811e-01, -4.02356158e-01,\n",
       "                           6.76901169e-01,  6.26934448e-01,  4.40131467e-01, -5.72951934e-01,\n",
       "                           2.76547398e-01,  1.12835077e+00,  4.39880646e-01, -1.34719371e-01,\n",
       "                           1.48935910e-01,  9.39175504e-02,  1.03706366e-01, -3.32122026e-01,\n",
       "                           5.55939460e-01,  8.26443689e-01,  1.05542037e+00, -4.98012648e-01,\n",
       "                           6.27313630e-01,  1.10288121e-02,  4.48665676e-01,  8.98269904e-01,\n",
       "                           6.72548646e-01,  3.28530778e-02, -5.50122171e-01, -5.26482279e-01,\n",
       "                          -4.31831643e-01,  4.20378766e-01, -1.83055312e-01, -4.25805639e-01,\n",
       "                          -5.10323198e-01, -3.12246583e-02,  7.96693007e-01,  9.22300096e-02,\n",
       "                          -9.63987055e-03,  5.51468553e-01,  9.53790352e-03,  1.04250894e+00,\n",
       "                          -5.89005437e-02,  2.49179428e-01, -6.88284440e-01,  5.34667518e-01,\n",
       "                          -7.67328228e-01, -4.19835169e-01, -5.52648582e-02, -7.57917988e-02,\n",
       "                           8.27541934e-01,  2.76803239e-01,  6.61983680e-01, -4.42786128e-01,\n",
       "                          -1.27738317e-02,  4.63710978e-01,  7.47544687e-01,  7.48051104e-01,\n",
       "                           8.37130021e-01,  8.33279422e-01,  6.76723456e-01,  2.01105398e-01,\n",
       "                          -8.72580477e-02,  9.96844701e-01, -9.41546901e-01,  1.45153766e-02,\n",
       "                           1.92049493e-01,  5.85451365e-01, -8.76116454e-02,  2.13837813e-02,\n",
       "                          -5.86054148e-01,  3.95119944e-01,  9.61960204e-01,  9.98725154e-02,\n",
       "                           1.67763889e-01,  9.31751591e-01,  6.88423021e-01,  1.16445600e+00,\n",
       "                           1.02240319e+00,  3.53953319e-01,  3.26688594e-01, -6.16580586e-01,\n",
       "                           2.52639694e-01,  3.31220690e-02,  7.11549555e-01,  1.21050094e+00,\n",
       "                          -2.98959425e-01, -6.04284386e-01, -5.45748891e-01, -4.59946460e-01,\n",
       "                          -6.39418951e-01,  3.38253353e-01,  6.85005047e-01, -1.71769176e-02,\n",
       "                           9.55617397e-01, -2.93420674e-01,  7.63525878e-01, -5.69513908e-01,\n",
       "                          -5.43282867e-01,  4.00014876e-01,  7.37285482e-01, -6.30330997e-01,\n",
       "                          -1.59939504e-01,  9.08485666e-01, -5.29767648e-01,  6.73980692e-01])},\n",
       "             {'colorscale': [[0, 'rgb(0,0,0)'], [1, 'rgb(0,0,0)']],\n",
       "              'contours': {'coloring': 'lines', 'end': 0.5, 'showlabels': False, 'start': 0.5},\n",
       "              'line': {'width': 5},\n",
       "              'ncontours': 1,\n",
       "              'showscale': False,\n",
       "              'type': 'contour',\n",
       "              'uid': 'b1aed7e2-f417-4f77-9a1c-41eebfe5077e',\n",
       "              'x': array([-1.64483117, -1.62483117, -1.60483117, ...,  2.75516883,  2.77516883,\n",
       "                           2.79516883]),\n",
       "              'y': array([-1.44154690e+00, -1.42154690e+00, -1.40154690e+00, -1.38154690e+00,\n",
       "                          -1.36154690e+00, -1.34154690e+00, -1.32154690e+00, -1.30154690e+00,\n",
       "                          -1.28154690e+00, -1.26154690e+00, -1.24154690e+00, -1.22154690e+00,\n",
       "                          -1.20154690e+00, -1.18154690e+00, -1.16154690e+00, -1.14154690e+00,\n",
       "                          -1.12154690e+00, -1.10154690e+00, -1.08154690e+00, -1.06154690e+00,\n",
       "                          -1.04154690e+00, -1.02154690e+00, -1.00154690e+00, -9.81546901e-01,\n",
       "                          -9.61546901e-01, -9.41546901e-01, -9.21546901e-01, -9.01546901e-01,\n",
       "                          -8.81546901e-01, -8.61546901e-01, -8.41546901e-01, -8.21546901e-01,\n",
       "                          -8.01546901e-01, -7.81546901e-01, -7.61546901e-01, -7.41546901e-01,\n",
       "                          -7.21546901e-01, -7.01546901e-01, -6.81546901e-01, -6.61546901e-01,\n",
       "                          -6.41546901e-01, -6.21546901e-01, -6.01546901e-01, -5.81546901e-01,\n",
       "                          -5.61546901e-01, -5.41546901e-01, -5.21546901e-01, -5.01546901e-01,\n",
       "                          -4.81546901e-01, -4.61546901e-01, -4.41546901e-01, -4.21546901e-01,\n",
       "                          -4.01546901e-01, -3.81546901e-01, -3.61546901e-01, -3.41546901e-01,\n",
       "                          -3.21546901e-01, -3.01546901e-01, -2.81546901e-01, -2.61546901e-01,\n",
       "                          -2.41546901e-01, -2.21546901e-01, -2.01546901e-01, -1.81546901e-01,\n",
       "                          -1.61546901e-01, -1.41546901e-01, -1.21546901e-01, -1.01546901e-01,\n",
       "                          -8.15469010e-02, -6.15469010e-02, -4.15469010e-02, -2.15469010e-02,\n",
       "                          -1.54690100e-03,  1.84530990e-02,  3.84530990e-02,  5.84530990e-02,\n",
       "                           7.84530990e-02,  9.84530990e-02,  1.18453099e-01,  1.38453099e-01,\n",
       "                           1.58453099e-01,  1.78453099e-01,  1.98453099e-01,  2.18453099e-01,\n",
       "                           2.38453099e-01,  2.58453099e-01,  2.78453099e-01,  2.98453099e-01,\n",
       "                           3.18453099e-01,  3.38453099e-01,  3.58453099e-01,  3.78453099e-01,\n",
       "                           3.98453099e-01,  4.18453099e-01,  4.38453099e-01,  4.58453099e-01,\n",
       "                           4.78453099e-01,  4.98453099e-01,  5.18453099e-01,  5.38453099e-01,\n",
       "                           5.58453099e-01,  5.78453099e-01,  5.98453099e-01,  6.18453099e-01,\n",
       "                           6.38453099e-01,  6.58453099e-01,  6.78453099e-01,  6.98453099e-01,\n",
       "                           7.18453099e-01,  7.38453099e-01,  7.58453099e-01,  7.78453099e-01,\n",
       "                           7.98453099e-01,  8.18453099e-01,  8.38453099e-01,  8.58453099e-01,\n",
       "                           8.78453099e-01,  8.98453099e-01,  9.18453099e-01,  9.38453099e-01,\n",
       "                           9.58453099e-01,  9.78453099e-01,  9.98453099e-01,  1.01845310e+00,\n",
       "                           1.03845310e+00,  1.05845310e+00,  1.07845310e+00,  1.09845310e+00,\n",
       "                           1.11845310e+00,  1.13845310e+00,  1.15845310e+00,  1.17845310e+00,\n",
       "                           1.19845310e+00,  1.21845310e+00,  1.23845310e+00,  1.25845310e+00,\n",
       "                           1.27845310e+00,  1.29845310e+00,  1.31845310e+00,  1.33845310e+00,\n",
       "                           1.35845310e+00,  1.37845310e+00,  1.39845310e+00,  1.41845310e+00,\n",
       "                           1.43845310e+00,  1.45845310e+00,  1.47845310e+00,  1.49845310e+00,\n",
       "                           1.51845310e+00,  1.53845310e+00,  1.55845310e+00,  1.57845310e+00,\n",
       "                           1.59845310e+00,  1.61845310e+00,  1.63845310e+00,  1.65845310e+00,\n",
       "                           1.67845310e+00,  1.69845310e+00,  1.71845310e+00,  1.73845310e+00,\n",
       "                           1.75845310e+00,  1.77845310e+00,  1.79845310e+00,  1.81845310e+00,\n",
       "                           1.83845310e+00,  1.85845310e+00,  1.87845310e+00]),\n",
       "              'z': array([[0.86597938, 0.86597938, 0.86597938, ..., 0.86597938, 0.86597938,\n",
       "                           0.86597938],\n",
       "                          [0.86597938, 0.86597938, 0.86597938, ..., 0.86597938, 0.86597938,\n",
       "                           0.86597938],\n",
       "                          [0.86597938, 0.86597938, 0.86597938, ..., 0.86597938, 0.86597938,\n",
       "                           0.86597938],\n",
       "                          ...,\n",
       "                          [0.16504854, 0.16504854, 0.16504854, ..., 0.16504854, 0.16504854,\n",
       "                           0.16504854],\n",
       "                          [0.16504854, 0.16504854, 0.16504854, ..., 0.16504854, 0.16504854,\n",
       "                           0.16504854],\n",
       "                          [0.16504854, 0.16504854, 0.16504854, ..., 0.16504854, 0.16504854,\n",
       "                           0.16504854]])}],\n",
       "    'layout': {'autosize': False,\n",
       "               'font': {'family': 'arial, monospace', 'size': 13},\n",
       "               'height': 480,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'n_estimators = 1, max_depth = 1',\n",
       "                         'x': 0.41,\n",
       "                         'xanchor': 'center',\n",
       "                         'y': 0.9,\n",
       "                         'yanchor': 'top'},\n",
       "               'width': 640,\n",
       "               'xaxis': {'title': {'text': 'feature 1'}},\n",
       "               'yaxis': {'title': {'text': 'feature 2'}}}\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features is 2 \n",
    "\n",
    "# initialize RandomForestClassifier\n",
    "ML_algo = RandomForestClassifier(random_state=42) \n",
    "\n",
    "# set RF parameter grid\n",
    "hyperparameters = {\n",
    "    'n_estimators': [1, 3, 10, 30],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "plot_clf_contour(hyperparameters, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|so so|constant|yes|max_features,  max_depth|no|so so|\n",
    "| random forest classification \t|<font color='red'>so so</font> |<font color='red'>step-like, difficult to tell</font>|<font color='red'>yes</font>|<font color='red'>max_features,  max_depth</font>| <font color='red'>no</font>|<font color='red'>so so</font>|\n",
    "| SVM rbf regression               \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|\n",
    "| SVM rbf classification           \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth is limited by the number of your training data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Support Vector Machine\n",
    "- very versatile technique, it comes in lots of flavors/types, read more about it [here](https://scikit-learn.org/stable/modules/svm.html)\n",
    "- SVM classifier motivation\n",
    "   - points in n dimensional space with class 0 and 1\n",
    "   - we want to find the (n-1) dimensional hyperplane that best separates the points\n",
    "   - this hyperplane is our (linear) decision boundary\n",
    "- we cover SVMs with radial basis functions (rbf)\n",
    "   - we apply a kernel function (a non-linear transformation) to the data points\n",
    "   - the kernel function basically \"smears\" the  points\n",
    "   - gaussian rbf kernel: $\\exp(-\\gamma (|x - x'|)^2)$ where $\\gamma > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "np.random.seed(10)\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "X = np.random.rand(n_samples)\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_new = np.linspace(-0.5, 1.5, 2000)\n",
    "\n",
    "reg = SVR(gamma = 1, C = 1)\n",
    "reg.fit(X[:, np.newaxis],y)\n",
    "y_new = reg.predict(X_new[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVR in module sklearn.svm._classes:\n",
      "\n",
      "class SVR(sklearn.base.RegressorMixin, sklearn.svm._base.BaseLibSVM)\n",
      " |  SVR(*, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |  \n",
      " |  Epsilon-Support Vector Regression.\n",
      " |  \n",
      " |  The free parameters in the model are C and epsilon.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to datasets with more than a couple of 10000 samples. For large\n",
      " |  datasets consider using :class:`~sklearn.svm.LinearSVR` or\n",
      " |  :class:`~sklearn.linear_model.SGDRegressor` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer or\n",
      " |  other :ref:`kernel_approximation`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
      " |       Specifies the kernel type to be used in the algorithm.\n",
      " |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |       used to precompute the kernel matrix.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Must be non-negative. Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features\n",
      " |      - if float, must be non-negative.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive.\n",
      " |      The penalty is a squared l2 penalty.\n",
      " |  \n",
      " |  epsilon : float, default=0.1\n",
      " |       Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
      " |       within which no penalty is associated in the training loss function\n",
      " |       with points predicted within a distance epsilon from the actual\n",
      " |       value. Must be non-negative.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `class_weight_` was deprecated in version 1.2 and will be removed in 1.4.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (1, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (1, n_SV)\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run by the optimization routine to fit the model.\n",
      " |  \n",
      " |      .. versionadded:: 1.1\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (1,), dtype=int32\n",
      " |      Number of support vectors.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV,)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  NuSVR : Support Vector Machine for regression implemented using libsvm\n",
      " |      using a parameter to control the number of support vectors.\n",
      " |  \n",
      " |  LinearSVR : Scalable Linear Support Vector Machine for regression\n",
      " |      implemented using liblinear.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n",
      " |      Machines and Comparisons to Regularized Likelihood Methods\"\n",
      " |      <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import SVR\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> rng = np.random.RandomState(0)\n",
      " |  >>> y = rng.randn(n_samples)\n",
      " |  >>> X = rng.randn(n_samples, n_features)\n",
      " |  >>> regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
      " |  >>> regr.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svr', SVR(epsilon=0.2))])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVR\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.svm._classes.SVR, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVR\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.svm._classes.SVR, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVR\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  class_weight_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  unused_param = 'random_state'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform regression on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c121a68194f451d91669d6c1b44d041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='gamma', options=(0.001, 0.1, 10.0, 1000.0, 100000.0), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gamma defines the width of each Gaussian function. \n",
    "# A small γ will produce a more flexible decision boundary, while a large γ can make the decision boundary more restricted (potentially leading to overfitting).\n",
    "# C defines the regularization; it determines the trade-off between maximizing the margin and minimizing classification errors.\n",
    "# A small C will result in a wider margin but may misclassify more training points, emphasizing simplicity over accuracy on the training set.\n",
    "# A large C will prioritize classifying all training examples correctly, potentially leading to a smaller margin and risk of overfitting.\n",
    "hyperparameters = {\n",
    "    'gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5],\n",
    "    'C': [1e-1, 1e0, 1e1]\n",
    "}\n",
    "\n",
    "vis(X, y, SVR, hyperparameters, X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "\n",
    "Let's measure how long it takes to fit a linear regression, random forest regression, and SVR as a function of `n_samples` using our toy regression dataset. \n",
    "\n",
    "Check [this](https://stackoverflow.com/questions/7370801/how-do-i-measure-elapsed-time-in-python) stackoverflow post to figure out how to measure the execution time of a couple of lines of code. \n",
    "\n",
    "Set n_estimators to 10 and max_depth to 3 in the random forest. \n",
    "\n",
    "Set the gamma and C parameters to 1 in SVR. \n",
    "\n",
    "Fit models with n_samples = 1000, 2000, 3000, 4000, 5000. Measure how long it takes to fit each model.\n",
    "\n",
    "Plot the run time as a function of n_samples for the three models. You might need to adjust the y axis range to check some of the statements.\n",
    "\n",
    "Which of these statements are true?\n",
    "\n",
    "- The random forest run-time scales linearly with n_samples.\n",
    "- The linear regression model is the fastest to fit. \n",
    "- The SVR run-time scales worse than linear. (I.e., if we double n_sample, the fit time more than doubles.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "3.314018249511719e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005548000335693359\n",
      "0.00037407875061035156\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "alg1 = RandomForestRegressor(n_estimators=10, max_depth=3)\n",
    "alg1.fit(X[:, np.newaxis],y)\n",
    "end1 = time.time()\n",
    "print(end1 - start1)\n",
    "start2 = time.time()\n",
    "alg2 = SVR(gamma = 1, C = 1)\n",
    "alg2.fit(X[:, np.newaxis],y)\n",
    "end2 = time.time()\n",
    "print(end2 - start2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "n_samples = [1000, 2000, 3000, 4000, 5000]\n",
    "RF_time = []\n",
    "SVM_time = []\n",
    "LR_time = []\n",
    "for n in n_samples:\n",
    "    start1 = time.time()\n",
    "    alg1 = RandomForestRegressor(n_estimators=10, max_depth=3)\n",
    "    alg1.fit(X[:n, np.newaxis],y)\n",
    "    end1 = time.time()\n",
    "    RF_time.append(end1-start1)\n",
    "    start2 = time.time()\n",
    "    alg2 = SVR(gamma = 1, C = 1)\n",
    "    alg2.fit(X[:n, np.newaxis],y)\n",
    "    end2 = time.time()\n",
    "    SVM_time.append(end2-start2)\n",
    "    start3 = time.time()\n",
    "    alg3 = LinearRegression()\n",
    "    alg3.fit(X[:n, np.newaxis],y)\n",
    "    end3 = time.time()\n",
    "    LR_time.append(end3-start3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAHRCAYAAADKexnNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4j0lEQVR4nOzdd1gT2dcH8O+EFop0UJqABUVFQRQVRYq9C2Iv2Ht37QV1XXVXV7G79rp21J9lVVTsXZG1YQVUsIAFRHq47x95kyUmQMDAUM7nefIod+7MnEkmMyd37tzhGGMMhBBCCCGEqJiA7wAIIYQQQkjpRIkmIYQQQggpFJRoEkIIIYSQQkGJJiGEEEIIKRSUaBJCCCGEkEJBiSYhhBBCCCkUlGgSQgghhJBCQYkmIYQQQggpFJRoEkIIIYSQQsFbomlnZweO48BxHC5dupRjPUmdpKSkIowufyQxlmb3799HmzZtYGxsDIFAAI7jcOHChTznY4xhz549aN26NcqXLw8NDQ0YGxujevXq8Pf3R1BQEOLi4gp/A4rQtm3bwHEc+vfvz3coxVZUVJT0e5OflzL7XH71798fHMdh27ZtKlme5NgWFRWlkuXxTfL+5Ofl5eUFoOS/F/Hx8Rg4cCCsrKygrq4OjuMwd+5c3uJR9rM4cuRIkcfm5eVVaN9RAIiMjJSee/z9/XOtW1KOwRcuXJD5vuRHYb/fqqTOdwAAMGPGDFy5coXvMEgOkpKS0KFDB7x9+xYNGzZE1apVIRAIUKFChVzny8zMRNeuXXHkyBFwHAdXV1c0bdoUHMfh+fPnOHLkCA4dOoQqVaqgffv2RbQ1pDjQ09NDQECAXPn9+/cRHh6OypUro0mTJnLT89rniOop+hwAYPv27QCALl26QE9PT2Za9erVCz2uojB48GAcPXoUVapUQbdu3aCpqQlnZ2e+w0KdOnVyjaNixYpFF0wR2bZtGyRPzD527Bg+f/4MY2NjnqMqHBcuXIC3tzc8PT1LRCKZF94TTR0dHVy9ehUnTpxAu3bt+A6HKHDr1i28ffsWHh4eubY+/2jNmjU4cuQIrKyscOrUKdSqVUtmelxcHPbu3Yvy5curOmRSzJmamipsQZw7dy7Cw8PRpEkTlbUw5mXRokWYNm0aLCwsVLK8c+fOISMjA1ZWVipZHt8GDx6MwYMHy5VLEs2lS5fCzs5O4bwl+b1IT0/HiRMnoK2tjbCwMLlkmk+dO3fmtWW1qDHGsGPHDgCApaUlYmNj8ffff2P06NE8R/Zz3Nzc8OTJE+jo6PAdSqHivY+mZEeZNWuW9NcKKV7evn0LAKhUqVK+5jtw4AAAIDAwUC7JBAAzMzOMGTMG9evX//kgCSkgCwsLVK9eHQYGBipZXuXKlVG9enVoaGioZHklWUl+L96/f4/MzEyYm5sXqySzLLpw4QKioqJga2uLP/74AwCK7IdoYdLR0UH16tVLZQt0drwnmr1790bNmjVx//597N+/X+n5cusXKen/9eOv7OzlIpEIf/zxBxwdHaGtrQ07OzsEBgYiMzMTABAdHY3+/fvDwsICQqEQdevWxYkTJ3KNiTGGdevWoU6dOtDR0YGZmRl69uyJly9f5jhPdHQ0Ro0ahSpVqkAoFMLQ0BDe3t4IDg5WWD97n6f9+/ejSZMmMDAwAMdx+Pr1a67xSURGRmLo0KGws7ODlpYWTExM0KpVKxw/flymnqT/iOQS5/bt2+X6YOXm48ePAABzc3Ol4so+X1BQEFq2bAk7OzsIhUIYGRmhadOm0l+1P8re1yUlJQXTp09HpUqVIBQK4eDggJUrV0rrPnjwAF26dIGZmRl0dHTg4eGBGzduyC0z+/6SmZmJhQsXolq1ahAKhbC0tMSwYcOk25gfDx8+RP/+/VGxYkXp+9+uXbscL5G8ePECw4YNQ7Vq1aCrqwt9fX1UrlwZ3bt3x7lz5/Jc36dPn6ClpQVdXV18+/ZNYZ20tDQYGRlBTU0NMTEx0vL79++jV69eqFKlCrS1tWFkZAQHBwf0798f9+7dy/e2/wxl9v2bN29i0qRJcHV1hbm5ObS0tGBjY4M+ffrg4cOHCpebUx/N7OURERHo0qULTE1NpceDffv25RlnTuUnT56Eh4cHypUrB319fbRu3TrX9/PMmTPw8vKCnp4eDA0N0bx5c1y8eDHHPl7Zy9PS0hAYGIgqVapAS0sL1tbWGD9+PL5//57r+60KyrwXhw8fhru7O/T09GBubo5+/frhw4cPAICUlBTMnj1benysVKkS/vjjjxwbJbKysrBr1y74+PjA2NgYWlpaqFSpEsaNGyddpjI4joOtrS0A8TE6e//H7D5+/IhJkybBwcFBevyWHKcUxZh9n7p37x46d+4Mc3NzCASCQu1XGRISgpEjR6J27dowNjaWvpfDhw9HdHR0jvNlZWVh9+7daNGiBUxNTaXfp7Zt22L37t05znf9+nW0bt0ahoaG0NHRQZMmTZQ6VuVE8t3s168f/Pz8YGBggLt37+b4nc5NVlYWVq9eDScnJ2hra6N8+fLo06cPoqKiMHfu3Bz74WZlZWHbtm3w8PCAoaEhhEIhqlWrhsmTJyM+Pl6ufvbvYFJSEqZOnSr9Dnbu3FmujkT//v3h7e0NALh48aLCvs8/ys/7nX0/3rRpE1xcXKCjowNLS0uMGTNGej/M58+fMXbsWFSsWBFCoRA1atQoeHLPeGJra8sAsAcPHrDg4GAGgDk4OLDMzEyZegAYAPbt2zeF5YpERkYyAMzW1jbHcn9/f6anp8c6dOjA2rVrx3R1dRkANnjwYPb8+XNmbm7OqlSpwrp3787q1avHADA1NTV2/vx5ufVJYhk3bhxTU1Nj3t7erEePHqxSpUoMADMyMmIPHjyQmy8kJISVK1eOAWDVqlVjfn5+zNPTkwmFQgaATZ8+Pcf3bcSIEQwAa9SoEevZsydzdXVlX79+zettZ1evXmX6+voMAKtatSrr0aMH8/LyYmpqagwAmzZtmrTukydPWEBAAGvcuDEDwCpXrswCAgJYQEAAW7RoUZ7ratasGQPA2rRpw1JTU/OsL7Fz504GgFWsWJE1a9aM9ejRg3l4eEhjHDlypNw8oaGh0vfD3d2dmZiYsC5durDmzZszDQ0NBoAtWLCAXbt2jenq6rLatWuz7t27s5o1azIATEdHhz158kRmmZL9pWLFiqxz585MS0uLtW7dmnXr1o1VqFBBui/FxMTIzLd161YGgAUEBCjcNkk8derUYf7+/szd3Z2pqakxjuPYunXrZOqHh4czPT09BoDVqFGDdenShfn5+bH69eszDQ0NNmzYMKXeU19fXwaAbdmyReH0/fv3MwCsZcuW0rLTp08zdXV1BoC5urqybt26sY4dOzJnZ2cmEAiU2gfyKzAwMMf3Tpl9v1mzZkxdXZ3VqVOHdezYkfn6+jIHBwcGgGlra7OLFy/KLTcgIIABYFu3blVYPmbMGKarq8scHR1Z9+7dmZubm/Q7v3v37hzjjIyMVFg+bdo0JhAIWJMmTVjXrl1Z5cqVGQCmq6vLnj59Kre8rVu3Mo7jGADWoEED1rNnT+lnMH78eAaAeXp6ysyT/fvg6enJDA0NWadOnVjbtm2lx5zsn3VBSN6DH7czP+/FpEmTpMfMLl26MEtLS+m+npiYyBo1asRMTEyYn5+fzHd53rx5cutKT09nnTp1YgCYnp4e8/LyYn5+ftLjsJWVFXv58qVS2xYQEMC6dOki/Vwkx73s++XTp0+l8VpbW7Nu3bqx1q1bMy0tLQaA9erVi2VlZcktFwAbNGgQ09TUZA4ODqxHjx6sefPm7Pjx40rFBYAFBgYqtR0SlStXZkKhkLm6ujI/Pz/WoUMHVrFiRQaAGRsbs4iICLl5UlNTWdu2bRkApqGhwTw9PVnPnj2Zp6cnMzIykju/enp6MgDsl19+Yerq6szV1ZV1796d1apViwFg6urqCr9/efn27Zv0/PzixQvGGGNDhgyR7j+K5HYM7t+/PwPANDU1WatWrVj37t2ZtbU1MzExyfH9zcrKYt26dWMAZM4DVlZWDACzsbFhz58/l5lH8h10c3NjdevWZfr6+qxDhw7M399fetyW1Mn+/d24cSNr1aoVA8DKly8vs+9lP+YW9P2WfG8nTZok3ZZOnToxY2NjBoA1b96cxcfHs6pVqzIrKyvWrVs31rRpU+kxaPv27cp8bLLrzPccKpI90WSMsfr16zMAbNOmTTL1CiPRBMAcHR3Zu3fvpNMePnzINDU1mUAgYI6OjmzSpElMJBJJp0+bNo0BYF5eXnLrkyxTV1eXXb16VVqemZnJhg0bxgAwFxcXmXliYmKYoaEh09DQYHv27JGZ9uTJE+n7c+7cOYXvm4aGBjt9+rTC7c9JSkoKs7a2ZgDYjBkzZA6CV69elSY0J0+elJkvty9tbg4cOCB9bypUqMCGDh3KtmzZwsLDw2Xe2x89fvyY3bp1S678xYsX0oPj9evXZaZJvrCSL21iYqJ02pkzZ6QnH1tbW7ZixQrpNJFIxHr16sUAsP79+8ssM/v+UqFCBZmDcXJyMuvQoQMDwHx9fWXmy+n9CgsLYxoaGszAwICdPXtWZtr169el+0P29UgOiosXL5Z7Pz59+sTu3r0rV67IkSNHctx/GWOsffv2DADbtWuXtMzLy4sBYHv37pWrHxMTwx49eqTUuvNDmUQzt33/n3/+YR8+fJAr37hxIwPAqlevnuPJP6dEEwD7/fffZaYtWbKEAWD29vY5xplTciUUCtmFCxek5enp6axz584MABswYIDMPK9fv2Y6OjqM4zi2b98+mWkrV66U2eezy/59aNSoEfv8+bN02osXL5iBgQEDUKATv4QqEk0dHR127do1afnXr19ZjRo1GABWs2ZNue/yqVOnpN/lpKQkmWVOnjxZeqLMfmwXiURsxowZDADz8PBQevtyOo9ISBogAgICWFpamrQ8IiJCmoCuXbtWZp7s+9S8efPk9sW8FDTRPHLkiFxDRGZmJpszZw4DwFq1aiU3z+jRoxkA5uTkxF69eiUzLTU1Ve48IUl8OI6TOadlZWVJl+Xt7Z2vuBljbPPmzQwAa9KkibTs6tWr0uNyRkaG3Dw5HYMPHTrEADAzMzOZ41daWhrr2bOn9LP58f1dtWqVwoQyNTVVev5wc3OTmSf7d9DV1ZXFxcXJxako0cytPLuCvt/Zz2nZf9i+ffuWmZmZSb97PXr0kNmv169fn+MxLy/FJtEMCQlhgLj1KHvrV2ElmiEhIXLzSQ729vb2Mm8wY4x9+fJFepJLT09XGMvkyZPllpmUlMRMTEwYAHbp0iVpueSgOGfOHIXbIPlC/JjESN43ZVuystu+fTsDxK2nihI9yUm+WbNmMuUFTTQZY2zt2rXSk1r2l5GRERs2bBiLjo7O1/I2bNgg/RWXneSLKRAIFP46d3Z2ZgBY48aN5abdv3+fAWB2dnYy5dn3lzVr1sjN9/r1a6ahocE4jmNRUVHS8pzer65duzIg51bFP//8kwFgEyZMkJZJWhTCwsIUzqOs9PR0ZmpqyjiOk3vPP378yNTV1Vm5cuXY9+/fpeWSE/6XL19+at35oUyiWZB9nzHG3N3dGQD28OFDmfK8Es2GDRvKLSs9PZ0ZGRkxADKfffY4c0qupk6dKre827dvK9wH586dywCwjh07KtymBg0a5HqiEggECn8QjBo1igFgc+fOVbhcZagi0Zw5c6bcPEFBQUp9l7Mn6/Hx8UwoFDIjIyMWHx8vN49IJGJ16tRhAFh4eLhS25dbonnx4kUGiFsDsyfCEpJjQOXKlWXKJfuUo6Njrj+2c5I9Uc3tlR9WVlZMIBDIbMf79++ZhoYGU1dXV7oVWJL4dO/eXW5aXFwcA8StiD+eP/Pi4eHBALCNGzfKlEuuVBw7dkxunpyOwZIfz8uWLVMYo6Tl9MdE097eXu6HuMSXL1+k57jLly9Ly7Mnmj82jPxY52cSzfy+35KYfnw/GWPSKyT6+vpy36PMzExpLvPjMS8vvPfRlGjevDm8vb3x+vVrrF+/vlDXpaGhIe0DkV3lypUBiMen0tTUlJlmaGgIExMTZGRkKOyPAYj7m/5IV1cXvr6+ACBzx/Y///wDAOjatavCZTVt2hQAFPYdBCDt45EfkvX36dMHAoH8Rz9w4EAAwNWrVyESifK9fEVGjBiBN2/eYMeOHRg4cCBq164NgUCAL1++4K+//kKdOnVw69YtufkyMjLwzz//IDAwEMOHD8eAAQPQv39/HDx4EADw7NkzheuztbVFtWrV5Moln23Lli1znBYbG5vjdij6bG1sbODp6QnGWJ7Dc2VlZeH06dNQU1ODn5+fwjqKPvN69eoBAEaOHIlz584hPT091/XkRENDAz179gRjDDt37pSZtmfPHulQVNnvfpSsu0+fPrh+/brK9omflde+//HjR2zevBmTJk3C4MGD0b9/f/Tv3x/v378HkPO+k5PWrVvLlWloaMDe3h5A7vuNIm3atJErk+yzPy5L8p3t3r27wmX17Nkz13VVrFgRNWrUUHp9RS2372Ne3+XssV+4cAGpqanw8fGBiYmJ3DwCgUA6TFNOx9T8kHwuvr6+KFeunNz0Pn36QENDAy9fvpTp8yzRsWNHhcdgZdWpUwcBAQE5vhSJjo7G2rVrMX78eAwaNEj6vcjIyEBWVhZevHghrXv+/HlkZGTAy8sr3zeBKtq/TU1NYWxsjPT09BzPn4q8fPkSV65cgba2Nrp16yYzrV+/fgCUvykoMzMT169fB6D4+2RqaooWLVrIlb99+xaRkZHQ1NREjx495KYbGhpKj+kXL16Um16+fHk0bNhQqRgLoqDvd27fPVdXV7nvkZqamvS+l/weN3gf3ii7hQsXolGjRli4cCEGDRpUaHf6VahQAWpqanLlkvVZW1srnE9PTw+fPn1CWlqawuk5DfEhKZfcvQ0Ar169AgA4OTnlGmtOg5lLOqrnh+SAJzlB/sja2hqamppITU3Fp0+f8n0TT07KlSuHvn37om/fvgDEN6fs2bMHs2fPxtevX9G/f388fvxYWj8iIgKdOnXKNSFITEzMcRsUye2zlUzLKYkzNDTM8Y5kRZ+tIp8+fZLGbGhomGvd7J/5lClTcOvWLZw6dQrNmzeHlpYWXF1d4ePjg379+qFq1aq5Liu7gIAArFq1Cjt37sTMmTOl5ZIbrCQHbonFixcjIiICJ06cwIkTJ6Cnpwc3Nzc0b94cAQEBsLS0VHrdqpTbvr927VpMmjQJqampOdbJad/JiY2NjcJySYKR0/EgP8uTLOvHfVDync1pm/M6Dqg6dlXL7fuY13c5e+yS4+mhQ4fyfHiGKh4QkdexVF1dHRUrVpQmmj8O71SQ43d2+R3eaNasWVi8eHGuPxazfy9ev34NAAoT/bzkts99/vw5X/ucZOxMX19f6Ovry0zr168f5syZo/SYmvHx8UhLS4OmpmaOQ5kp+lwkn3XFihUV5g3AfyOyKPpR8bOfdV4K+n6r6runjGKVaDZs2BAdOnTAsWPHEBQUhFmzZhVoOVlZWblOz+uX5M/80lSW5Avfq1evAg39oa2treqQioyJiQlGjx4Na2tr+Pr64smTJ3j+/Lk0afL398ezZ8/QuXNnTJ06FdWqVYO+vj7U1NRw5swZtGrVKse7TovDZ6uI5PPW1NTMsxXK1NRU+n9dXV38888/uHPnDk6cOIGLFy/ixo0buHbtGhYtWoR169ZhyJAhSsXg6uqKmjVr4tGjR7h58yYaNGiAJ0+e4O7du7Czs5O2qEpYWFjg+vXruHLlCv755x9cunQJly9fxvnz5/Hrr7/iwIEDvIx9m9O+f/v2bYwePRrq6upYtmwZ2rdvD2tra2n9Xr16Yc+ePfkeRk3V+0xBlpdT8lRc93dl5RZffmKXfL9q1KiR53BpNWvWVHq5haUoj98HDx7Eb7/9Bn19fQQFBcHb2xsWFhbQ0tICALi7u+P69esy34ufedKdqvY5lm3szBs3bih8cICGhgbS0tLyNaZmbttWGN+Xwv6sCxqzqr57yihWiSYALFiwAMePH8fSpUsxatSoHOtpaGggIyMDSUlJci2fb968KewwFYqOjkbt2rXlyiVDe2T/VWtjY4MXL15g/vz50ubqwiZZv+TX/4/evn2L9PR0CIXCInniQrNmzaT/j4uLQ9WqVREREYFHjx6hfPnyOHjwoNwvyOyXd4rK169fkZiYKPeLGlD82SoiGRYnIyMDf/31l/Qgr6x69epJL2WnpqZiw4YNGD9+PMaOHYtu3bopPQZkv379MHXqVOzYsQMNGjSQac1UdAAWCARo2rSpNAlNTEzEokWLsHjxYgwZMoT3S6/ZHTp0CIwxjB07FhMmTJCbzse+87MsLS3x9OlTvH79Gu7u7nLTS+qjHVVN0qpTt27dIhlfMa9jaWZmprRVkO/B6iXdjX777TcMGDBAbrqi74VkXMf8djNRpfPnz0vfw1evXuX4XgPils+8Ek0TExNoamoiLS0NHz58UPiUMUXfJ8nn9/r1a4hEIoWtmpLY+P6si6ti93O3du3a6NGjBxISEvD777/nWE9y2e7p06dy086cOVNo8eXm77//litLTk7G0aNHAUCmxUjS70tyECgKkvXv3r1bYavv1q1bAQCNGzeGuvrP/wbJq+Xo+fPn0v9LvqCfP38GIG5NU/SF3rt370/HVRCKPtuYmBhcunQJHMfl+Jg+CXV1dTRv3hwikeinx8sTCoUYO3YsqlSpgtTU1HydDCT9c/ft24fU1FTpWHg/XjbPib6+PhYuXAhNTU28e/euWD2nXrLvKLqUFBERgbCwsKIO6ad5eHgAQI5jdvL1fShumjVrBg0NDZw6dUo6DmBhkhxLjxw5onBs2t27dyMjIwOVK1fmPfnI7Xtx7tw5hd9hb29vaGhoIDQ0FJGRkYUeoyKSHwwTJkwAE9+4LPdKSUmBvr6+UmNqamhoSPtKKvo+ff78GSEhIXLl1tbWsLe3R3p6usLvW0JCAg4fPgwA8PT0zO9mKiS5R0QyrndJV+wSTQCYP38+1NXVsWrVqhzrSG7m+e2332Q+jDNnzmD58uWFHqMia9askeloLhKJMHnyZMTFxaFOnTrSkwYA/PLLLyhXrhzmzp2LzZs3y/WdYYzh9u3bCnf8guratSusrKzw9OlTBAYGyiSCN2/exJ9//gkAmDhxokrW16FDByxbtkzhoObR0dHSS74NGjSQ9mORPEf94cOHuHz5srQ+YwwLFy6UKStK8+fPl0mMU1NTMWrUKKSnp6NDhw459s/Nbs6cOVBXV8fIkSMVJpsikQihoaEy+9DatWtl1ivx4MEDREdHQyAQ5NifRhFLS0s0b94cnz59wuTJk/HmzRs0btxYYav6n3/+qbDvaUhICNLT06Gvry/T33T69OmoXr06pk+frnQ8qiR5vvaOHTtkko34+HgMGDCgRB60Bw0aBG1tbRw9ehSHDh2SmbZu3TrpzQ1lXYUKFTBixAjEx8fD19dXYevX169f8ddff6lkP2jatClcXV2lg1pnZGRIpz1//lzaB3rSpEk/va6fJflebNy4USbOqKgojBgxQuE85cuXx9ChQ5GZmQk/Pz+5Qd3T0tKkN7QWhsTEROlDS/r06ZNjPaFQKL0RR5mWbEmr58KFCxERESEtz8jIwLhx43L8kSK5QjJ9+nSZB7Ckp6dj9OjR+Pr1K9zc3PJscFCW5MfJixcvSuRx60fF7tI5AFSpUgUDBgzAxo0bc6wzbdo0HDhwAIcPH4ajoyOcnZ0RFRWFu3fvYurUqVi8eHERRiw2cOBANGnSBJ6enjA3N8ft27fx8uVLGBoaYseOHTKXJm1tbREcHIyuXbti8ODBmDt3LmrWrAkTExN8+vQJ9+/fx4cPHzB16lSFd8IVhLa2Nvbt24e2bdtiwYIFOHDgAOrWrYsPHz7g4sWLEIlEmDZtGtq2bauS9b19+xaTJk3ClClTULNmTVStWhVqamp4+/Ytbt68CZFIBCsrK5kDhJmZGYYPH461a9fC29sbXl5eMDMzw927d/Hq1Sv88ssvWLp0qUriU1bFihXh4uICJycn+Pj4oFy5crh8+TLevXuHihUrYs2aNUotp379+ti2bRsGDRoEX19f6eP59PX18eHDB4SFheHLly9Yt26d9Jf3hg0bpE+OqlWrFnR0dBATE4OrV68iMzMTkydPzvczugMCAnDmzBmsXr1a+rciv/76KyZPnowaNWqgevXq0NTURGRkJG7evAlA/Izw7P2L3717h6dPn+Ldu3f5ikdVBgwYgOXLl+PevXuoXLkymjRpgoyMDFy4cAGWlpbo3LlzoT59pTBUrFgRq1atwpAhQ+Dv74+GDRvC3t4eERERCA8Px5gxY7Bq1Sq5UTLKoiVLluDt27cIDg5G9erV4eLiAjs7O2RlZeHVq1f4999/kZmZiYCAAJVcsfn777/h7e2Nbdu24dy5c3B3d0diYiLOnz+PtLQ09OzZE8OHD1fBlsk7cuRIrt0mWrZsiV69egEAxo4di+3bt+PEiROoWrUq3NzckJiYiIsXL8LNzQ1mZma4du2a3DKWLl2K58+f48yZM3BwcEDjxo1RoUIFvHv3DuHh4dDX1y+0rhv79+9HcnIyHB0dUbdu3Vzr9u7dG9u2bcPu3buxePHiXD/brl27om/fvti5cyecnZ3h7e0NAwMDXLt2DUlJSdJpP36fRo0ahcuXL+PAgQOoVasWvL29oa+vj6tXr+Lt27ewtrbO9UlJ+WVrawsXFxeEhYWhdu3acHV1hZaWlvRJRCVNsWzRBMStP0KhMMfp1apVw6VLl9CqVSt8+PABJ0+ehIaGBo4ePYphw4YVYaT/CQoKQlBQED5+/IgjR47g69ev6N69O27fvq2w72bz5s3x6NEjTJkyBUZGRrhy5QoOHz6MZ8+eoXbt2ggKCsLYsWNVGmPjxo0RFhaGwYMHIyUlBQcPHkRYWBh8fHxw9OhRLFq0SGXrOnToENasWYOOHTsiMzMT586dQ3BwMJ4+fYpGjRph8eLFePz4sfQXt8SqVauwZs0a1KxZE9evX0dISAgcHBxw+fJlXm4+4TgOBw4cwIwZM/DixQscOXIEjDEMGTIEN2/ezFeLYu/evfHgwQOMHDkSampqOH/+PP73v//h9evXaNKkCTZs2CAzjMeCBQswdOhQ6Orq4vLlyzh06BCioqLQunVrnDx5Uvrc3/zIfgenUCiUGzZEYvXq1ejbty8YYzh37hyOHDmCuLg4dOvWDVevXsXIkSPzve7CZGRkhNu3b2PgwIHQ1tbGiRMn8ODBAwwaNAg3btxQ2bPMi9qgQYOkj6z8999/ceLECRgaGuLMmTNwc3MDIHsDWVmlqamJQ4cOITg4GK1atUJ0dDQOHz6MCxcuIDMzE4MHD8apU6dyPa/kh4ODA8LCwjBhwgRoaWnh8OHDuHLlivQH5e7du3/qpprchIeHY/v27Tm+sg8ZV6VKFdy9exf+/v7IyMjAsWPHEBUVhalTp+LMmTM53owqFApx8uRJbNmyBY0aNUJYWBgOHTqEly9fwt3dvVAbcySND7m1Zkr4+PjAwsIC79+/x6lTp5Ra9ooVK1ClShWEhobi/PnzaNy4Me7cuSNNMH/8PgkEAuzduxdbtmyBq6ur9FwtFAoxadIk3Lt3D1WqVMn/huYiODgY3bp1w+fPn7Fnzx5s3rw5z8dgF1ccy+8tmISUEVFRUbC3t4etrS3ddEGKpSFDhmDTpk1YsmQJfvnlF77DIaTEyszMhJOTEyIiInD79m3pzZfk5xXbFk1CCCHiHzyKbtjYsWMHtmzZotSQWYQQsQcPHsiNs5uSkoIJEyYgIiICNWvWpCRTxYplH01CCCFix48fx/jx4+Hi4gJbW1ukp6fjyZMnePHiBTiOw4oVK3i/s5mQkmLevHk4ffo0XFxcYGlpiU+fPiE8PBxxcXHQ19eXjr5CVIcSTUIIKcaaNm2K3r174+rVq3j69ClSU1NhamoKX19fjB8/Xm6gfUJIzvr06YO0tDTcv38fd+7cAWMMVlZW8PPzw5QpU/L9yE2SN+qjSQghhBBCCgX10SSEEEIIIYWCEk1CCCGEEFIoqI8mD7KyshAbG4ty5coV2jhrhBBCCFEtxhi+ffsGS0tLCATUVqcMSjR5EBsbq/C5s4QQQggp/t68eZOvh3WUZZRo8qBcuXIAxDuq5AkthBBCCCneEhMTYWNjIz2Pk7wVu0QzKysLK1aswF9//YWoqCiYmZmhW7dumD9/PnR1dVU+/8mTJ7FgwQKEh4dDS0sLzZo1wx9//AF7e3uZenPnzsW8efMUrjO/T+WQXC7X19enRJMQQggpYajbm/KKXaI5YcIErFy5Er6+vpg0aRKePHmClStXIiwsDGfPns2zT0R+5g8ODoa/vz/q1KmDJUuWICEhAUFBQdLnnlpaWsotf/ny5XLPQXV1dVXNxhNCCCGElCLFKtF89OgRVq1aBT8/Pxw6dEhabm9vj7Fjx2Lv3r3o1auXSubPyMjAmDFjYGNjg8uXL0NPTw8A0KZNG7i6umLu3LnYsGGD3Do6d+4MOzs7FW0xIYQQQkjpVaxumdqzZw8YYxg/frxM+ZAhQ6Cjo4Ndu3apbP6LFy8iNjYWgwcPliaZAODs7AwvLy/s27cPGRkZCteTmJiIzMzM/G0cIYQQQkgZU6wSzdu3b0MgEMDNzU2mXCgUwtnZGbdv31bZ/JL/N2rUSG45DRs2RGJiIp49eyY3rXbt2jAwMIBQKIS7uzv++eefPLcrLS0NiYmJMi9CCCGEkNKuWCWasbGxMDU1hZaWltw0KysrxMfHIz09XSXzx8bGSssV1QWAmJgYaZmhoSGGDh2KVatW4ejRo1i0aBGio6PRrl07bNu2LdftWrRoEQwMDKQvGtqIEEIIIWVBseqjmZycrDBJBMStkpI6mpqaPz1/cnIyACisn72uxI+X4wFg4MCBqFWrFiZMmAB/f3+ZS/DZTZ8+HRMnTpT+LRkegRBScCKRKMfuLYQQkh8aGhpQU1PjO4xSqVglmjo6Ovj48aPCaampqdI6qphf8m9aWlqB1gUAJiYmGD58OObOnYtr166hZcuWCutpaWnlmAATQvKHMYb3798jISEBjDG+wyGElAIcx8HAwAAVKlSgoYtUrFglmpaWlnj8+DHS0tLkErOYmBiYmprm2JqZ3/klQxfFxMTA0dFRri6g+LL6jyR3oMfHx+dZlxDy8xISEvD161eYmZlBV1eXTgqEkJ/CGMP3798RFxcHbW1tGBoa8h1SqVKsEs369evjzJkzuHXrFjw8PKTlqampuH//Ppo2baqy+evXrw8AuH79Opo3by6znBs3bkBfXx8ODg55xvz8+XMAQPny5fPeQELIT2GM4ePHj9DX15cbz5YQQgpKW1sbaWlp+PjxIwwMDOgHrAoVq5uBunfvDo7jEBQUJFO+ceNGJCcno3fv3tKyly9fIiIiosDze3p6wsLCAps2bUJSUpK0PDw8HBcuXEDXrl2hoaEBAMjMzERCQoJcvG/evMG6detgYmICd3f3gm626ohEwIULwJ494n9FIr4jIkSlRCIRRCIRPVGLEKJy+vr60mMMUZ1i1aLp5OSEUaNGYfXq1fDz80Pbtm2lT/bx9PSUGay9WbNmiI6OlumjlZ/5NTQ0sGLFCnTv3h0eHh4YMmQIEhMTsXz5cpiZmck8bjIpKQn29vbo3LkzHB0dYWRkhKdPn0qT1D179kBbW7to3qScBAcD48YBb9/+V2ZtDaxYAfj58RcXISokGb9WXb1YHboIIaWA5LiSmZlJxxhVYsVMZmYmW7p0KXNwcGCamprM0tKSTZgwgX379k2mnq2tLVMUvrLzSxw7dow1aNCAaWtrM0NDQ9alSxf24sULmTqpqals0KBBrFatWszQ0JCpq6uzChUqsC5durCbN2/mexsTEhIYAJaQkJDveRU6dIgxjmMMkH1xnPh16JBq1kMIz1JSUtjjx49ZSkoK36EQQkoZZY4vKj9/lwEcY3TbZlFLTEyEgYEBEhISfv4SoEgE2NnJtmRmx3Hils3ISICGbiAlXGpqKiIjI2Fvby8dhowQQlRBmeOLSs/fZUSx6qNJCuDy5ZyTTEDctvnmjbgeIYQQQkgRokSzpHv3TrX1CCFESRcuXADHcXk+HY0QUnZRolnSWVioth4hpFiQJHHZX3p6eqhbty6WL18uvTGK5OzH9y/7a/HixXyHl6egoCBK4kmJR7dVlXQeHuI+mDEx4svkipQvL65HCClxevbsibZt20qfiLRjxw5MnDgRT548wYYNG/gOr9hzdnbGpEmT5MpdXFx4iCZ/goKCYGdnh/79+/MdCiEFRolmSaemJh7CyN9ffOOPomQzIQE4dgzo3LnIwyOE/Jy6deuiT58+0r9HjhyJ6tWrY9OmTfjtt99gZmbGY3TFn5WVlcz7p2oZGRkQiUR0cxohOaBL56WBnx9w8CDw4yMzbWyA3buBDh0AX19gwYKcWz0JISXioQe6urpo2LAhGGN4+fKltDwrKwu//fYbmjZtigoVKkBTUxMVK1bEiBEj8OnTJ5llREVFgeM4zJ07F8ePH0f9+vUhFAphYWGByZMnK7wsf/ToUbi4uEAoFMLGxgazZ89GRkaGwhjj4+MxatQo2NjYQFNTEzY2Nhg1apRcHNu2bQPHcTh37hzmz58PW1tbaGtro0GDBrhx4wYA4OLFi2jSpAl0dXVhYWGBX3/99WffQjlRUVHo27cvypcvDy0tLVSuXBkzZsxAcnKyTL25c+eC4zg8evQIEydOhLW1NYRCoTTWtLQ0LFy4EDVr1oRQKIShoSE6dOiAsLAwmeVkZWUhKCgItWvXRrly5aCvr49q1aph0KBB0veU4zhER0fj4sWLMpf8o6KiVL79hBQmatEsLfz8gE6dxHeXv3sn7pPp4SFu8ezZE6hVC5g9G3j4ENiyBdDR4TtiQoqXEvTQA0mCaWxsLC1LT0/HkiVL0KVLF3Tq1Am6urq4ffs2Nm/ejCtXruDu3bvQ1NSUWc7Jkyexdu1aDB8+HAMHDsTRo0exdOlSGBkZYcaMGdJ6hw8fRpcuXWBnZ4c5c+ZAXV0dW7duxYkTJ+RiS0hIgLu7O168eIGBAweibt26CAsLw7p163D+/HncunUL5cqVk5ln2rRpEIlEGDduHNLT0/Hnn3+iZcuW2LFjBwYNGoShQ4eid+/e2L9/P+bMmQN7e3ulWykzMjIQHx8vUyYQCKTvXXR0NNzc3JCQkICRI0eiatWquHDhAhYtWoSrV6/i3LlzcoN39+7dG9ra2pg0aRI4joOFhQUyMjLQunVrXLt2DX379sXo0aORkJCAjRs3onHjxrh06RLq1asHAPjtt98wZ84cdOjQAcOHD4eamhoiIyPxv//9D2lpadDQ0MDOnTsxYcIEmJqaYubMmdJ1Uws2KXH4HcazbOJtwNeDBxnT0WGsbl3GXr8u2nUTogKFNmB7MXzoQWhoKAPA5s2bx+Li4tjHjx/Zv//+y0aOHMkAMDc3N5n6WVlZLDk5WW45mzZtYgDYvn37pGWRkZEMANPR0WGRkZEyy6hZsyarUKGCtCwzM5PZ2NgwExMTFhcXJy3/+vUrq1ixIgPAtm7dKi2fMWMGA8DWrFkjE8fq1asZADZr1ixp2datWxkA5uLiwtLS0qTlR48eZQCYuro6u337trQ8LS2NVahQgTVs2FCJd5AxAApf5cuXl9bp1asXA8BOnDghM+8vv/zCALBNmzZJywIDAxkA5unpyTIyMmTqL1u2jAFgp06dkilPSEhgNjY2zNPTU1rm4uLCHB0d84zf1tZWZj5SuGjA9sJBl87Lki5dgGvXgPh4oH594Pp1viMihH8ikbglU1G3EknZ+PG8XUYPDAyEmZkZzM3NUbt2baxduxZ+fn44evSoTD2O46SPwhWJRPj69Svi4+Ph4+MDALh586bcsjt37gw7OzuZZXh7e+P9+/dISkoCANy9exdv3rzBgAEDYGpqKq1rYGCA4cOHyy3z8OHDMDMzw9ChQ2XKhw0bBjMzMxw+fFhunhEjRsi0tnr8/82LDRo0kLYCAoCmpibc3Nzw/PlzxW+WAg0aNEBISIjM68CBAwDEl7D/97//wcXFBW3btpWZb/r06RAIBArjHT9+vFwr565du1C9enW4uroiPj5e+kpPT0eLFi1w5coVpKSkABC/dzExMbhy5YrS20FISUWXzsuaOnWA27fFNw95eQEbNgABAXxHRQh/8vPQAy+vIgtLYujQoejatSsyMjLw4MED/P7773j79q3Cm0/279+PP//8E2FhYXL9J798+SJXv1KlSnJlJiYmAIBPnz5BT08Pr169AgBUr15drm6NGjXkyiIjI1GvXj25RExdXR0ODg64d+9ennEYGRkBAOzt7eXqGhkZyfX1zI2pqSmaN2+ucFpcXBySkpJQs2ZNuWnGxsawsLCQbn92Dg4OcmVPnjxBSkpKrpe24+PjYWNjg4ULF6Jz587w8PCApaUlvLy80K5dO/j7+8t1byCkpKNEsywyNwfOngVGjQL69wcePAB+/50eUUnKpmL+0IOqVatKE6U2bdqgSZMmaNKkCYYPH469e/dK6wUHB6N79+5wc3PDihUrYGNjA6FQCJFIhNatWyMrK0tu2Wq5fOdZEd44mFMcucXHJx0FfdwZY3BycsKyZctynE+ShDZq1AgvX77E6dOnERoaitDQUPz9999YsGABrly5ItP3lpCSjhLNskpTU9yaWbs2MGEC8OgRsHcvYGDAd2SEFK0S9tADd3d39O3bFzt27MDYsWPh7u4OANi5cyeEQiFCQ0NlEqGIiIifWp+ktVHRch4/fqyw/tOnT5GZmSnTqpmZmYlnz54pbEXli5mZGcqVK4dHjx7JTfvy5QvevXsHZ2dnpZZVtWpVxMXFwcfHBwJB3r3S9PT00KVLF3Tp0gUAsHbtWowaNQqbN2/G5MmTAYi7MhBS0lEfzbKM44AxY4BTp4AbN4AGDYB89H0ipFSQPPQgp5M6x4mHCitGDz2YPXs21NTUMGfOHGmZmpoaOI6TablkjGHBggU/tS5XV1dYW1tj69atMndvJyYmYv369XL1O3fujLi4OGzatEmmfOPGjYiLi4Ovr+9PxaNKAoFAOvzQqVOnZKYtXrwYWVlZSsfbr18/vH//PscWzQ8fPkj//+Nd8IB4vFQA+Pz5s7RMT09P5m9CSiJq0SRA8+bArVtAx46Amxuwfz/QogXfURFSNHJ76IEk+QwKKlZdS6pUqYIePXpg9+7duHz5Mjw8PODv749Dhw7Bx8cH/fr1Q0ZGBo4cOSI3FmR+qampYfny5ejWrRvc3NwwZMgQqKurY8uWLTAxMcHr169l6k+ZMgUHDhzAqFGjcO/ePbi4uCAsLAybN29GtWrVMGXKlJ+KR9UWLlyIkJAQdO7cGSNHjkSVKlVw6dIl7Nu3D02bNkWAkn3Yx40bh5CQEEyePBnnz5+Hj48P9PX18fr1a5w7d07a2gwAjo6OaNiwIRo0aABLS0u8e/cOGzZsgKamJnr06CFdZsOGDbF582bMnj0bjo6O0sRYV1e3UN4LQgoFz3e9l0nFdniEr18Za9OGMTU1xlasYCwri++ICJFRaMMbMSYewsjaWnZ4IxsbXoY2Yuy/4Y2WLFmicPrjx4+ZQCBgXl5e0rINGzYwR0dHpqWlxSpUqMCGDBnCPn36xACwgIAAaT3J8EaBgYFyy5UM4ZN92CPGGDt06BCrU6cO09TUZNbW1mzWrFnszJkzcsMbMcbYx48f2YgRI5iVlRVTV1dnVlZWbOTIkTLDIzH23/BGoaGhcnH8GLNEQEAAU/bUBYC1a9cuz3qvXr1iffr0YWZmZkxDQ4PZ29uz6dOns+/fv8vUy+m9kcjIyGArVqxg9erVYzo6OkxHR4dVqVKF9erVi50+fVpab9GiRczDw4OZmZlJ309/f3929+5dmeV9+PCB+fn5MSMjI8ZxXK7rJj+PhjcqHBxj9KiYopaYmAgDAwMkJCRAX1+f73BkiUTAtGnA0qXAoEHAmjWAlhbfURECAEhNTUVkZCTs7e0L55F/IpHihx4QQko9ZY4vxfr8XUzRpXMiS00NWLIEcHIChgwBIiLET0wxN+c7MkIKn5oaL0MYEUJIaUU3AxHF+vUDLl4EXr4UD+5+/z7fERFCCCGkhKFEk+SsYUPx4O5mZkDjxsChQ3xHRAghhJAShBJNkjtra+DSJfEd6f7+wLx5gIKBnwkhhBBCfkR9NEnedHSAv/8GatUCZs0CHj4Etm0DaIgNQgghhOSCWjSJcjgOmDkTOHIE+OcfoEkT4Ifx8wghhBBCsqNEk+RPp07A9evA16/im4SuXuU7IkIIIYQUU5RokvxzchI/Sah6dcDbG9iyhe+ICCGEEFIMUaJJCsbMDAgJAQYOFA/sPmECkJnJd1SEEEIIKUboZiBScJqawPr1QO3awNixwOPHwN69gJER35ERQgghpBigFk3y80aOBM6cAe7cEY+9+fQp3xERQgghpBigRJOoho+PuN+mujrQoAFw+jTfERFCCCGEZ5RoEtWpXFl8R7qHB9C2LbBsGcAY31ERQgjhQf/+/cFxnFJ1o6KiwHEc5s6dW7hBkSJHiSZRLX198VibkycDkyaJbxZKS+M7KkJKpFevXmHo0KGoXr06dHR0YGRkBEdHRwQEBCA0NJTv8ArV169fMXfuXFy4cEGp+l27dgXHcbh//36OdRhjsLe3h6GhIVJSUlQTaDb379/H3LlzERUVpfJlK4PjOHAch1q1auVYx9nZWVqPkKJANwMR1VNTAxYvFg+DNGgQ8OwZEBwMlC/Pd2SElBh37tyBp6cnNDQ00K9fP9SsWRMpKSl4/vw5zpw5g3LlysHb25vvMAvN169fMW/ePACAl5dXnvUHDRqEgwcPYuvWrVixYoXCOqGhoYiKisKwYcOgra2tynABiBPNefPmwcvLC3Z2dipfvjKEQiEePXqE27dvo379+jLT7t69i/DwcAiFQqSmpvISX05sbW2RkpICdXVKS0ob+kRJ4endG6haFejcGahXDzh6FKhbl++oCCkR5s2bh+TkZNy/fx916tSRm/7+/Xseoip8KSkp0NDQyPd8LVu2hI2NDXbv3o0lS5ZAU1NTrs7WrVsBiJPSkkYkEiEtLQ06Ojq51vPw8MC9e/ewdetWuURzy5YtMDU1Rd26dXHmzJnCDDffOI6DUCjkOwxSCOjSOSlcbm7A7duAhYX4sZX79/MdESE5EomACxeAPXvE/4pE/MXy/PlzmJiYKEwyAaBChQrS/+fWv23u3LngOE7mcq6k71xcXBz69esHExMT6OrqolmzZrh3757M/NmXvWfPHtSuXRtCoRAVK1bE3Llzkalg/Nx///0Xvr6+MDExgVAoRI0aNfDHH39A9MMbmj2OgQMHonz58tDV1cWuXbtgb28PQJxwSy715tZKKBAI0L9/f3z69An/+9//5KYnJibi0KFDqFWrljQBS0tLw8KFC1GzZk0IhUIYGhqiQ4cOCAsLk5ufMYaNGzeiQYMG0NPTg56eHpycnDBnzhzp+zxgwAAAgLe3tzTm/v37S5cRHx+PUaNGwcbGBpqamrCxscGoUaPw6dMnmXVt27YNHMfh7Nmz+PXXX1G5cmUIhULsV+L4qampid69e2PPnj0yrZZpaWnYs2cPevfurTCRj4iIwMiRI1GzZk2UK1cOOjo6cHV1xaZNmxSuJzExETNnzoSjoyOEQiFMTEzQpEkT7N27V65uQkICRowYAXNzcwiFQjRu3Bg3b96UqaNoH85edvz4cdSvXx9CoRAWFhaYPHmywn3v+fPn6Nu3LywsLKCpqQk7OztMnjwZ379/z/O9I4WDWjRJ4bOyAi5eBAYPBrp3Bx4+BObOBQT0O4cUH8HBwLhxwNu3/5VZWwMrVgB+fkUfT+XKlfH06VMEBwfDr5ACaN26NYyNjTF37ly8f/8eq1evhqenJ65fvy7Xz+9///sfXr16hVGjRqFChQr43//+h3nz5iE6OlraUgjIXvKX1D127BimTp2K8PBw7N69Wy6OFi1aoEKFCpg9eza+f/+ONm3aYPny5ZgwYQJ8fX2l26+np5fr9gwYMAALFizA1q1b4e/vLzNt7969SElJkbZmZmRkoHXr1rh27Rr69u2L0aNHIyEhARs3bkTjxo1x6dIl1KtXTzp/3759sXv3bjRo0AAzZ86EoaEhIiIicPDgQcyfPx9+fn549+4dNmzYgBkzZsDR0RGA+HMExMmWu7s7Xrx4gYEDB6Ju3boICwvDunXrcP78edy6dQvlypWTifmXX35BRkYGhgwZAn19fVSrVi3X7ZcYOHAgVq5cicOHD6Nnz54AgMOHD+PLly8YOHAgZsyYITfPhQsXcOnSJbRv3x729vb4/v07Dhw4gCFDhiAuLg7Tp0+X1v369SuaNGmCR48ewd/fHyNGjIBIJEJYWBiOHz+OHj16yCy7VatWMDMzw5w5c/Dp0ycsW7YM7dq1Q2RkpNw2K3Ly5EmsXbsWw4cPx8CBA3H06FEsXboURkZGMtty9+5d+Pj4wNDQEMOGDYOVlRXCw8OxcuVKXL16FRcvXixQazn5SYwUuYSEBAaAJSQk8B1K0crKYmzxYsY4jjFfX8a+feM7IlLCpKSksMePH7OUlBSVLvfQIfFuKR4m4b8Xx4lfhw6pdHVKuXbtGtPQ0GAAWNWqVdmAAQPY2rVr2ePHj+XqRkZGMgAsMDBQblpgYCADwCIjI6VlAQEBDADz9fVlWVlZ0vI7d+4wjuNYq1at5JYtEAjY3bt3peVZWVmsc+fODAC7fv26tNzd3Z2pqamx8PBwmbpdu3ZlANjZs2fl4ujdu3e+tik3Pj4+TE1NjcXGxsqUN2zYkGlqarK4uDjGGGPLli1jANipU6dk6iUkJDAbGxvm6ekpLdu3bx8DwPr06cNEIpFM/ex/b926lQFgoaGhcnHNmDGDAWBr1qyRKV+9ejUDwGbNmiW3HAcHB/b9+3eltx0Aa9euHWOMsbp167IWLVpIp7Vo0YK5uroyxhhr164d+/H0n5SUJLc8kUjEPD09mb6+PktPT5eWjxgxggFgf/31l8J5JCSf74gRI2Tq7N+/nwFg69evl5Yp+rwlZTo6OjL7b1ZWFqtZsyarUKGCzHJr167NqlWrxhITE2XKg4ODGQC2detWuXizU+b4UmbP3z+BmpRI0eE4YOpUcV/NkBCgcWOAp7szCZEQicQtmYpG4pKUjR9f9JfRGzVqhLt37yIgIAAJCQnYunUrRo4ciRo1aqBp06Z49erVT69jypQpMncfu7q6okWLFjh79iySkpJk6rZo0QJ1s/Wx5jgOU6ZMASBuLQOAjx8/4tq1a+jYsSNq164tU3fmzJkydbP75ZdffnpbJAYNGgSRSIQdO3ZIyyIiInDjxg107NgRpqamAIBdu3ahevXqcHV1RXx8vPSVnp6OFi1a4MqVK9I70yWtsEuXLoXghysxP/6dk8OHD8PMzAxDhw6VKR82bBjMzMwUvi8jRozIs09mTgYOHIhz587hzZs3ePPmDc6dO4eBAwfmWF9XV1f6/9TUVHz69AmfP39Gy5YtkZiYiIiICABAVlYW9u7dC0dHR7ltARS/HxMmTJD528fHB4D4MrcyOnfuLNNtguM4eHt74/3799L99MGDB/j333/Rq1cvpKWlyXymTZo0ga6ubrHrl1pWUKJJil6HDsCNG0BSElC/PnD5Mt8RkTLs8mXZy+U/Ygx484af3dTJyQnbtm3Dhw8fEBUVhe3bt8PDwwOXL19Gp06dkJ6e/lPLl1zeza5GjRoQiUSIjo5Wqi4AadIbGRkJAKhZs6bCdQkEAoUJsoODQ/6Dz4Gfnx8MDQ1lLudv2bIFAGQSrSdPniAiIgJmZmZyry1btkAkEiE+Ph6AOCGysLBA+Z8YOSMyMhLVqlWTu6taXV0dDg4OKn9fevXqBQ0NDWzfvh3btm2Dpqam9DK6IklJSfjll19QsWJFaGtrw9TUFGZmZtIfCF++fAEg7mf65csXODs7Kx1LpUqVZP42MTEBALm+qcrOr2gZT548AQAEBgbKfZ7m5ub4/v07Pnz4oHTMRHWojybhR82a4icJde0KNGsGrF0r7sNJSBF790619QqLra0t+vXrh759+8LDwwNXr17FrVu30KRJk1zHRFR0w0RxU9BWO0WEQiF69eqFtWvX4tq1a2jQoAF27twJa2trtGrVSlqPMQYnJycsW7Ysx2WZmZmpLK6C+Jn3xcjICJ07d8a2bdvAGEPnzp1hZGSUY/1evXrh+PHjGDp0KJo2bQoTExOoqanh5MmTWL58ObKysgoci5qamsJypuQDPXKaP/syJP9OmjQJrVu3Vlg3t+0nhYcSTcIfExPxoyrHjweGDAH+/Vf8NCEaR40UIQsL1dYrbBzHoUGDBrh69SpiYmIAAMbGxgCAz58/y9XP7RL7kydP0LBhQ5myx48fQ01NDba2tnJ1f/T48WMA/7U4Se4Uf/TokVzdiIgIZGVlKWydUuRnBhQfNGgQ1q5di61bt+Lz5894//49Zs6cKXNZt2rVqoiLi4OPj0+el78dHBxw9OhRfPjwIddWzdxirlSpEp4+fYrMzEyZVs3MzEw8e/ZM6fclPwYOHIh9+/YBANavX59jva9fv+L48ePo27evXL2zZ8/K/G1qagojIyOEh4erPN6fUbVqVQDipLR58+Y8R0Oyo0vnhF8aGsCaNcC6deJXmzaAgpMlIYXFw0N8d3lOOQLHATY24npFKSQkRGFrZEpKirSvmeTSdbly5VChQgWcP39eppXo1atXOHLkSI7r+OOPP2Tq37t3D2fPnkWzZs3k7vAOCQmRGfqIMYY//vgDgLgPHQCYm5vD3d0dx44dw8OHD2XqLlq0CADg6+urzOZL168oec5L3bp14ezsjH379mHNmjXgOE6uf2K/fv3w/v37HFs0s19m7d27NwBxn9YfW/ayv3+5xdy5c2fExcXJDRe0ceNGxMXFKf2+5Efz5s3x66+/YsGCBWjWrFmO9SQthj+2ML57904uXoFAgJ49e+Lx48fYvHmz3LKUbaVUNRcXF9SqVQvr169X+OMqMzOzQPsS+XnUdESKh+HDgerVAX9/oEED4H//AxT0CSNE1dTUxEMY+fuLk8rs50lJ8hkUJK5XlCZMmIBPnz6hY8eOcHJygo6ODt68eYO///4bz549Q79+/eDk5CStP3r0aMyaNQtt2rRB586dERsbi/Xr16NWrVq4ffu2wnVER0ejVatW6NixI969e4fVq1dDW1sbS5Yskatbp04d+Pj4YNSoUbCwsMDRo0dx9uxZ9O3bF40aNZLWW7FiBTw9PeHh4SEd3uj48eM4ffo0evXqlWvCk52JiQmqVKmCvXv3onLlytIxNjt06KDU/IMGDcKYMWNw6tQpeHl5ybUYjhs3DiEhIZg8eTLOnz8PHx8f6Ovr4/Xr1zh37hyEQqH0MZ9du3ZF9+7dsWPHDjx//hwdO3aEkZERnj17htOnT0uT6vr160MgEOC3337Dly9foKurC3t7ezRo0ABTpkzBgQMHMGrUKNy7dw8uLi4ICwvD5s2bUa1aNemNVaokEAgwa9asPOuVK1cOLVu2xK5du6CtrY369esjOjoaf/31F+zt7eX6Ui5YsADnz5/H4MGDcebMGTRp0gSMMYSFhSEzMxM7d+5U+bbkheM47Ny5Ez4+PqhduzYGDhyImjVrIjk5GS9evEBwcDAWLVokM64pKSK83OtextHwCLl4+ZKxWrUYK1eOsRMn+I6GFDOFNbwRY+IhjKytZYc3srHhZ2gjxhg7ffo0GzlyJKtduzYzMTFhampqzNjYmHl5ebHNmzfLDbOTkZHBJk+ezCpUqMC0tLSYi4sL+9///pfr8EYfP35kffr0YcbGxkxbW5t5e3uzO3fuyCw3+7Azf//9N3NycmKamprM2tqazZ49W2bYG4n79++zTp06MSMjI6apqcmqV6/Ofv/9d5aZmSlTTxJHTm7evMnc3d2Zjo4OA8BsbW2Vfv8+f/7MhEIhA8B27NihsE5GRgZbsWIFq1evHtPR0WE6OjqsSpUqrFevXuz06dMydUUiEVu9ejVzcXFh2traTE9Pjzk5ObG5c+fK1Nu2bRtzdHSUDk0VEBAgnfbx40c2YsQIZmVlxdTV1ZmVlRUbOXKkdMglidyGScoNsg1vlBtFwxvFxcWxQYMGMQsLC6alpcVq1arFNmzYkGMsX758YZMnT2aVK1dmGhoazNjYmDVp0oTt27dPWie3z/fH9ya34Y2UHbaLMcaioqLYsGHDmK2trTSuunXrsmnTprHXr1/n+r7Q8EaFg2OMp3buMiwxMREGBgZISEiAvr4+3+EUP9++AX37ils1f/8d+OWXnK9rkjIlNTUVkZGRsLe3L5TH1YlE4rvL370T98n08Cj6lsyi0L9/f2zfvl2py5xRUVGwt7dHYGCgwicPEVJaKHN8ofN3/tGlc1L8lCsnfkzLnDnAlCnAgwfAhg0APQeXFDI1NcDLi+8oCCGk9KCbgUjxJBAACxaIHzp94ID47M/3+DKEEEIIyRdKNEnx1qPHfyNq168P3LnDd0SEEEIIURIlmqT4q1cPuH1bPAaNhwewdy/fERFSokkG8VaGnZ0dGGPUP5MQUiCUaJKSwcICuHBB/CShnj2BmTOBn3hSBSGEEEIKH90MREoOoRDYvh1wcgKmTgUePgR27RLfPEQIIYSQYodaNEnJwnHA5MnA8ePiFk53dyAyku+oCCGEEKIAJZqkZGrbFrhxA0hNFd8kdOEC3xERQggh5AeUaJKSy9ERuHkTcHEBWrQA1q/nOyJCCCGEZEOJJinZjI2Bf/4BRowQv0aNAjIy+I6KEEIIIaBEk5QG6urAypXipwdt3Ai0agV8+sR3VIQQQkiZR4kmKT2GDAHOnRM/stLNDXj0iO+ICCGEkDKNEk1Sunh4iAd319MDGjYEjh3jOyJCCtWFCxfAcRy2bdvGdyikCHAch/79+/MdBiFKo0STlD52dsDVq+IbhDp1AhYvBpR8CgohxYUkgVy6dCnfoRQpyXZnf+np6aFu3bpYvnw5MjMz+Q6REJIPxS7RzMrKwvLly1G9enUIhULY2Nhg0qRJ+P79e6HMf/LkSbi7u0NXVxfGxsbo2rUrIpUYl3HdunXSg2B8fHy+tpEUAT094OBBYPZsYPp0oE8fICWF76gIUbmmTZsiJSUFffv25TsUlerZsyd27tyJHTt2IDAwEBkZGZg4cSJGjhzJd2i8SklJwcaNG/kOgxClFbtEc8KECZg4cSJq1KiBVatWoWvXrli5ciU6dOiALCUeOZif+YODg9G+fXukpKRgyZIlmDx5Mi5duoTGjRsjNjY2x3XExsZi2rRp0NPT++ntJYVIIADmzQP27wcOHwY8PYGYGL6jIkSlBAIBhEIh1NTU+A5FKSkpKUq1StatWxd9+vRB3759MXnyZNy4cQPW1tbYtGkT4uLiiiBSxb59+8bbugFAKBRCQ0OD1xgIyRdWjDx8+JBxHMf8/PxkyleuXMkAsN27d6ts/vT0dGZpackqVqzIvn37Ji0PCwtjAoGADRkyJMf1dO7cmbm4uLA+ffowACwuLi4/m8kSEhIYAJaQkJCv+chPuHuXMWtrxiwsGLt5k+9oSAGlpKSwx48fs5SUlEJZfqYok4VGhrK///2bhUaGskxRZqGsRxmhoaEMAFuyZIlS9bZu3aqwbMuWLaxGjRpMU1OTVaxYkf3+++8Kl3P79m3WuXNnZmJiwjQ1NZmDgwNbsGABy8jIkKl38+ZNFhAQwKpWrcq0tbWZnp4ec3d3Z8HBwXLLDAgIYADYx48f2YABA5i5uTnjOI5FRkYWaLv9/f0ZAHb9+nWZ8tjYWDZ8+HBmY2PDNDQ0mIWFBRsyZAj78OGD3DLCw8NZixYtmI6ODjM2Nmb9+vVjcXFxDAALCAiQ1ouMjGQAWGBgINu7dy+rW7cuEwqFMnVCQkJYixYtmIGBAdPS0mJOTk5s3bp1cuu8evUqa926NStfvjzT0tJilpaWrE2bNjLb8enTJzZ+/HhWqVIlpqWlxYyNjVndunXZH3/8IbOsH+OU2LhxI3NxcWFCoZDp6+uzFi1asMuXL8vVk8x/7do11rRpU+n7MGjQIJlzYVmkzPGFzt/5V6xaNPfs2QPGGMaPHy9TPmTIEOjo6GDXrl0qm//ixYuIjY3F4MGDZVomnZ2d4eXlhX379iFDwXiMhw8fxv/+9z+sX7++xLQgEAB16wJ37oj7bzZtCuzezXdEpJgJfhIMuxV28N7ujV7BveC93Rt2K+wQ/CSY79AKbP369Zg/fz569uyJP//8ExYWFpg6dSr+/vtvmXonTpxA48aN8ezZM0yaNAkrV65Eo0aNMGfOHPTs2VOm7uHDhxEREYFu3bphxYoVmDlzJj5//gw/Pz+55Uq0aNECsbGxmD17NhYtWlTgq0EvX74EABgbG0vLXr9+jXr16uHgwYPo1asX1qxZg759+2Lv3r1o3LgxEhISpHWfP38ODw8PXL9+HWPHjsW8efMQFxeH1q1b57jOI0eOYMSIEWjdujVWrlyJNm3aAAA2bNiAli1bIikpCTNnzsSyZctQuXJljBgxApMnT5bO//TpU7Ro0QLPnj3DuHHjsHbtWowePRocxyE8PFxar2vXrli9ejXatm2LVatWITAwEG5ubrigxFPPpk6diiFDhkBDQwMLFy7EpEmT8PjxY3h7e+PkyZNy9e/fv4/27dujfv36WLZsGVq2bInNmzdj4sSJea6LkHzjO9PNrmXLlkwgELDU1FS5ae7u7szU1FRl8y9cuJABYCEhIXJ1Z8yYwQCwhw8fypQnJCQwS0tLNmLECMbYf7/WqUWzBElNZax/f8YAxqZOZSyTvxYrkn+F1aJ56PEhxs3lGOZC5sXN5Rg3l2OHHh9S6fqUoYoWTQsLC/b161dp+ffv35mpqSlr2LChtCwlJYWVL1+eeXh4yLVeLlu2jAFgoaGh0rKkpCS5GL5//84cHByYo6OjTLnkGNm7d29lNlkm9nnz5rG4uDj28eNH9u+//7KRI0cyAMzNzU2mfseOHZmZmRl78+aNTPnt27eZmpoaCwwMlJZ17dqVAWBXrlyRqdutW7ccWzTV1dXZ48ePZerHxsYyLS0t1rNnT7n4x44dywQCAXv58iVjjLEVK1YwAOxmLldSvn79ygBIzy25+THOiIgIxnEca9y4MUtLS5OWx8TEMAMDA2Zra8sysx3nADCO49iNGzdkltu2bVumrq5epls1qUWzcBSrFs3Y2FiYmppCS0tLbpqVlRXi4+ORnp6ukvklfTCtrKwU1gWAmB/6802dOhVZWVlYtGiR8hsFIC0tDYmJiTIvwhMtLWDLFmDZMmDJEqBzZ4A+jzJNlCXCuFPjwCA/MoGkbPyp8RBliYo6tJ82YMAAGBgYSP/W0dFBw4YN8fz5c2lZSEgIPnz4gAEDBuDr16+Ij4+Xvtq2bQsAOHPmjLS+rq6u9P/Jycn49OkTkpOT4ePjgydPnig8vv3yyy/5jj0wMBBmZmYwNzdH7dq1sXbtWvj5+eHo0aPSOgkJCTh+/Dg6duwIoVAoE7udnR2qVKkijV0kEuHkyZNwc3ND48aNZdY1adKkHONo164dHB0dZcoOHjyItLQ0DBo0SGad8fHx0vsBzp49CwDS9//o0aNITU1VuA5tbW1oaWnh5s2biIqKytf7dPToUTDGMGXKFGhqakrLLS0tMWDAAERHRyMsLExmnkaNGqFBgwYyZT4+PsjMzMz3+gnJS7FKNJOTkxUmiYC4A7Skjirml/yrqL6idV29ehV//fUXli1bJnPgVsaiRYtgYGAgfdnY2ORrfqJiHAdMmACcOAFcviweb/PFC76jIjy5/Poy3ia+zXE6A8ObxDe4/PpyEUalGpUqVZIrMzExwadsT8568uQJAGDgwIEwMzOTeVWvXh0A8OHDB2n9jx8/YujQoShfvjx0dXVhamoKMzMzrF+/HgDw9etXuXU6ODjkO/ahQ4ciJCQEJ0+exO+//w5jY2O8fftWenwGxJels7KysHnzZrnYzczM8PTpU2nscXFx+P79O6pVqya3LkVlucUuec+aN28ut84WLVoA+O8969GjB5o3b46FCxfC2NgYPj4++P333xEdHS1dnqamJoKCgvDw4UPY29ujZs2aGDNmDM6dO5fn+yQZJaVmzZpy0yRlr169kinPab8AILNvEKIK6nwHkJ2Ojg4+fvyocJrkl6COjo5K5pf8m5aWlmfd9PR0DB06FM2bN5frr6SM6dOny/R9SUxMpGSzOGjdGrh5E+jQQfwkoYMHAR8fvqMiRezdt3cqrVecKNOPnP3/GLNLliyBs7OzwjqWlpbSui1btsSTJ08wbtw41KtXDwYGBlBTU8PWrVvx999/KxwdJLfjdk6qVq2K5s2bAwDatGmDJk2aoEmTJhg+fDj27t0rE3ufPn0QEBCgcDna2tr5Xnd2imKXrHfHjh2wsLBQOJ8kmdPS0kJISAhu3bqF06dP49KlS5gzZw7mzp2Lv//+G76+vgCA4cOHo1OnTjhx4gQuXryIgwcPYvXq1ejevbt0e1Ult/2C0ZjDRMWKVaJpaWmJx48fIy0tTa6lMSYmBqampjKXBn5mfsmBMyYmRu6yiOSSueQS+po1axAREYE///wTL7K1fEmGuYiMjERiYqLCX4mA+ECTU0sr4Vm1auJks3t3oGVLYMUKYORIcasnKRMsyilOFApar6SpWrUqAPElcUlil5N///0X4eHhmDNnDubNmyczbdOmTYUWIwC4u7ujb9++2LFjB8aOHQt3d3dUqVIFHMchPT09z9jNzMygq6uLp0+fyk1TVJYbyXtmamqa53ol3Nzc4ObmBgB48+YNXFxcMGvWLGmiCQAWFhYYPHgwBg8eDJFIhL59+2LPnj2YNGkS6tevr3C5kvPOo0ePULlyZZlpjx8/lqlDCB+K1aXz+vXrIysrC7du3ZIpT01Nxf3791GvXj2VzS/50l6/fl1uOTdu3IC+vr70kkl0dDSysrLQpk0bVK1aVfoKDhbfjerm5obatWvnf4NJ8WBkBJw8CYwdC4weDYwYAeTSF5iULh4VPWCtbw0Oin9ccOBgo28Dj4oeRRxZ0WjVqhXMzc2xePFifP78WW56SkqK9Ee1pCXsx1avhw8f4vDhw4Ue6+zZs6GmpoY5c+YAEF/ubdu2LYKDg3Hjxg25+owx6ZibampqaNOmDW7duoWrV6/K1Pvzzz/zFUe3bt2gpaWFwMBApCh4EERCQoL0apmiB3pYW1vDzMxM+n4nJyfLdQtTU1OTnlcUfS4SHTt2BMdxWLJkicxIKe/evcPWrVtha2sLFxeXfG0fIapUrFo0u3fvjoULFyIoKAgeHv8d1Ddu3Ijk5GT07t1bWvby5UtkZGRI+xDld35PT09YWFhg06ZNmDBhgnS4jfDwcFy4cAEDBgyQDoo7YMAANGnSRC7eNWvW4MKFC9iyZQuMjIxU90aQoqeuLr5BqFYtYPhwICJCfCnd1JTvyEghUxOoYUXrFfDf7w8OnMxNQZLkM6h1ENQE/Axndu7cOYU3kZiammL48OE/vXxdXV3s2LEDnTt3RrVq1TBw4EBUqVIFX79+RUREBIKDg3H48GF4eXnB0dERNWvWxB9//IHk5GRUq1YNz549w19//QUnJyfcvXv3p+PJTZUqVdCjRw/s3r0bly9fhoeHB9atW4cmTZqgadOm6NevH1xcXJCVlYVXr17h6NGj6NevH+bOnQsAWLBgAU6fPo3WrVtj9OjRsLa2xokTJ6TJKKfklQxra2usW7cOgwcPhqOjI/r27QtbW1vExcXhwYMHOHLkCB4/fgw7OzssWLAAZ86cQfv27WFvbw/GGI4dO4aIiAhMmTIFAPDs2TN4enrC19cXtWrVgpGREZ48eYJ169bB3t5e5nz2o2rVqmHy5Mn4448/0LRpU3Tv3h3fvn3Dhg0bkJSUhN27d9NQfIRfvN3vnoPRo0czAMzX15dt3LiRTZw4kamrqzNPT08mEomk9WxtbZmi8JWdnzHG9u/fzziOY87OzmzNmjVs0aJFzNzcnJUvX569ffs2z1hpeKNS6soVxszNGbOzY+zff/mOhmRTmAO2H3p8iFkvs5YZ3shmmQ0vQxsx9t8wPzm9qlWrJlMvpwHbfyQ5bv3owYMHrHfv3szS0pJpaGgwc3Nz1qhRIzZ//nz26dMnab2oqCjm7+/PTE1Nmba2Nqtfvz4LDg5mgYGBDIDMYOw5rUuZ7c5pWKfHjx8zgUDAvLy8pGVxcXHsl19+YVWrVmVaWlrMwMCA1apVi40dO5Y9evRIZv6wsDDWrFkzpq2tzYyMjFjfvn3Zq1ev5IYXyj5ge06uXLnCOnfuzMzMzKQDxXt5ebGlS5dK99HQ0FDWrVs3Zmtry4RCITMyMmJubm5s48aNLCsrizHGWHx8PBs/fjyrU6cOMzAwYEKhkFWuXJmNGzeOxcbGyqwTOQzYvmHDBubs7My0tLRYuXLlWPPmzdmlS5fk6uU0/9atW+WGsipraHijwlHsEs3MzEy2dOlS5uDgwDQ1NZmlpSWbMGGC3NheOSWays4vcezYMdagQQOmra3NDA0NWZcuXdiLFy+UipUSzVIsOpoxZ2fG9PQYO3KE72jI/ytLTwYiRefOnTsMAFu0aBHfoRAeUaJZODjG6BazopaYmAgDAwMkJCRAX1+f73BITr5/B/r3F19CX7AAmDGDbhLiWWpqKiIjI2Fvby8zzA0hykpJSZG5E50xhh49emD//v24c+cOXF1deYyO8EmZ4wudv/OvWPXRJKRY0dUF9u0Dfv0VmDULePBAPNh7AYZqIYQUD87OzvDx8YGTkxO+f/+OY8eO4fLly+jevTslmYQUAko0CcmNQAAEBopvEurXT/yc9CNHAGtrviMjhBRAp06dcOzYMezcuROZmZmwt7fHr7/+iqlTp/IdGiGlEl065wE1vZdQ9+8DnToBaWniZLNhQ74jKnPo0jkhpLDQpfPCUazG0SSkWHN2Bm7fBqpUATw9gR07+I6IEEIIKdYo0SQkP8zNgfPngb59gYAAYPJkQCTiOypCCCGkWKI+moTkl6YmsHEjULs2MGEC8OgRsGcPYGDAd2RlBvX4IYSoGh1XCge1aBJSEBwnfmTlqVPA9evi/prPn/MdVamnri7+bZyZmclzJISQ0kZyXJEcZ4hqUKJJyM9o0QK4eRNgDHBzA0JC+I6oVFNTU4OamhoSExP5DoUQUsokJiZKjzFEdShtJ+RnOTiIk80ePYA2bcTPTB8zhgZ3LwQcx8Hc3Bzv3r2DlpYWdHV1lX4+NSGEKMIYw/fv35GYmAgLCws6pqgYJZqEqIKBAXD8ODB1KjBuHPDvv8DateL+nESlDAwMkJKSgvj4eMTFxfEdDiGkFOA4DoaGhjCgvvYqR4kmIaqipgYsXQo4OQFDhwJPnwKHDonvVCcqw3EcLCwsYG5ujoyMDL7DIYSUAhoaGnTJvJBQokmIqgUEiC+n+/oC9esD//sfUKcO31GVOtSXihBCij+6GYiQwtCoEXDnDmBqCri7A8HBfEdECCGEFDlKNAkpLNbWwOXLQIcOQJcuwPz54rvTCSGEkDKCLp0TUph0dMSDuTs5AbNmAQ8fAlu3Arq6fEdGCCGEFDpq0SSksHEcMHMmcPgwcPIk4OEBvH7Nd1SEEEJIoaNEk5Ci0rkzcO0a8Pmz+Cahq1f5jogQQggpVJRoElKUatcGbt8GqlcHvL3Fl9EJIYSQUor6aBJS1MzMxI+qHDMGGDgQePAA+OMPQF0dEInENxC9ewdYWIgvs9MQPiUHfX6EECKDEk1C+KCpCaxfL27hHDcOePwY6N0bmDEDePv2v3rW1sCKFYCfH3+xEuUEB4s/S/r8CCFEimOMxlspaomJiTAwMEBCQgL09fX5Dofw7dw5cf/NpCT5aZJn7h48SMlKcRYcDPj7yw9fRZ8fIaUKnb/zj/poEsI3Ly9AT0/xNEniMn68+LIsKX5EInFLpqLf7PT5EULKOLp0TgjfLl8G3r/PeTpjwJs34svtamriVjKBQPyS/P/Hf4v7tOIQg6qmRUTIXi7P6fO7fFn8o4IQQsoQSjQJ4du7d8rV698fcHUVJy5ZWf/9m/3/uZUVdJqqlpWZyd+6VVH/Z3sZKfs5E0JIKUKJJiF8s7BQrl7fvtQixjdFSejFi0Dr1nnPO2cO8OgR0L69eBxVuhudEFIGUB9NQvjm4SG+O1ly48iPOA6wsRHXI/ziOHGCqKEh7sogFALNm+f++QGAiQng5gasWwc0aiT+cREQABw4ACQkFF38hBBSxCjRJIRvamriIXAA+WRF8ndQELWAFVd5fX4cB2zYAOzeDXz8CFy5AgwaBISFAd26AaamgI8PsGwZ8OxZ0cdPCCGFiBJNQooDPz/xEDhWVrLl1tY0NE5JoOznp6YGNG4MLFoE/PsvEBUlTlK1tcVjqFarBlStCkyYIB72Kj29yDeFEEJUicbR5AGNw0VyRE+WKdl+5vP7/h04fx44cQI4fhyIiQHKlQNathT362zTBihfvnDjJ4Tkis7f+UeJJg9oRyWE5IoxIDz8v6Tz5k1xmZubOOls1w5wccm9XyghROXo/J1/lGjygHZUQki+xMUB//wjTjpPnwYSEwFLS3HC2a6d+IYkXV2+oySk1KPzd/5RoskD2lEJIQWWkSG+oej4cfHr2TNASwvw9hYnne3bA3Z2fEdJSKlE5+/8o0STB7SjEkJU5vlz8SX2EyfEY3pmZAA1a/6XdDZqBKjTkMmEqAKdv/OPEk0e0I5KCCkUiYlASMh/iefHj4CRkXhA+fbtxf8aG/MdJSElFp2/848STR7QjkoIKXRZWcCdO//dUHTvnvj57O7u/91QVLMm3VBESD7Q+Tv/KNHkAe2ohJAiFxsLnDwpTjpDQoDkZMDWVpx0tm8vfrypUMh3lIQUa3T+zj9KNHlAOyohhFepqeL+nJIbiqKiAB0d8d3r7dsDbdvKDz5PCKHzdwFQoskD2lEJIcUGY8Djx/9dYr96VXzZ3cXlvxuK6tcXX3YnpIyj83f+UaLJA9pRCSHF1ufP4rE6jx8Xj9355Qtgbi5+MlH79uInFdFxi5RRdP7Ov59KNC9duoQzZ87gw4cPmDRpEqpXr46kpCTcu3cPtWvXhqGhoQpDLT1oRyWElAiZmcCNG+Kk88QJ4OFD8VBJTZv+17ezalW+oySkyND5O/8KlGiKRCL06tULBw8eBGMMHMchJCQEPj4+SE1NhaWlJX755RfMmDGjMGIu8WhHJYSUSFFR/w2ddP48kJYmTjQlSWeTJoCmJt9RElJo6PydfwXqdPP777/j0KFDWLZsGZ48eYLsuapQKISvry9OnjypsiAJIYQUA3Z2wKhR4rvXP30Cjh4VP5Fo3z6gWTPA1BTo2hXYvl08hichpMwr0OMiduzYgX79+mHcuHH49OmT3HRHR0dKNHkgyhLh8uvLePftHSzKWcCjogfUBGp8h0UIKY10dYGOHcUvxoD79/+7oWjAAHEdN7f/xux0dqYxOwkpgwrUohkVFYVGjRrlON3Q0BBfvnwpcFAk/4KfBMNuhR28t3ujV3AveG/3ht0KOwQ/CeY7NEJIacdx4rvUZ80S9+l8/x7YuhWwsQH++AOoW1f8/2HDgP/9D/j+ne+ICSFFpECJZrly5fD58+ccp7948QJmZmYFDorkT/CTYPjv98fbxLcy5TGJMfDf70/JJiGkaJmbAwEBwIEDQHw8cO4c0K0bEBoKdOoEmJiIx+pcs0bc75MQUmoVKNFs0qQJdu3aBUX3EX358gVbtmyBt7f3TwdH8ibKEmHcqXFgkP8sJGXjT42HKEtU1KERQoj45iAfH2DZMuDZM+DpU2DRIvGNROPHA/b2gJMTMG0acOWK+E53QkipUaBEc+bMmXj+/Dl8fHxw/PhxAEB4eDj++usv1K1bF9+/f8e0adNUGihR7PLry3ItmdkxMLxJfIPLry8XYVSEEJIDBwdgwgRxK2d8vLjV09UV2LIF8PAAypcHevcG9uwRj+lJCCnRCnQzUL169XDo0CEMHjwYA/6/0/cvv/wCxhjMzc1x+PBh1KhRQ6WBEsXefXun0nqEEFJkDAwAf3/xKysLuH37vzE7//5b/DSixo3/u6GoRg26oYiQEuanBmxPS0tDSEiIdIijqlWrolWrVtDR0VFljKWOKsfhuhB1Ad7b8+6mEBoQCi87r59aFyGEFJm3b8XDKJ04AYSEACkp4uGVJEmnlxcgFPIdJSljaBzN/KNHUPJAlTuqKEsEuxV2iEmMUdhPkwMHa31rRI6LpKGOCCElU0oKcOHCf8MnRUcDOjpAixbipLNdO8DSku8oSRlAiWb+FaiPJik+1ARqWNF6BQBxUqlIUOsgSjIJISWXtrb4WeurVwORkcCDB8CcOeJB44cPB6ysxP0858wBbt0SX4YnhBQLBU40//77bzRu3Bjm5uZQU1OTe6mrF6j7JykAP0c/HOx2EFb6VnLT1rZbCz9HPx6iIoSQQsBxQK1awNSpwOXL4icQ7d4NVKsmTkQbNAAsLMSDxh86BCQm8h0xIWVagS6dL1iwAIGBgShfvjzc3NxgZGSksN7WrVt/OsDSqLCa3rM/GchQaIgBRwegTdU22NqJPgdCSBmQmQlcvy6+vH78OPD4MaChATRt+t/z2KtUyX0ZIpE4gX33TpywengAanRFiIjRpfP8K1CiaWlpCUdHR5w6dQoaGhqFEVepVlQ76upbqzHu1Dg8GPEANcxoFABCSBkTGflfv87QUCA9XTy8kiTpbNJEnIhKBAcD48aJb0SSsLYGVqwA/OjKEKFEsyAKlGjq6enhzz//xLBhwwojplKvqHbUdFE6qq2uhroWdXGo26FCWw8hhBR7SUnisTslwye9ewfo6wOtWomTTpEIGDRI/Nz27CTDKR08SMkmoUSzAArUR9PFxQVv3rxRdSxExTTVNDHPax6CnwTjVswtvsMhhBD+6OmJH3+5cSMQEwPcvQtMmiS+gz0gABg4UD7JBP4rGz9enIwSQvKlQC2aFy9eRJcuXRASEgIXF5fCiKtUK8pfRKIsEeqsr4MKehVwtt/ZQl0XIYSUSMHBQJcueddr0ED8yEx9ffFg8/r6ub8MDMTDMNEg86UGtWjmX4FuDff09MTmzZvRsGFDNGzYEHZ2dlD7obM0x3HYvHlzvpedlZWFFStW4K+//kJUVBTMzMzQrVs3zJ8/H7q6uiqf/+TJk1iwYAHCw8OhpaWFZs2a4Y8//oC9vb1MvT///BPHjh3D06dP8fnzZxgbG6N69eoYO3YsfH19872dRUVNoIYFPgvgu88X516dQ7NKzfgOiRBCipe0NOXqZWYCHz4Az5+L72aXvFJScp5HIMg7GVUmYdXVFS+LkBKmQC2aN2/eRKtWrZCYy7ARHMdBVIDLDOPGjcPKlSvh6+uLNm3a4MmTJ1i1ahU8PDxw9uxZCPL4ouVn/uDgYPj7+6NOnToYMmQIEhISEBQUBDU1Ndy5cweW2QYA7t69O7S1tVGjRg2Ympri8+fPOHDgAG7duoX58+dj9uzZSm9jUf8iYoyh0eZGYGC4MegGOPp1TQgh/7lwAfDO+wlrCA0VP5HoRxkZwLdv4qQzIUE2CVX0yqnO9+85r5vjgHLlfj5h1dMr/XfRF+LIAdSimX8FSjQbNmyIV69eYfPmzfDw8IChoaFKgnn06BGcnJzg6+uLQ4f+u3ll1apVGDt2LHbv3o1evXqpZP6MjAzY2dlBXV0djx49gp6eHgDg/v37cHV1xaBBg7Bhw4Zc483MzISrqytevXqFr1+/yrXq5oSPHTU0MhQ+O3wQ3C0Yvo7FtwWWEEKKnEgkfrxlTIzifpocJ777PDKycJO0zEzxTUvKJqw51fv2Lff16On9fCurvj5QHMfLLuSRAyjRzL8CJZo6OjqYO3cupkyZotJgZs2ahd9++w2XLl2Ch4eHtDw1NRUmJibw9PTEyZMnVTL/2bNn0aJFC4Wtkc2aNcOdO3cQHx+f5/BNbdu2xalTp5CcnAyhks/d5WtHbbmzJd4mvsWDEQ/oSUGEEJJdcDDg7y/+f/bTYkm86zwr67+E9WeT1txSBB0d1SSsmpqq2W7JZ1iIIwdQopl/Bfo5Ym5uDk1V7RjZ3L59GwKBAG5ubjLlQqEQzs7OuH37tsrml/y/UaNGcstp2LAhzp8/j2fPnqFmzZoy0z5//gyRSIT4+HgcOHAAp06dgre3t9JJJp8WNluI+hvrY+e/O9HfuT/f4RBCSPHh5ydORBS1hgUFlZwkE5DtF/ozGBNfzlfmsn/218uX8mW5daUTCpW77J/bdF1d8WeX08gBHCceOaBTp9LfdaCYKVCiOXDgQOzatQujR49W6aMmY2NjYWpqCi0tLblpVlZWuHbtGtLT03NMcvMzf2xsrLRcUV0AiImJkUs0HRwc8OnTJwCAuro6unTpgrVr1+a6XWlpaUjL1tk8t76thameZT10ceyCwAuB6FmrJ7TU5d8nQggps/z8xIkIPRlIjOPEl9n19IBs9yzkG2PiG6bym7C+fi1bLyFB3L2goDG8eSP+bBX1syWFpkBZYpMmTXD8+HE0bNgQI0eOhL29vcL+iU2bNs3XcpOTkxUmiQCkLYbJyck5Jpr5mT85ORkAFNbPXvdHwcHBSE1NRUxMDA4cOICUlBR8+/YNZmZmOW7XokWLMG/evBynF6VfvX9FrXW18NfdvzC2wVi+wyGEkOJFTY0SEVXjOPFldh0doEKFgi+HMfEIAYou+Z8+Daxbl/cy3r0r+PpJgRQo0WzevLn0/4MHD5a7i5kxVqC7znV0dPDx40eF01JTU6V1VDG/5N80BcNa5Lau7MnzgAED0LNnTzRu3BiPHz/O8Znv06dPx8SJE6V/JyYmwsbGJsftKEyOZo7oX6c/FlxagIEuA6GnqcdLHIQQQki+cJz4MrtQCJiby04zMFAu0bSwKJzYSI4KlGhu3bpV1XEAED9D/fHjx0hLS5NraYyJiYGpqWmufUPzM79k6KKYmBg4OjrK1QUUX1b/UUBAAPbu3Yvg4GAMGjRIYR0tLa0cW1r5EOgViF0PdiHoRhBmNZ3FdziEEELIz/HwEPenzWvkgGw3CpOiUaBEMyAgQNVxAADq16+PM2fO4NatW3J3jd+/fz/PS/H5mb9+/foAgOvXr8u00ALAjRs3oK+vDwcHhzxjTvn/gXo/f/6c9wYWExUNKmJkvZFYcm0JRtQbARMdE75DIoQQQgpOTU08hJG/vzipVDRyQFBQ2e1vy6Ni9ZiB7t27g+M4BAUFyZRv3LgRycnJ6N27t7Ts5cuXiIiIKPD8np6esLCwwKZNm5CUlCQtDw8Px4ULF9C1a1fp0Ebfv3+XqSMhEomwZs0aAOI71UuSGR4zkMWysPjKYr5DIYQQQn6eZOSAH69GWluXrOGpShmlxtG8dOkSgP/6J0r+zkt+bwYCgDFjxmD16tXw9fVF27Zt8eTJE6xcuRKNGzfG+fPnpU/2sbOzQ3R0NH4MX9n5AeDAgQPo3r279MlAiYmJWL58OTiOw927d6WXzu/fvw9PT0/4+/ujWrVqMDY2RkxMDPbs2YOnT58iICAA27ZtU3obi8s4XIGhgfjj2h94MeYFrPTz7iZACCGEFHv0ZKDihSmB4zgmEAhYWlqazN85vSTTCyIzM5MtXbqUOTg4ME1NTWZpackmTJjAvn37JlPP1taWKQpf2fkljh07xho0aMC0tbWZoaEh69KlC3vx4oVMnbi4ODZq1ChWu3ZtZmRkxNTV1ZmJiQlr3rw527VrF8vKysrXNiYkJDAALCEhIV/zqVpCagIz+d2EDf3fUF7jIIQQQkqC4nL+LkmUatHctm0bOI5Dv379wHEctm/frlQSW1h9OUu64vSLaNn1ZZgSMgVPRj1BVZOqvMZCCCGEFGfF6fxdUij9CModO3agadOmsLOzK+SQSr/itKOmZqai6qqqaFKxCfZ02cNrLIQQQkhxVpzO3yWF0jcDDRgwANeuXSvMWAgPhOpCBHoGYu/DvQh7F8Z3OIQQQggpRZRONJVs+CQlUH/n/nAwccDM8zP5DoUQQgghpUixGt6I8ENdoI5fvX/FPy/+weXoy3yHQwghhJBSghJNAgDwr+EPlwoumH5uOrVeE0IIIUQl8vVkoA0bNuDs2bNK1eU4Dps3by5QUKToCTgBFjVbhNa7W+Pk85No59CO75AIIYQQUsIpfdd59oHOlVowx0EkEhUoqNKuuN61xhiD93ZvfEn9grBhYRBw1OBNCCGESBTX83dxlq8WzaCgIHTq1KmwYiE84zgOi5otgvsWd+x9uBe9nHrxHRIhhBBCSrB8JZqmpqawtbUtrFhIMdDIphE6OHTAnNA56FqjKzTUNPgOiRBCCCElFF0bJXJ+8/kNr768wuYw6mNLCCGEkIKjRJPIcSrvhF5OvTD/4nwkZyTzHQ4hhBBCSiilE01PT0+UL1++MGMhxch87/mIS47D6lur+Q6FEEIIISWU0olmaGgomjVrVpixkGKkklElDK07FIuvLMbX1K98h0MIIYSQEogunZMczWo6C6mZqVhydQnfoRBCCCGkBKJEk+TIopwFxjUYh6CbQXif9J7vcAghhBBSwlCiSXI1pfEUaKpp4rdLv/EdCiGEEEJKGEo0Sa6MtI0wxX0K/rr7FyK/RPIdDiGEEEJKEEo0SZ7GNhgLEx0TzL04l+9QCCGEEFKCUKJJ8qSrqYvZTWdjZ/hOPPz4kO9wCCGEEFJCcIwxlt+ZKlWqlPtCOQ7a2tqoWLEiWrZsiSFDhkBXV7fAQZY2iYmJMDAwQEJCAvT19fkORynponRUX10dtcvXxpEeR/gOhxBCCClyJfH8zbcCtWhWrFgR6urqiIqKwpcvX2BoaAhDQ0N8+fIFUVFRUFdXh7a2Nm7cuIGJEyfC1dUVcXFxqo6dFCFNNU3M956Po0+P4sbbG3yHQwghhJASoECJZlBQED5//oy1a9fi48ePuHfvHu7du4e4uDisXr0anz9/xubNmxEfH49Vq1bh+fPnmDNnjqpjJ0WsZ62eqGVeCzPOzUABGsIJIYQQUsYU6NJ58+bNUa1aNaxZs0bh9JEjR+L58+cICQkBAPTp0weXLl3C69evfy7aUqIkN70fe3oMHfd2xJk+Z9Cicgu+wyGEEEKKTEk+f/OlQC2aN2/eRO3atXOcXrt2bdy48d/lVXd3d3z48KEgqyLFTHuH9mhk3QgzzlOrJiGEEEJyV6BEU0tLC7dv385x+q1bt6ClpSX9Oy0tDXp6egVZFSlmOI7DomaLcCf2DoKfBPMdDiGEEEKKsQIlmh07dsTWrVuxePFiJCcnS8uTk5OxaNEibN++HR07dpSWX7t2DQ4ODj8fLSkWPO080apyK8w8PxOZWZl8h0MIIYSQYqpAfTQ/f/6MZs2aITw8HOrq6rC0tAQAxMbGIjMzE05OTjh//jxMTEyQmpqKIUOGoFWrVujTp4/KN6AkKg19PO69uwfXDa7Y3HEzBroM5DscQgghpNCVhvN3UStQogkA6enp2LRpE44fP47ISPGjCe3s7NChQwcMHjwYmpqaKg20NCktO2q3A91w4+0NPBvzDEJ1Id/hEEIIIYWqtJy/i1KBE01ScKVlR30a/xQ119bE0pZLMb7heL7DIYQQQgpVaTl/FyV6BCUpsGqm1TDAeQB+u/wbvqV94zscQgghhBQz6gWd8fv37/j777/x/PlzfPr0SW6oG47jsHnz5p8OkBRvgV6B2PnvTiy7vgyBXoF8h0MIIYSQYqRAl85v3bqF9u3bIz4+PucFcxxEItFPBVdalbam90mnJ2HjvY14Ne4VTHVM+Q6HEEIIKRSl7fxdFAp06XzixIlIT0/H/v37ER8fj6ysLLkXJZllx3SP6QCARZcX8RwJIYQQQoqTAiWad+/exaRJk+Dv7w9jY2NVx0RKGFMdU0xqNAlrbq/Bm4Q3fIdDCCGEkGKiQImmvr4+TExMVB0LKcEmNpqIclrlMP/ifL5DIYQQQkgxUaBE08/PD6dPn1Z1LKQEK6dVDjM9ZmLr/a14Gv+U73AIIYQQUgwUKNH8/fff8fHjR4wZMwYvX76Uu+OclE3D6w2HZTlLzA6dzXcohBBCCCkGCnTXuUAgAMdxuS+Y45CZSc/BVqQ037W2JWwLBv1vEO4OvYu6FnX5DocQQghRmdJ8/i4sBRpHs1+/fnkmmqRs6lenH5ZcW4IZ52bgVJ9TfIdDCCGEEB4VKNHctm2bisMgpYW6QB2/ev+Krge64mLURXjaefIdEiGEEEJ4Qo+gJCrXxbELXC1cMf3cdOq/SwghhJRhlGgSleM4DouaLcL1t9dx/NlxvsMhhBBCCE+USjQFAgHU1dWRnp4u/VtNTS3Xl7p6gR+jTkqB5pWaw9vOGzPOz4Aoi54SRQghhJRFSmWDkpt/1NTUZP4mJCccx2Fhs4VotLkR9jzcgz61+/AdEiGEEEKKWIGGNyI/pywNj9B5b2f8++FfRIyOgKaaJt/hEEIIIQVWls7fqkJ9NEmhWuCzAFFfo7Dp3ia+QyGEEEJIEfvpjpTJycn49OmTwruLK1as+LOLJyVcLfNa6FunL3699CsC6gRAV1OX75AIIYQQUkQK1KKZlZWFxYsXw8rKCuXKlYOdnR3s7e3lXoQAwDyvefiU/Amrbq3iOxRCCCGEFKECtWhOmzYNS5cuRc2aNdGlSxeYmJioOi5SitgZ2mGY6zD8fvV3DHMdBiNtI75DIoQQQkgRKNDNQJaWlnB2dsbJkycLI6ZSryx2Jv6Q9AGVVlbCWLexWNR8Ed/hEEIIIflWFs/fP6tAl86/fPmCTp06qToWUoqV1yuP8Q3GY8XNFXj37R3f4RBCCCGkCBQo0XRycsK7d5QskPyZ3HgyhOpCLLi0gO9QCCGEEFIECpRoBgYGYv369Xjz5o2q4yGlmKHQENOaTMOGexvw6ssrvsMhhBBCSCEr0M1Ad+/eha2tLWrUqAFfX1/Y29tLnxokwXEcZs+erZIgSekx2m00gm4EIfBCIHb67uQ7HEIIIYQUogLdDCQQ5N0QynEcRCJ6xrUiZb0z8fo76zHyxEiEDw+HU3knvsMhhBBClFLWz98FUaBEMzo6Wql6tra2+Q6oLCjrO2qGKAOOaxxRw6wG/tfzf3yHQwghhCilrJ+/C6JAl84pgSQ/Q0NNA/O956N3cG9ce3MN7jbufIdECCGEkEJQ7J51npWVheXLl6N69eoQCoWwsbHBpEmT8P3790KZ/+TJk3B3d4euri6MjY3RtWtXREZGytRhjGHXrl3o0aMHqlSpAh0dHVSsWBEdO3bEzZs3f3qby6IetXqgdvnamHFuhsLHlxJCCCGk5FPq0vn8+fPBcRxmzpwJgUCA+fPn573gAt4MNG7cOKxcuRK+vr5o06YNnjx5glWrVsHDwwNnz57Ns39ofuYPDg6Gv78/6tSpgyFDhiAhIQFBQUFQU1PDnTt3YGlpCQBITU2FtrY2nJ2d0a5dO9jb2+Pdu3dYv349YmNjsWPHDvTp00fpbaSmd7ETz06g/Z72ONX7FFpVacV3OIQQQkiu6PxdAEwJHMcxgUDA0tLSpH/n9RIIBMosWsbDhw8Zx3HMz89PpnzlypUMANu9e7fK5k9PT2eWlpasYsWK7Nu3b9LysLAwJhAI2JAhQ6RlGRkZ7MKFC3Lre//+PTMxMWHm5uZMJBIpvZ0JCQkMAEtISFB6ntIoKyuLNd7cmLmsd2GiLOXfP0IIIYQPdP7OP6UunUdGRuLVq1fQ1NSU/p3X69Wr/I+TuGfPHjDGMH78eJnyIUOGQEdHB7t27VLZ/BcvXkRsbCwGDx4MPT09abmzszO8vLywb98+ZGRkAADU1dXh6ekpt77y5cvD09MTHz9+xMePH/O5tYTjOCxqtghh78Nw8PFBvsMhhBBCiIopdTPQjzf/FNbNQLdv34ZAIICbm5tMuVAohLOzM27fvq2y+SX/b9SokdxyGjZsiPPnz+PZs2eoWbNmrut8+/YtNDU1YWhomGs9opiHrQfaVGmD2aGz4efoB3VBge5PI4QQQkgxVKxuBoqNjYWpqSm0tLTkpllZWSE+Ph7p6ekqmT82NlZarqguAMTExOQa78mTJ3Hr1i10794dQqEwx3ppaWlITEyUeZH//ObzG559eoZt97fxHQohhBBCVOinmo/u3LmDmzdv4suXL8jKypKZVpCbgZKTkxUmiQCkiVxycrL0Ev7PzJ+cnAwACutnr5uT58+fo2/fvrCyssKff/6ZYz0AWLRoEebNm5drnbLMxcIF3Wt2x7yL89Cndh8I1XNO2gkhhBBSchQo0UxJSYGfnx/OnDkDxhg4jpMOUSP5f0ESTR0dnRz7OqampkrrqGJ+yb9paWn5XldkZCSaNWsGjuPwzz//wMzMLMeYAGD69OmYOHGi9O/ExETY2NjkOk9Z86v3r3Bc44i1t9diYqOJec9ACCGEkGKvQJfO58+fjzNnzmDmzJkIDQ0FYwzbt2/HP//8Aw8PD9SvXx+PHz/O93ItLS0RHx+vMPmLiYmBqalpjq2Z+Z1fMnSRosvjkjJFl9WjoqLg7e2NpKQkhISEwMkp70coamlpQV9fX+ZFZFU1qYpBLoOw8PJCJKZR1wJCCCGkNChQonnw4EF07doV8+fPR61atQCIk7JWrVrh7NmzSE9Px7Zt2/K93Pr16yMrKwu3bt2SKU9NTcX9+/dRr149lc1fv359AMD169fllnPjxg3o6+vDwcFBpjwqKgpeXl5ISEhASEgIXFxc8rV9JHdzPOfge8Z3/Hkt964IhBBCCCkZCpRovnnzRjrcj5qaGgBIb7JRV1dHz549sXfv3nwvt3v37uA4DkFBQTLlGzduRHJyMnr37i0te/nyJSIiIgo8v6enJywsLLBp0yYkJSVJy8PDw3HhwgV07doVGhoa0vLo6Gh4e3vj69evOHPmDFxdXfO9fSR3VvpWGF1/NJbdWIa473F8h0MIIYSQn1SgPprlypVDZmam9P8CgUB6FzcAGBgY4P379/lerpOTE0aNGoXVq1fDz88Pbdu2xZMnT7By5Up4enqiV69e0rrNmjVDdHS0zOML8zO/hoYGVqxYge7du8PDwwNDhgxBYmIili9fDjMzM5mbd759+wZvb29ERUVhzJgxePr0KZ4+fSoTe4sWLVC+fPl8bzORNa3JNGy4twELLy/E8tbL+Q6HEEIIIT+jIKO8N2jQgI0ePVr6d+3atVmbNm0YY+KnvbRs2ZJVrVq1QCPIZ2ZmsqVLlzIHBwemqanJLC0t2YQJE2Se3sMYY7a2tkxR+MrOL3Hs2DHWoEEDpq2tzQwNDVmXLl3YixcvZOpERkYyALm+QkNDld5GerJA7uZfmM80f9Vk0V+j+Q6FEEIIkaLzd/4p9azzH82aNQtbtmzBmzdvoKamhrVr12L06NGwt7cHx3GIjIzEwoULMXXqVJUlxKUJPSs1d0npSai0ohI6OHTA5k6b+Q6HEEIIAUDn74IoUKKZlJSEmJgYVK5cGerq4qvvy5Ytw65du6CmpgZ/f39MmTIFHMepPODSgHbUvK28uRITTk/AwxEP4WjmyHc4hBBCCJ2/C6BAiSb5ObSj5i0tMw3VVldDPct6ONiNnoNOCCGEf3T+zr9833WelJSEypUry93ZTYgqaalrYa7XXBx6cgh3Yu/wHQ4hhBBCCiDfiaaenh4+ffoEPT29woiHEKm+tfvC0dQRM87N4DsUQgghhBRAgcbRbNiwIe7coVYmUrjUBGpY4LMAIa9CEBoZync4hBBCCMmnAiWaixcvxv79+7F161ZQF09SmHyr+6K+ZX1MPzed9jVCCCGkhFH6ZqDXr1/DzMwM2tra8PHxQXR0NKKiomBsbIzKlStDR0dHdsEch3PnzhVK0CUddSbOn3OvzqH5zuY43P0wOlfvzHc4hBBCyig6f+ef0ommmpoadu3ahZ49e8LOzk6poYsiIyN/OsDSiHbU/Gu+ozneJb3Dv8P/hZpAje9wCCGElEF0/s4/pR9ByRiTXrqMiooqrHgIUWhhs4VosKkBdj/YjX51+vEdDiGEEEKUUKA+moQUNTcrN/hW90XghUCki9L5DocQQgghSqBEk5QYC3wW4HXCa2y4u4HvUAghhBCiBKUvnQPA5cuXkZmZqXT9fv3oEidRnRpmNdCvTj8suLQA/Z37Q0+TxnIlhBBCijOlbwYSCARKP7ucMQaO4yASiX4quNKKOhMXXPTXaDisdsCcpnMws+lMvsMhhBBShtD5O//y1aI5dOhQNGzYsLBiISRPtoa2GO46HEuuLcGI+iNgrG3Md0iEEEIIyUG+Ek0PDw/06tWrsGIhRCkzm87E5rDN+P3K7/i9xe98h0MIIYSQHNDNQKTEMdc1x4SGE7Dy1krEfovlOxxCCCGE5IASTVIi/eL+C3Q0dPDrxV/5DoUQQgghOaBEk5RIBkIDTG8yHZvCNuHF5xd8h0MIIYQQBZRONLOysqh/JilWRtUfhfK65TEndA7foRBCCCFEAWrRJCWWtoY25njOwZ6HexD+PpzvcAghhBDyA0o0SYk2wHkAqhhXwczzNKYmIYQQUtxQoklKNA01Dfzq/StOPD+Bq6+v8h0OIYQQQrKhRJOUeN1qdoNzBWdMOzcNSj7oihBCCCFFgBJNUuIJOAEW+izElddX8M+Lf/gOhxBCCCH/jxJNUiq0rtIaHhU9MOPcDGSxLL7DIYQQQggo0SSlBMdxWNRsEcI/hGP/o/18h0MIIYQQUKJJSpHGFRujXdV2mB06GxmiDL7DIYQQQso8SjRJqfKbz2948fkFtt7fyncohBBCSJlHiSYpVepUqINeTr0w7+I8pGSk8B0OIYQQUqZRoklKnfle8/Hx+0esvrWa71AIIYSQMo0STVLqVDaujMEug7H46mIkpCbwHQ4hhBBSZlGiSUql2Z6zkZKRgqXXlvIdCiGEEFJmUaJJSiXLcpYY4zYGy28sx4ekD3yHQwghhJRJlGiSUmtqk6lQF6hj4eWFfIdCCCGElEmUaJJSy1jbGFMaT8H6u+sR9TWK73AIIYSQMocSTVKqjWswDkZCI8y9MJfvUAghhJAyhxJNUqrpaupiVtNZ2PnvTjyOe8x3OIQQQkiZQokmKfWGug5FRYOKmHV+Ft+hEEIIIWUKJZqk1NNU08Q8r3k4HHEYt2Ju8R0OIYQQUmZQoknKhN5OvVHTrCZmnJvBdyiEEEJImUGJJikT1ARq+M3nN5yLPIezr87yHQ4hhBBSJlCiScqMjtU6oqF1Q8w4NwOMMb7DIYQQQko9SjRJmcFxHBb6LMTt2Ns4HHGY73AIIYSQUo8STVKmeNt7o0WlFph1fhZEWSK+wyGEEEJKNUo0SZmzsNlCPIl/gp3/7uQ7FEIIIaRUo0STlDn1LOuhi2MXBF4IRFpmGt/hEEIIIaUWJZqkTFrgswBvE9/ir7t/8R0KIYQQUmpRoknKpOqm1dG/Tn8suLQA39K+8R0OIYQQUipRoknKrECvQCSkJSDoRhDfoRBCCCGlEiWapMyqaFARI+uNxNLrS/Ep+RPf4RBCCCGlDiWapEyb4TEDWSwLi68s5jsUQgghpNShRJOUaWa6ZpjYcCJW316Nt4lv+Q6HEEIIKVUo0SRl3iT3SdDV0MX8i/P5DoUQQggpVSjRJGWevpY+ZnjMwJawLXj26Rnf4RBCCCGlBiWahAAYWX8kLMpZYE7oHL5DIYQQQkoNSjQJASBUFyLQMxD7Hu1D2LswvsMhhBBCSgVKNAn5f/2d+8PBxAEzz8/kOxRCCCGkVCh2iWZWVhaWL1+O6tWrQygUwsbGBpMmTcL3798LZf6TJ0/C3d0durq6MDY2RteuXREZGSlX79atWxg7diwaN24MPT09cByHbdu2/cymkmJGXaCOX71/xT8v/sGl6Et8h0MIIYSUeMUu0ZwwYQImTpyIGjVqYNWqVejatStWrlyJDh06ICsrS6XzBwcHo3379khJScGSJUswefJkXLp0CY0bN0ZsbKxM3ZMnT2LNmjX4+vUr6tSpo9JtJsWHfw1/1LWoi+nnpoMxxnc4hBBCSMnGipGHDx8yjuOYn5+fTPnKlSsZALZ7926VzZ+ens4sLS1ZxYoV2bdv36TlYWFhTCAQsCFDhsgs4/379ywpKYkxxtiBAwcYALZ169aCbCZLSEhgAFhCQkKB5ieF69TzUwxzwY49PcZ3KIQQQooROn/nX7Fq0dyzZw8YYxg/frxM+ZAhQ6Cjo4Ndu3apbP6LFy8iNjYWgwcPhp6enrTc2dkZXl5e2LdvHzIyMqTl5cuXh66ubsE3jpQYLSu3hKetJ2aen4kslncrOiGEEEIUK1aJ5u3btyEQCODm5iZTLhQK4ezsjNu3b6tsfsn/GzVqJLechg0bIjExEc+e0ZiKZRHHcVjUbBH+/fAv9j7cy3c4hBBCSIlVrBLN2NhYmJqaQktLS26alZUV4uPjkZ6erpL5JX0wraysFNYFgJiYmAJtx4/S0tKQmJgo8yLFWyObRujg0AFzQucgQ5SR9wyEEEIIkVOsEs3k5GSFSSIgbpWU1FHF/JJ/FdVXZl35sWjRIhgYGEhfNjY2KlkuKVy/+fyGV19eYXPYZr5DIYQQQkqkYpVo6ujoIC0tTeG01NRUaR1VzC/5V1F9ZdaVH9OnT0dCQoL09ebNG5UslxQup/JO6F27N+ZfnI/kDNX86CCEEELKkmKVaFpaWiI+Pl5h8hcTEwNTU1NoamqqZH5LS0tpuaK6gOLL6gWhpaUFfX19mRcpGeZ5zUNcchxW3VzFdyiEEEJIiVOsEs369esjKysLt27dkilPTU3F/fv3Ua9ePZXNX79+fQDA9evX5ZZz48YN6Ovrw8HBoaCbQkqJSkaVMLTuUPx+9Xd8Tf3KdziEEEJIiVKsEs3u3buD4zgEBQXJlG/cuBHJycno3bu3tOzly5eIiIgo8Pyenp6wsLDApk2bkJSUJC0PDw/HhQsX0LVrV2hoaKhu40iJNavpLKRmpmLJ1SV8h0IIIYSUKBxjxevxJ2PGjMHq1avh6+uLtm3b4smTJ1i5ciUaN26M8+fPQyAQ58Z2dnaIjo6We3qLsvMDwIEDB9C9e3fUqVMHQ4YMQWJiIpYvXw6O43D37l2ZS+fR0dHYuXMnAODRo0fYu3cv/Pz84OLiAgDo27cvbG1tldrGxMREGBgYICEhgS6jlxDTz07Hylsr8XLsS1TQq8B3OIQQQnhA5+8C4HW4eAUyMzPZ0qVLmYODA9PU1GSWlpZswoQJMk/vYYwxW1tbpih8ZeeXOHbsGGvQoAHT1tZmhoaGrEuXLuzFixdy9UJDQxmAHF+hoaFKbyM9WaDk+Zz8mRkuNmSjT4zmOxRCCCE8ofN3/hW7Fs2ygH4RlUyLryzGnNA5eDr6KeyN7PkOhxBCSBGj83f+Fas+moQUZ2MbjIWJjgkCLwTyHQohhBBSIlCiSYiSdDR0MLvpbOz6dxcefnzIdziEEEJIsUeJJiH5MLjuYNgZ2mHW+Vl8h0IIIYQUe5RoEpIPmmqamO89H0efHsWNtzf4DocQQggp1ijRJCSfetbqiVrmtTD93HS54bUIIYSQ/2vvzuNjutc/gH/OTDKTPUGCRGKJK7HUWjupvRvVCNJbey1tXVpE1VZbbdXWFtQS96Ktq1XVix+9F0XrukprrUuRii1yS1Q2kW3m+f0RMzJmskySyWTi8369zmtmvud7zjzPfMM8c1Z6hIUmkZXUKjUWdF2AQ1cPYd+VffYOh4iIqNxioUlUDL1CeqFdYDtM+24at2oSERHlg4UmUTEoioKF3RbiRMIJfH3ha3uHQ0REVC6x0CQqpk61O+G5us/hvQPvIUefY+9wiIiIyh0WmkQlsKDbAly8exGfnvnU3qEQERGVOyw0iUqghX8LRDaKxKxDs5CRk2HvcIiIiMoVFppEJTS3y1wkpCZg9U+r7R0KERFRucJCk6iEQqqE4LVmr2HBvxcgNTPV3uEQERGVGyw0iUrBrM6zkJqZiiVHl9g7FCIionKDhSZRKQj0CsSYVmOw+OhiJKYn2jscIiKicoGFJlEpmRo2FQCw8PBCO0dCRERUPrDQJColvm6+eKf9O1j10yrcSL5h73CIiIjsjoUmUSma0HYCvLRemPP9HHuHQkREZHcsNIlKkafWE9PCpmHD6Q24mHjR3uEQERHZFQtNolL2Zss3UcOzBmYcnGHvUIiIiOyKhSZRKXNxcsHszrPx1fmvcDLhpL3DISIishsWmkQ2MKTpENT3rY9p302zdyhERER2w0KTyAacVE6Y12Ue/vXbv3Do6iF7h0NERGQXLDSJbCSiQQRaBrTE1O+mQkTsHQ4REVGZY6FJZCOKomBB1wX48eaP2HVpl73DISIiKnMsNIlsqHtwd3Sp3QXTD0yHTq+zdzhERERlioUmkQ0pioIF3Rbg3O1z2HJui73DISIiKlMsNIlsrG1gW7wc+jJmHpyJLF2WvcMhIiIqMyw0icrA/K7zcTXpKmJOxNg7FCIiojLDQpOoDDSq2giDmw7G3B/m4n7WfXuHQ0REVCZYaBKVkTmd5+CPB38g+li0vUMhIiIqEyw0icpIbZ/aeOPpN/Dhfz7EvQf37B0OERGRzbHQJCpD7z3zHrJ0WfjwyIf2DoWIiMjmWGgSlaFqHtUwvs14LD+2HAmpCfYOh4iIyKZYaBKVsUkdJsHFyQVzf5hr71CIiIhsioUmURnzcfHBlI5TEHMyBr/98Zu9wyEiIrIZFpoViE4HHDoEbNmS+6jjHQ/LrbGtx8LPzQ+zDs2ydyhEREQ2w0Kzgti+HahdG+jSBRgwIPexdu3cdip/3JzdMLPTTPz9l7/jl99/sXc4RERENsFCswLYvh3o1w+4edO0PT4+t53FZvk0ovkIBFcKxvQD0+0dChERkU2w0HRwOh0wbhwgYj7P0DZ+PHejl0fOame83+V97Lq0C0euH7F3OERERKWOhaaDO3zYfEtmXiLAjRvArl1Aejqg15ddbFS4Pz/1ZzSp1gTTDkyDWPq1QERE5MCc7B0AlUxCES/F2KfPo+dubrmTu7ttHp34V1VkKkWFBV0XoNeWXvjXb/9CjzrP4/Dh3HH19wfCwgC12t5RUlHpdOD4ERHlwZLAwfn7F63f3LlAcHDuVs379/N/TEsDfv/d8vyMjKK9l0ZjuyLW3T13/YpS/M+svHmx3ovoENQBf/l6GjJXdcMt9RHAIwFI80cNXRiil6kREWHvKKkw27fnHsaSdw9DYCCwfDk4fkT0xFKE++vKXEpKCry9vZGcnAwvL68SrUunyz27PD7e8nGaipL7ZRcXV/ItKzod8OBBwYVqQfOK8liUv0a12rZbZF1dAVUZH1Qy77PDmHHlGSC9MuD2x6MZyYHAP5fj63kRLFbKMcMJeY///Rp+EG3bxmKTqCIoze/vJwULTTso7T9Uw5ccYPpF52hfciK5W02tLVCt6ZuTU7RYXF1NC1BbHl6g0wHVOm/H3W59cxvybq2V3BdVvtuG3w9FcDdsOWT4sXfzJgBFB9Q6bNwijWthUKAutR97RGRfLDStx0LTDmzxh2ppt11QELBsmWMUmWUlO7vkW10LKm6tObzAUHhCEcRn/heocRwIHwEcHw1c6fFY4G5oX/1Z+Pk+qkILutJAUdrLU1t5i8eaGJOSgHPnALgmApWuAOosQNEDmrTcwvN2YyC5NgYMABo1Ajw8Cp/c3VmUEpVHLDStx2M0K4iICODll3kiQmGcnQEfn9zJFopyeMHjj3t/vIH4P74Hst2A6+2Bp7YCosqd9OqHz9W44nwTmZ6VoYgaCpxyH0UNFZygQA1FDG1OUClq4/O88wx9VQ/bIWqo8y7/8EIU+R0Da6m9qG1luXxZvtfVqwC8rwG1Dz5qFDWQ5Q5keQCet4CMSti3zxv79uUeB/3ggeX3zMvVtWhFaWEFa97XFe34ZlvgCV2Oj2NYvrDQrEDUaqBzZ3tH8WRTqx99qReVbusRHL0w1rSxzSqzfv97ONmak8oJakUNtUptfO6kcrL4ulTmKaW77qLEXxq5KQ8rtu8O6tB9V0fA66bpYQ8GogApgdjyUhy6dcn9ttPpHp18V5wpMdFye2H7p5ycSl68Pj65uVWc4nX7duDt8TrEqx8d/sAT8hwLT8orf7jr3A646Z3y+u63Q+j+eZdC+/0jchc61moHneiQo8+BTq8zeZ6jzymVeYbXxZ5Xxu+rE/vcjUClqKBW1FApKmTqMgvt38jvKVTzqAqNWgOtWgutk9b43OTx8XYnbYHzDK+dVRpIjhY5GVpkZWiQ/UCLzHQNMu474/59pVgFbWpq4cc1K4r5ltPS2BJb1pdJ274d6PveduD5cYB3niqFJ+Q5DONJeXjsWOnrYVBEXSrnK/D723osNO2Af6iUl06vQ7UPauNuVjygWDpgUEEVTSB+nxIHtYr7fx4nItCL3m5F9/H449h0ZlOhcT5T8xkEeAUgS5eFzJzM3EddpvF13uePzytpMZ1fcVpQ4Wp4VCsaqPRaKDotRKcBcrTQZ2sg2VrosjXQZWmRk6FBTqYW2RlaZD/QICvdUORqkXFfgwdpWjxI0yA9RYv0VA0epGoBnRbQOcPyZmDAxaX0ilbDc63W8tbXRyfk9QMgPCHPARlPyvPM/8dCUFpEiU/K4/e39bjrnMjO1Co11vVZjr5b++V+qeUtNkUBFGBdn2UsMvOhKEru7nCooVFryvz9G/o1LFKhOafLHHSu3blY76HT68yKz/xeFzSv0KL24WNSRlKR38ukCNY+nHyKnpuzSgNnRQNnlRZqaKCGFirRQC1aKHoNcnRaJOm0uJeTu8VWn62BPksLXZYGOQm5RW72w624yDYUsLkFMXQak9cq0cBVo4WrRgM3rRbuWi08XDXIytDgbmoy8M/FgFMmoM4AVDkPC04FEAV3dVcwcpQewXUeXfussEMGnvT5ZRlDbCxwM/sMUPMwcP7hFTxqHwL8zwBe8UBkP9zYug2HD0fwELMyxi2adsBfRGTJ9gvbMe7bcbiZ+uiXeKBXEJY/vwwRDbjPrrzS6XWovbw24lPiITD/71SBgkCvQMSNq5hbpA1FsE0K35xMZOmL0Ofh64ycTGTl5D7P1mUhR4p4PbOC6HNPxss9MU+de8Lcw9eK5LYZTthT8vSz3KaG8rAdj/VVHmsz9suzrLHdZH1qiD7PexmXybNOQ5teDUCV5z0eazN5r4frzNMmevP3Nyxv6CcP16PAQr+H8YvF91JBebgpuShVyeN9cnIEGbr7pj/Ue0wCWq19uEDusdKft4zDwAHF/3fI72/rcYsmUTkR0SACL4e+jMPXDyMhNQH+nv4IqxlWIYuTikStUmP588vRb2s/KFBMik3DF+ey5yvuFmm1Sg1XlStcnV3tHYoZnV6HbH12oYXv2gP/xObrCyyvRKUHoAfU2ehRbTCea9LUeDiFTnS5h208fJ730XA4h8W2ApfPKnz5Qtryiytvm170ZToWRWE47lmtUps8z/uoUlQW25LSMpCQEZf/yhUBvG/gjtthAJ3LKiUCC02ickWtUhd79yrZT0SDCGyL3IZx/xyHmyl5t0gHYhm3SNuNWpVbjLg4uRTYL+sZHTZ/nk+hmcfkHsPRrW7nUorOvgzHNhe3UC1RoV0KhfLjbefvXEDClQIKzYf86iSUwadLebHQJCIqBdwi7bg61wlDFefAQk/I61wnrOyDs5G8xzY7w9ne4ZTYoauHsPfKvwrtV8PbvwyiobxYaBIRlRJukXZMPCHP8YXVDEOgVyBupsQDFo6VBhQEeQUirGbF+bHgKFSFdyEiIqrYIhpE4OvIbQj0qmHSHugdiK8jt/Hwh3LOcKy0gkfHRhsoD1sq8rHS5RnPOrcDnrVGRFQ+6fQ6Hv7gwLZf2G52rHSQV1CpHSvN72/rlbstmnq9HkuXLkX9+vXh4uKCoKAgTJw4Effv37fJ8nv27EH79u3h7u6OypUro3///oiLs3xA8cWLFxEeHo5KlSrB3d0dYWFhOHDgQLFzJSKi8sVw+MOrjV9F59qdWWQ6mIgGEbg67ioODj2Iv0f8HQeHHkTcuDhukbajcrdFc9y4cYiOjkafPn3wwgsv4MKFC1ixYgXCwsKwf/9+qFQF18bWLL99+3b069cPTZs2xahRo5CcnIxly5ZBrVbj559/RkBAgLHvb7/9htatW8PJyQnjx4+Ht7c3YmJicO7cOXz77bfo3r17kXPkLyIiIiLHw+/vYpBy5Ny5c6IoikRERJi0R0dHCwDZvHlzqS2flZUlAQEBUrNmTUlNTTW2nzp1SlQqlYwaNcpkHf379xeVSiWnTp0ytqWmpkrNmjUlJCRE9Hp9kfNMTk4WAJKcnFzkZYiIiMi++P1tvXK163zLli0QEYwfP96kfdSoUXBzc8Pnn39east///33uHXrFkaOHAkPDw9je7NmzdC5c2d8+eWXyM7OBgDcv38fO3fuROfOndGsWTNjXw8PD4wcORKXLl3CTz/9VLykiYiIiCqoclVo/vTTT1CpVGjdurVJu4uLC5o1a1ZoMWfN8obn7dq1M1tP27ZtkZKSgkuXLgEAzp49i8zMzHz75l2fJZmZmUhJSTGZiIiIiCq6clVo3rp1C76+vtBqtWbzatSogcTERGRlZZXK8rdu3TK2W+oLAPHx8Vb3tWThwoXw9vY2TkFBQfn2JSIiIqooylWhmZ6ebrFIBHK3Shr6lMbyhkdL/UvS15KpU6ciOTnZON24cSPfvkREREQVRbm6M5Cbmxtu375tcV5GRoaxT2ksb3jMzMws1b6WaLXafAtgIiIiooqqXG3RDAgIQGJiosWCLj4+Hr6+vtBoNKWyvOHSRZZ2eRvaDLvFrelLRERERLnKVaHZqlUr6PV6HD9+3KQ9IyMDp0+fRsuWLUtt+VatWgEAjh49araeH3/8EV5eXggJCQEANG7cGFqtNt++AAqNjYiIiOhJU64KzVdeeQWKomDZsmUm7TExMUhPT8fAgQONbb/99ht+/fXXYi/fqVMn+Pv7Y/369UhLSzO2nzlzBocOHUL//v3h7OwMIPcyRi+99BIOHTqEM2fOGPumpaVh/fr1qFevntmZ7kRERERPunJ3Z6C33noLK1euRJ8+ffDiiy/iwoULiI6ORocOHXDgwAHjnX1q166Na9eu4fHwi7o8AHz11Vd45ZVXjHcGSklJwdKlS6EoCk6cOGGyOzw2NhatW7eGs7MzJkyYAC8vL8TExOCXX37B7t278dxzzxU5x+TkZPj4+ODGjRu8swAREZGDSElJQVBQEJKSkuDt7W3vcByDXS8Xb0FOTo58/PHHEhISIhqNRgICAmTChAkmd+8REalVq5ZYCr+oyxvs2rVL2rRpI66uruLj4yN9+/aV2NhYi33Pnz8vvXv3Fm9vb3F1dZUOHTrIvn37rM7xxo0bAoATJ06cOHHi5IDTjRs3rP7uf1KVuy2aTwK9Xo9bt27B09MTiqKU6roNv7Yq6tbSip4fUPFzZH6Or6LnyPwcn61yFBGkpqYiICDAZA8p5a9cXd7oSaFSqRAYGGjT9/Dy8qqw/4EAFT8/oOLnyPwcX0XPkfk5PlvkyF3m1mE5TkREREQ2wUKTiIiIiGyChWYFo9VqMWvWrAp7J6KKnh9Q8XNkfo6voufI/Bzfk5Cjo+DJQERERERkE9yiSUREREQ2wUKTiIiIiGyChSYRERER2QQLTSIiIiKyCRaadrZw4UL0798fwcHBUBQFtWvXLrD/sWPH0L17d3h6esLLywvPP/88Tp8+bbHvrVu3MGTIEPj5+cHV1RUtW7bEV199ZbFvZmYmZs6ciTp16kCr1aJu3bqYN28esrOzyyy/YcOGQVEUi9O2bdtKHPOnn36K5s2bw9XVFdWqVcPIkSNx586dEuV36dIlzJw5E23btoWfnx88PT3RrFkzzJ8/H/fv3zfrf/HiRYSHh6NSpUpwd3dHWFgYDhw4YHHdycnJeOutt1CjRg24uLigUaNGWL16NSydv6fX67F06VLUr18fLi4uCAoKwsSJEy3GYMscZ8+ene8YfvzxxyWOe8+ePWjfvj3c3d1RuXJl9O/fH3FxcSXK7+LFixg4cCAaNGgAb29vuLm5oX79+oiKikJCQoLF/o40htbk54jjZ0l6errx/5yxY8eazXe0MbQ2R0cdx/xi9vDwMOtbEcbwiWG3m1+SiIgAkMqVK0v37t2lUqVKUqtWrXz7Hj16VLRarQQHB8uSJUtkyZIlEhwcLB4eHnL27FmTvnfv3pU6deqIu7u7zJgxQ9auXSudOnUSAPK3v/3NbN0vv/yyAJDhw4dLTEyMDB8+XADI0KFDyyy/oUOHCgD57LPPzKZr166VKOYlS5YIAOnUqZOsXbtWZsyYIe7u7tKwYUNJS0srdn6TJ08WDw8PGTBggERHR8vq1aslMjJSAEiTJk0kPT3d2Dc2NlYqV64sVatWlQULFsiqVaukWbNm4uTkJPv27TNZb2ZmprRq1UqcnJxkwoQJsm7dOunTp48AkFmzZpnF8fbbbwsA6dOnj6xbt04mTJggTk5O0qVLF9HpdMXOz9ocZ82aJQBk6dKlZmN4/vz5EsX99ddfi6Io0qxZM1m1apUsWLBAqlatKv7+/hIfH1/s/Pbv3y9dunSRqVOnyqpVq2Tt2rUyduxYcXd3F39/f/n999+NfR1xDK3JzxHHz5KJEyeKh4eHAJAxY8aYzHPEMbQ2R0cdRwASFhZmFvMXX3xh0q+ijOGTgoWmnf3222/G540aNSqwEGvVqpV4enrKzZs3jW03b94UT09P6dGjh0nfSZMmCQDZuXOnsS0nJ0datWollStXltTUVGP77t27BYBERUWZrCMqKkoAyJEjR4qbnlX5GQrNorAm5jt37oibm5u0atVKcnJyjO07d+4UADJ//vwiZmPup59+kqSkJLP26dOnCwBZsWKFsa1///6iUqnk1KlTxrbU1FSpWbOmhISEiF6vN7avWrVKAEh0dLTJeiMiIsTZ2VmuXr1qbDt37pwoiiIREREmfaOjowWAbN68udj5WZuj4QsuLi6u0PVaE3dWVpYEBARIzZo1Tf52T506JSqVSkaNGlWMzAq2detWASCLFi0ytjnqGFpiKb+KMH4nTpwQtVotixcvtliEVYQxLCxHRx3Hom7cqAhj+CRhoVmOFFSIXb582bj17nHDhw8XRVEkISHB2FajRg2pW7euWd9PP/1UAMiXX35pbBs4cKAAkOvXr5v0vX79ugCQ0aNHFzMjU0UtNPV6vSQnJxf469GamGNiYgSAfPrpp2brCQ4OlgYNGlifTCHOnj0rAOSNN94QEZG0tDTRarXStWtXs77vv/++AJBjx44Z2zp06CBubm7y4MEDk74//PCDWXFgKPh++OEHk74PHjwQNzc3eeGFF0ozNaPHcxQx/YJLTk6W7OzsfJe3Ju59+/YJAHn//ffN1tO1a1fx8vKSrKysUsjqkWPHjgkAmTJliohUvDF8PD8Rxx+/nJwcadGihfTs2VPi4uLMirCKMIaF5SjiuONoKDQzMzNNCtm8KsIYPml4jKaD+OmnnwAA7dq1M5vXtm1biAhOnDgBAEhISEB8fDzatm1rsW/e9Rme16hRA0FBQSZ9g4KCEBAQYNK3LHh7e8Pb2xuurq7o0aMHjh07ZtbHmpgL++x+/fVXpKWllWoON2/eBABUq1YNAHD27FlkZmbmG0PeOPV6PU6ePInmzZvDxcXFpG/r1q2hKIpZfiqVCq1btzbp6+LigmbNmtls/B7PMa8mTZrA29sbLi4uaN++Pb799luzPtbEXdgYpqSk4NKlSyXKJyMjA4mJibh58yb27t2LN954AwDw4osvAnD8MSwsv7wccfwAYOnSpfj111+xcuVKi/MdfQyBwnPMyxHHcdu2bXBzc4OnpyeqVq2Kt956C8nJycb5FWEMnzQsNB3ErVu3AAA1atQwm2doi4+Pt7qvob+lvob+efvaUvXq1TFhwgSsXr0a33zzDaZNm4aff/4ZYWFh2L9/v0lfa2Iu7PMQEWOf0qDT6TB37lw4OTlhwIABRYoBeDQm9+7dw4MHDyz21Wq18PX1NcvP19fX4q3WatSogcTERGRlZZU8sTws5QgAPj4+eP3117FixQrs2LEDCxcuxLVr19CzZ09s3LjRZB3WxG3t33RxrF+/Hn5+fggKCsJzzz2HpKQkfP755wgLC7M6hvI4hoXlBzj2+MXFxWHWrFmYOXNmvicdOvoYFiVHwHHHsXXr1pg9eza2bduGTZs2oWvXrli5ciXCwsKMGwMcfQyfRE72DoCKJj09HQAs/gMw/FIz9LGmr+F5fveDdXFxMelrSx988IHJ6/DwcAwYMADNmjXD6NGjcfnyZeM8a2K29vMoqfHjx+Po0aNYsGABQkNDrY6hoL6G/taMn6GPRqMpTjoWWcrR0P644cOH46mnnsKECRPQr18/4xmk1sRdFmMYHh6O+vXrIy0tDadOncLOnTuRmJhonO/oY1hYfoBjj9+bb76J4OBgREVF5dvH0cewKDkCjjuOj++9GjJkCJo0aYLp06dj+fLlmD59usOP4ZOIWzQdhJubG4DcS/o8LiMjw6SPNX0Nzy31NfTP27es1atXD5GRkYiNjTXZJWNNzNZ+HiUxY8YMrFy5Eq+//jqmTp1arBgK6mvob8345V1nacgvx/xUqVIFb775JpKSkvCf//zH2G5N3GUxhoGBgejevTvCw8MxZ84cbNq0Ce+++y4WLlxodQzlcQwLyy8/jjB+n3/+Ofbt24fVq1fD2dk5336OPIZFzTE/jjCOlkyaNAkajQa7d++2OobyNoZPKhaaDiIgIACA5d0ShjbD7gFr+hr657e7Iz4+Pt9d1GXFsIso79YXa2Iu7PNQFMXYpyRmz56NefPm4bXXXsOaNWtM5lkzJpUqVYKrq6vFvpmZmUhMTDTLLzEx0eJ/kPHx8fD19S21X+AF5ViQ/MawqHFb+zddGpo0aYLmzZvjk08+sTqG8jyGBo/nV5DyPH6ZmZmIiorCiy++iOrVqyM2NhaxsbG4du0agNxrKMbGxiIpKclhx9CaHAtSnscxP87OzsYYrY2hPI3hk4yFpoNo1aoVAODo0aNm83788UcoioKnn34aAODv748aNWrgxx9/tNgXAFq2bGmy7vj4eNy4ccOk740bN3Dr1i2TvvZg2GWe96QTa2Iu7LMLDQ21eEFga8yePRtz5szB0KFDsX79eiiKYjK/cePG0Gq1+cYAPBoTlUqFFi1a4NSpU2b/4R0/fhwiYpafXq/H8ePHTfpmZGTg9OnTpTZ+heVYkPzGsKhxFzaGXl5eCAkJsSqfonjw4AH++OMPABVjDB+XN7+ClOfxe/DgAe7cuYPdu3ejXr16xqlz584AcrcE1qtXD+vXr3fYMbQmx4KU53HMT0ZGBm7evGmM2VHH8Ilmz1PeyVRhl/9p2bKleHp6mlwUNz4+Xjw9PaVbt24mfd955518r6Pp4+MjKSkpxvb/+7//K/CalIcPHy5hZrkKyi8tLc3s8hMiIidPnhSNRmN2CSJrYr59+7a4urpK69atLV5Hc+7cuSXISmTOnDkCQAYPHlzgJZn69esnKpVKTp8+bWwzXPutXr16Jtd+W7lyZb7XfnNycjK5Pt7Zs2cLvPbbZ599VqL8RIqWY3Z2tsXrbV6/fl0qV64sVapUMbm4uzVxZ2Vlib+/v9n1+06fPi0qlUpGjBhR7NzyXhYsrwMHDohKpTK5jIojjmFR83PU8cvKypKvvvrKbPrkk08EgDz//PPy1VdfycWLF0XEMcfQmhwddRwTExMtthu+y/JehsgRx/BJxkLTzj799FOZO3euzJ07V6pWrSo+Pj7G149f9/HIkSOi0WgkODhYli5dKkuXLpXg4GBxd3c3+QcnkvuPtlatWuLh4SEzZ86UtWvXSufOnQWArF+/3iyOXr16CQAZMWKErF+/XkaMGCEAZNCgQWWS36lTp6R69ery5ptvyuLFi2XNmjUyevRo0Wq14urqarHYtSbmjz/+WABI586dZe3atTJz5kxxd3eX+vXr53u9tqIw/CdWs2ZN2bRpk9kdLfbu3Wvse/nyZalUqZJUrVpVFi5caLybhVqtln/+858m683MzJSnn35anJycJCoqSmJiYox3s3jvvffM4hg7dqzxbhYxMTESFRUlTk5O0qlTpxLfzaKoOd67d098fHxk2LBhsmjRIlm3bp1MnDhRvL29Ra1Wy9atW0sU99atW03uSLJw4UKpWrWqVKtWzeQmBtYKDw+XNm3ayNSpU2XNmjWybNkyGTx4sDg7O4u3t7fJRaEdcQyLmp+jjl9+8rvGpCOOoTU5Ouo4jh8/Xtq2bStTp06V1atXy0cffSRdunQRANKmTRuT4rgijeGTgIWmnRluC2lp6tSpk1n///znP9K1a1dxd3cXDw8PefbZZ+XEiRMW133z5k0ZNGiQVKlSRbRarTRv3tzsVl4GDx48kOnTp0utWrVEo9FInTp15P333y/xRZSLml9CQoIMGjRIQkNDxdPTU5ycnCQoKEiGDBkiFy5cKJWYN2zYIE2aNBGtVit+fn7y2muvmdx+rzgMF5kv6hieP39eevfuLd7e3uLq6iodOnQwu2Wawb1792TMmDHi7+9v3Kq7YsUKk1/rBjk5OfLxxx9LSEiIaDQaCQgIkAkTJpSoiLY2x4yMDBkxYoQ89dRT4uPjI05OTlK9enXp27evyQWUSxL3rl27pE2bNuLq6io+Pj7St29fiY2NLVF+X375pfTs2VMCAwNFq9WKi4uLhIaGytixYy3e+tTRxrCo+Tnq+OUnv0JTxPHGMD+WcnTUcfzHP/4hzz77rAQEBIhWqxU3Nzdp2rSpzJ8/3+Lerooyhk8CRcTCXeWJiIiIiEqIJwMRERERkU2w0CQiIiIim2ChSUREREQ2wUKTiIiIiGyChSYRERER2QQLTSIiIiKyCRaaRERERGQTLDSJiIiIyCZYaBJRuaYoCoYNG2bvMIolPT0db7/9NmrWrAm1Wo3atWvbO6QyM3v2bCiKgqtXr9o7FCKyIxaaRE+gQ4cOQVEUKIqCmJgYi30URUGvXr3KOLKKZdGiRVixYgVeeeUVbNy4EcuWLSuwf3JyMubNm4dmzZrBx8cHHh4eqFOnDsLDw7F+/fqyCZqIqBQ52TsAIrKv2bNnY9CgQXB1dbV3KBXOvn370LhxY3z00UeF9k1JSUGrVq1w5coV9OvXD8OHD4dGo8GVK1fw73//G8uXL8fIkSPLIGoiotLDQpPoCdayZUv8/PPPWLZsGaZOnWrvcOxOp9MhMzMTbm5upbK+//3vf6hZs2aR+sbExODy5ctYtmwZxo0bZ3FdRESOhrvOiZ5gkZGRePrpp7Fo0SLcvXu30P75HS+5ceNGKIqCQ4cOGdsMx+idP38e48ePh7+/P9zc3NCtWzdcvHgRALB9+3a0aNECrq6uqF27NtatW5fve+/fvx9t27aFm5sbqlevjnHjxiEtLc2sX3JyMiZPnow//elP0Gq18PPzw6uvvoorV65YjHn//v2YO3cu6tatCxcXF2zdurXAzyAnJweLFi1Cw4YN4eLigipVqqBPnz745ZdfzNYdFxeH77//3niYwuzZs/Nd7+XLlwEA3bp1szi/evXqJq+PHz+OYcOGISQkBG5ubvD09ESHDh3wzTffmC07bNgwKIqCu3fvYtiwYfD19YWnpyfCw8ONBey6devQoEEDuLi4oH79+tixY4fJOq5evWrMYcuWLWjSpAlcXFxQs2ZNzJ49Gzk5OQV+bgZFHZ+MjAzMnj0boaGhcHNzg4+PDxo3boxJkyYV6X2IqHzgFk2iJ5iiKPjggw/Qo0cPzJ8/H0uWLCn19xg6dCg8PDwwbdo03LlzB4sXL8Zzzz2HuXPn4t1338Xo0aMxfPhw/PWvf8Ubb7yBhg0bomPHjibrOHnyJLZt24ZRo0ZhyJAhOHjwIKKjo3Hu3Dns27cPKlXub+bk5GS0b98e169fx/Dhw9GoUSMkJCTgk08+QZs2bfDzzz+jVq1aJut+5513kJ2djVGjRsHLywuhoaEF5jNw4EBs3boVPXr0wOjRo/G///0Pq1atQrt27XD48GE0b94czzzzDD777DNMmDABvr6+mD59OgCgSZMm+a63bt26AIANGzZg0aJFcHIq+L/nb775Br/++isiIyNRq1Yt3L17F5s2bUJERAQ2b96MAQMGmC3z/PPPIzAwEO+//z5iY2MRHR2NPn36ICIiAuvWrcOIESPg4uKC6Oho9OvXD5cuXUKdOnVM1rFz505cuXIFY8aMQfXq1bFz507MmTMH165dw4YNGwqM2ZrxGTNmDP72t79hyJAhiIqKQk5ODi5fvowDBw4U+B5EVM4IET1xDh48KADko48+EhGRHj16iFarlatXrxr7AJCePXuaLAdAhg4dara+DRs2CAA5ePCgsW3WrFkCQHr16iV6vd7Yvnz5cgEgnp6ecv36dWP77du3RavVyp///Gez9wQg33zzjUn722+/LQBky5YtJm0uLi5y+vRpk75Xr14VT09Pk9gNMYeEhMj9+/ctf1CP2bt3rwCQyMhIk5xOnz4tarVaOnbsaNK/Vq1a0qlTpyKt+48//pCgoCABIFWrVpW+ffvKBx98IIcPHxadTmfWPy0tzazt/v37EhISIg0aNDBpHzp0qACQv/zlLybtEyZMEAASFBQkycnJxvYzZ84IAJkyZYqxLS4uTgCISqWSEydOGNv1er2Eh4cLADl69Kix3TD+cXFxxjZrxqdSpUrywgsv5PNpEZGj4K5zIsKiRYuQlZWFGTNmlPq63377bSiKYnwdFhYGAOjduzeCgoKM7X5+fggNDTXuQs4rNDQU4eHhJm1TpkwBAOOuYhHB5s2b8cwzz6BGjRpITEw0Tu7u7mjbti327t1rtu7Ro0cX+ZhMw3tNnz7dJKemTZvipZdewr///W/cuXOnSOt6XKVKlXDixAlMnjwZ3t7e+PrrrzFlyhSEhYWhbt26ZrG7u7sbn6enp+Pu3btIT09H165dceHCBaSkpJi9x/jx401eG8ZiyJAh8PLyMrY3adIEXl5eFseiR48eaNGihfG1oih49913AcDibnsDa8fH29sb//3vf3Hu3Ll810lE5R8LTSJC8+bN8eqrr2Lz5s04e/Zsqa47ODjY5HWlSpUAwGyXrGGepWNFGzRoYNbm7+8PHx8f47F9d+7cwd27d7F37174+fmZTfv27cPvv/9utp6QkJAi5xIXFweVSmUxnkaNGhn7FJefnx8++OADXLp0CYmJidi1axcGDx6Ma9euoU+fPoiNjTX2vX37Nl5//XVUq1YN7u7u8PX1hZ+fH9asWQMASEpKMlu/rcaiYcOGAGB2nGVe1o7PsmXLcO/ePTRu3Bh169bFyJEjsWPHDuj1+nzfg4jKHx6jSUQAgHnz5mHbtm2YPHkyvv32W6uWLehEELVabVW7iFj13o8v1717d0yePLnIy5XWGealrUqVKujVqxd69eqFoKAgLFiwAF988QXee+89iAieffZZXLhwAePGjUPLli3h7e0NtVqNDRs24O9//7vFgqysxqKgdRV1fF5++WVcvXoVe/bswffff4/9+/fjr3/9K8LCwrB//35oNJpSi42IbIeFJhEByN2qNXr0aCxfvtzk7PG8KleujD/++MOsvaAtWaXhwoULZm0JCQlISkoybqXz8/ODj48PUlJS0L17d5vEERwcDL1ejwsXLpid2HP+/HkAlrcOllTbtm0BAPHx8QCAs2fP4syZM5g5cybmzJlj0tfWF3a3NBaG3B/fYppXccancuXKGDRoEAYNGgQRwZQpU/Dhhx9ix44d6N+/f/ESIKIyxV3nRGT03nvvwcvLy3jM3eNCQkJw9OhRpKenG9vu3btX6NnGJXXx4kX84x//MGlbtGgRABiP3VSpVBg4cCCOHz+Obdu2WVzP7du3SxSH4b0WLlxosrXv3Llz2LlzJzp27Ag/P79irfvo0aMWd3cDMOZu2EVt2AL5+BbHc+fOFXicZGnYt28fTp48aXwtIvjwww8BwOw42rysGR+dTmf2WSiKgubNmwOAxR87RFQ+cYsmERn5+vpi0qRJ+Z4UNHbsWAwaNAhdu3bF4MGDkZSUhJiYGNSqVcumFxRv3LgxBg0ahFGjRqFevXo4ePAgtm3bhk6dOuGVV14x9ps/fz6OHDmCyMhIREZGom3bttBoNLh27Rr27NmDp59+Ghs3bix2HD169EBkZCS++OIL3Lt3D7169TJe3shwWaDi2rx5MzZs2ICePXuidevWqFKlCu7evYs9e/bg4MGDaNiwIYYPHw4g9zjJRo0a4cMPP0R6ejpCQ0Nx6dIlrF27Fo0bN8aJEyeKHUdhmjZtiq5du2LMmDHw9/fHjh07sH//fgwePBjt2rUrcNmijk9qair8/f3Ru3dvNG/eHFWrVkVcXBxWr16NSpUq4aWXXrJZfkRUulhoEpGJqKgofPLJJ0hISDCbN3DgQNy6dQsrV65EVFQUgoODMXPmTKhUKhw7dsxmMbVo0QJLlizB9OnTsWbNGnh5eWHs2LFYsGCB8RqaQO6ZykeOHMHixYuxdetW7NixA05OTggMDETHjh1L5RaOmzdvRosWLbBx40ZMnDgR7u7u6NSpE+bOnYvGjRsXe71vvvkmfHx8cPDgQSxZsgSJiYnQarX405/+hFmzZiEqKsp4prlarcbu3bvxzjvvYNOmTbh//z6eeuopbNq0CWfOnLFpodm7d2+EhoZi4cKFuHjxIqpWrYoZM2YU6YoFRR0fNzc3jB8/Ht999x3279+PtLQ0Y+E5depUBAQE2Cw/IipdipTm0d5ERFQhXb16FXXq1MGsWbMKvMMREVFePEaTiIiIiGyChSYRERER2QQLTSIiIiKyCR6jSUREREQ2wS2aRERERGQTLDSJiIiIyCZYaBIRERGRTbDQJCIiIiKbYKFJRERERDbBQpOIiIiIbIKFJhERERHZBAtNIiIiIrIJFppEREREZBP/D2WhCaIGDu2YAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(n_samples, RF_time, color='r', label='Random Forest')  \n",
    "plt.plot(n_samples, RF_time, color='r', linestyle='-', linewidth=1)\n",
    "plt.scatter(n_samples, SVM_time, color='b', label='Support Vector Machine')\n",
    "plt.plot(n_samples, SVM_time, color='b', linestyle='-', linewidth=1)\n",
    "plt.scatter(n_samples, LR_time, color='g', label='Linear Regression')\n",
    "plt.plot(n_samples, LR_time, color='g', linestyle='-', linewidth=1)\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Training Time')\n",
    "plt.title('Number of Samples vs. Trainingn Time for Each Algorithm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n_samples = np.linspace(1000,5000,5,dtype=int)\n",
    "\n",
    "timer_lin = []\n",
    "timer_RF = []\n",
    "timer_SVR = []\n",
    "\n",
    "for n_sample in n_samples:\n",
    "    X = np.random.rand(n_sample)\n",
    "    y = true_fun(X) + np.random.randn(n_sample) * 0.1\n",
    "    \n",
    "    # add your code below\n",
    "\n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        reg = LinearRegression()\n",
    "        start_time = time.time()\n",
    "        reg.fit(X[:, np.newaxis],y)\n",
    "        end_time = time.time()    \n",
    "        times.append(end_time-start_time)\n",
    "    timer_lin.append(np.mean(times))\n",
    "\n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        reg = SVR(gamma = 1, C = 1)\n",
    "        start_time = time.time()\n",
    "        reg.fit(X[:, np.newaxis],y)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time-start_time)\n",
    "    timer_SVR.append(np.mean(times))\n",
    "    \n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        reg = RandomForestRegressor(n_estimators=10,max_depth=3)\n",
    "        start_time = time.time()\n",
    "        reg.fit(X[:, np.newaxis],y)\n",
    "        end_time = time.time()  \n",
    "        times.append(end_time-start_time)\n",
    "    timer_RF.append(np.mean(times))\n",
    "\n",
    "# prepare the plot below:\n",
    "plt.plot(n_samples,timer_lin,'o',label='lin reg')\n",
    "plt.plot(n_samples,timer_RF,'o',label='RF')\n",
    "plt.plot(n_samples,timer_SVR,'o',label='SVR')\n",
    "plt.xlabel('n_samples')\n",
    "plt.ylabel('runtime')\n",
    "plt.ylim([0,0.1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004866838455200195, 0.0035638809204101562, 0.003554105758666992, 0.003086090087890625, 0.002998828887939453]\n",
      "[0.000308990478515625, 0.00024390220642089844, 0.00024509429931640625, 0.0001709461212158203, 0.00017023086547851562]\n",
      "[0.003225088119506836, 0.00022602081298828125, 0.0002048015594482422, 0.00016427040100097656, 0.0001468658447265625]\n"
     ]
    }
   ],
   "source": [
    "print(RF_time)\n",
    "print(SVM_time)\n",
    "print(LR_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|so so |constant|yes|max_features,  max_depth| no|so so|\n",
    "| random forest classification \t|so so |step-like, difficult to tell|yes|max_features,  max_depth| no|so so|\n",
    "| SVM rbf regression               \t|<font color='red'>no</font>|<font color='red'>non-linear extrapolation</font>|<font color='red'>yes</font>|<font color='red'>C, gamma</font>|<font color='red'>yes</font>|<font color='red'>so so</font>|\n",
    "| SVM rbf classification           \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1, probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1, probability=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# create the data\n",
    "X,y = make_moons(noise=0.2, random_state=1,n_samples=200)\n",
    "# set the hyperparameters\n",
    "clf = SVC(gamma = 1, C = 1, probability=True)\n",
    "# fit the model\n",
    "clf.fit(X,y)\n",
    "# predict new data\n",
    "#y_new = clf.predict(X_new)\n",
    "# predict probabilities\n",
    "#y_new = clf.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer or\n",
      " |  other :ref:`kernel_approximation`.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Must be non-negative. Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features\n",
      " |      - if float, must be non-negative.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, note that\n",
      " |      internally, one-vs-one ('ovo') is always used as a multi-class strategy\n",
      " |      to train models; an ovr matrix is only constructed from the ovo matrix.\n",
      " |      The parameter is ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes * (n_classes - 1) // 2,)\n",
      " |      Number of iterations run by the optimization routine to fit the model.\n",
      " |      The shape of this attribute depends on the number of models optimized\n",
      " |      which in turn depends on the number of classes.\n",
      " |  \n",
      " |      .. versionadded:: 1.1\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n",
      " |      Machines and Comparisons to Regularized Likelihood Methods\"\n",
      " |      <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.svm._classes.SVC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVC\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.svm._classes.SVC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVC\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluate the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  probA_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  probB_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  unused_param = 'nu'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e91ae237924d9895a8a5e096a758a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='gamma', options=(0.001, 0.1, 10.0, 1000.0, 100000.0), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982eed3a93d541f8b0990136ca55758f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorbar': {'title': {'text': 'predicted probability'}},\n",
       "              'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n",
       "                             [0.2, 'rgb(214,96,77)'], [0.3, 'rgb(244,165,130)'],\n",
       "                             [0.4, 'rgb(253,219,199)'], [0.5, 'rgb(247,247,247)'],\n",
       "                             [0.6, 'rgb(209,229,240)'], [0.7, 'rgb(146,197,222)'],\n",
       "                             [0.8, 'rgb(67,147,195)'], [0.9, 'rgb(33,102,172)'],\n",
       "                             [1.0, 'rgb(5,48,97)']],\n",
       "              'contours': {'end': 1, 'size': 0.05, 'start': 0},\n",
       "              'type': 'contour',\n",
       "              'uid': '9207fe02-b988-41f0-8372-4d9df032d8d4',\n",
       "              'x': array([-1.64483117, -1.62483117, -1.60483117, ...,  2.75516883,  2.77516883,\n",
       "                           2.79516883]),\n",
       "              'y': array([-1.44154690e+00, -1.42154690e+00, -1.40154690e+00, -1.38154690e+00,\n",
       "                          -1.36154690e+00, -1.34154690e+00, -1.32154690e+00, -1.30154690e+00,\n",
       "                          -1.28154690e+00, -1.26154690e+00, -1.24154690e+00, -1.22154690e+00,\n",
       "                          -1.20154690e+00, -1.18154690e+00, -1.16154690e+00, -1.14154690e+00,\n",
       "                          -1.12154690e+00, -1.10154690e+00, -1.08154690e+00, -1.06154690e+00,\n",
       "                          -1.04154690e+00, -1.02154690e+00, -1.00154690e+00, -9.81546901e-01,\n",
       "                          -9.61546901e-01, -9.41546901e-01, -9.21546901e-01, -9.01546901e-01,\n",
       "                          -8.81546901e-01, -8.61546901e-01, -8.41546901e-01, -8.21546901e-01,\n",
       "                          -8.01546901e-01, -7.81546901e-01, -7.61546901e-01, -7.41546901e-01,\n",
       "                          -7.21546901e-01, -7.01546901e-01, -6.81546901e-01, -6.61546901e-01,\n",
       "                          -6.41546901e-01, -6.21546901e-01, -6.01546901e-01, -5.81546901e-01,\n",
       "                          -5.61546901e-01, -5.41546901e-01, -5.21546901e-01, -5.01546901e-01,\n",
       "                          -4.81546901e-01, -4.61546901e-01, -4.41546901e-01, -4.21546901e-01,\n",
       "                          -4.01546901e-01, -3.81546901e-01, -3.61546901e-01, -3.41546901e-01,\n",
       "                          -3.21546901e-01, -3.01546901e-01, -2.81546901e-01, -2.61546901e-01,\n",
       "                          -2.41546901e-01, -2.21546901e-01, -2.01546901e-01, -1.81546901e-01,\n",
       "                          -1.61546901e-01, -1.41546901e-01, -1.21546901e-01, -1.01546901e-01,\n",
       "                          -8.15469010e-02, -6.15469010e-02, -4.15469010e-02, -2.15469010e-02,\n",
       "                          -1.54690100e-03,  1.84530990e-02,  3.84530990e-02,  5.84530990e-02,\n",
       "                           7.84530990e-02,  9.84530990e-02,  1.18453099e-01,  1.38453099e-01,\n",
       "                           1.58453099e-01,  1.78453099e-01,  1.98453099e-01,  2.18453099e-01,\n",
       "                           2.38453099e-01,  2.58453099e-01,  2.78453099e-01,  2.98453099e-01,\n",
       "                           3.18453099e-01,  3.38453099e-01,  3.58453099e-01,  3.78453099e-01,\n",
       "                           3.98453099e-01,  4.18453099e-01,  4.38453099e-01,  4.58453099e-01,\n",
       "                           4.78453099e-01,  4.98453099e-01,  5.18453099e-01,  5.38453099e-01,\n",
       "                           5.58453099e-01,  5.78453099e-01,  5.98453099e-01,  6.18453099e-01,\n",
       "                           6.38453099e-01,  6.58453099e-01,  6.78453099e-01,  6.98453099e-01,\n",
       "                           7.18453099e-01,  7.38453099e-01,  7.58453099e-01,  7.78453099e-01,\n",
       "                           7.98453099e-01,  8.18453099e-01,  8.38453099e-01,  8.58453099e-01,\n",
       "                           8.78453099e-01,  8.98453099e-01,  9.18453099e-01,  9.38453099e-01,\n",
       "                           9.58453099e-01,  9.78453099e-01,  9.98453099e-01,  1.01845310e+00,\n",
       "                           1.03845310e+00,  1.05845310e+00,  1.07845310e+00,  1.09845310e+00,\n",
       "                           1.11845310e+00,  1.13845310e+00,  1.15845310e+00,  1.17845310e+00,\n",
       "                           1.19845310e+00,  1.21845310e+00,  1.23845310e+00,  1.25845310e+00,\n",
       "                           1.27845310e+00,  1.29845310e+00,  1.31845310e+00,  1.33845310e+00,\n",
       "                           1.35845310e+00,  1.37845310e+00,  1.39845310e+00,  1.41845310e+00,\n",
       "                           1.43845310e+00,  1.45845310e+00,  1.47845310e+00,  1.49845310e+00,\n",
       "                           1.51845310e+00,  1.53845310e+00,  1.55845310e+00,  1.57845310e+00,\n",
       "                           1.59845310e+00,  1.61845310e+00,  1.63845310e+00,  1.65845310e+00,\n",
       "                           1.67845310e+00,  1.69845310e+00,  1.71845310e+00,  1.73845310e+00,\n",
       "                           1.75845310e+00,  1.77845310e+00,  1.79845310e+00,  1.81845310e+00,\n",
       "                           1.83845310e+00,  1.85845310e+00,  1.87845310e+00]),\n",
       "              'z': array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          ...,\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]])},\n",
       "             {'marker': {'color': array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "                                         0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "                                         1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "                                         1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "                                         1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "                                         0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "                                         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "                                         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "                                         1, 1, 0, 1, 1, 0, 1, 0]),\n",
       "                         'colorscale': [[0, 'rgb(255,0,0)'], [1, 'rgb(0,0,255)']],\n",
       "                         'line': {'width': 1},\n",
       "                         'size': 8},\n",
       "              'mode': 'markers',\n",
       "              'type': 'scatter',\n",
       "              'uid': '79bd7f5a-a525-4617-844b-ab8fdbdfcfd9',\n",
       "              'x': array([-0.31410929,  0.39443922,  0.48606504, -0.12805768,  1.73330291,\n",
       "                           2.08500896, -1.08258853,  1.46899598,  0.54077095,  2.04624573,\n",
       "                           1.26754011,  0.84766004,  1.12118285, -0.78670168,  0.00903277,\n",
       "                           0.44164301,  1.43162307,  0.42529121,  0.47635606, -0.21866384,\n",
       "                          -0.08003084,  0.89546191,  0.22021464, -0.86869386,  0.720033  ,\n",
       "                           1.13779598,  0.8517701 ,  0.78598197,  1.9446092 ,  0.57102512,\n",
       "                          -0.0874615 ,  1.36354658,  2.01180011,  1.74821345,  2.02576178,\n",
       "                          -1.01470657,  1.66026241, -0.95942153, -0.69886079,  1.69148155,\n",
       "                           0.1386857 , -0.08753717,  2.30359131,  0.89058213, -0.18985218,\n",
       "                           0.87929191, -0.18902626,  0.62843809,  1.98598879,  0.42815849,\n",
       "                          -0.76592918, -0.1766055 , -0.16502413,  0.09064031,  0.58215419,\n",
       "                           1.59947816,  1.46796344,  0.07718396,  2.05560682,  0.45951857,\n",
       "                           0.14430234, -0.46286897, -0.75771806,  0.31091269,  0.44194998,\n",
       "                           0.95163996,  0.4400647 ,  0.087738  , -0.19010962, -0.91944812,\n",
       "                          -0.04820292, -0.77905887,  1.82882388,  1.24333486,  1.85387971,\n",
       "                          -0.04940048,  0.8753758 , -0.12773072, -0.97433768, -0.04547499,\n",
       "                           1.30029351, -1.14483117, -1.00043214,  0.53227789,  2.18759633,\n",
       "                           1.18059461, -0.60654542,  0.28976789,  2.0755619 ,  0.36715992,\n",
       "                          -0.70800052,  0.50273757,  1.65490162,  1.84352533,  1.30164148,\n",
       "                           0.22470731,  1.94238198,  2.03105931,  0.82243733,  1.85498244,\n",
       "                          -0.85944022,  0.48924579, -1.09621553,  1.09430083,  0.9242366 ,\n",
       "                          -0.59077915, -0.78977567,  0.95483132,  0.90948993, -0.11689905,\n",
       "                           1.23484548,  1.38018566, -0.57539165, -0.22204826, -0.37269637,\n",
       "                           1.51305089, -1.05739763,  0.3571857 , -0.12866277, -0.10547563,\n",
       "                          -0.53502926, -0.91608495,  0.9249523 ,  1.25270494,  0.95080015,\n",
       "                          -0.84234887,  1.53095717,  0.78535597,  1.59884341,  0.99957283,\n",
       "                           0.64464005, -1.0699057 ,  2.00213519, -0.40614721,  0.33469936,\n",
       "                           0.65214022,  0.03407413,  0.96458548,  1.6415562 , -0.02042865,\n",
       "                           0.91079629,  0.51978855, -0.08485074,  2.01666972, -0.19347125,\n",
       "                           1.00515377,  0.35275976,  1.31814843,  0.18031667, -0.10900477,\n",
       "                          -0.02504993,  0.74639483, -0.70470324,  0.18864587,  0.77469984,\n",
       "                           1.12402685,  1.86928319, -0.04793449,  0.96031217,  0.39875679,\n",
       "                           1.73646864,  0.44796085,  0.53978437, -0.10049249,  1.733278  ,\n",
       "                           1.19167168, -0.05156596,  0.26728811,  1.04684185, -0.23701974,\n",
       "                           0.80800707, -0.08867949, -0.7399108 ,  1.35458806,  2.1841648 ,\n",
       "                           0.85739515, -0.723131  , -0.73175367, -0.79048783, -0.16666084,\n",
       "                           0.94541406,  1.09982239,  1.1253117 ,  0.61537428,  0.95447778,\n",
       "                          -0.14118295,  0.85190312,  1.41971143,  0.65454195,  0.57056522,\n",
       "                          -0.8452877 ,  0.33104374,  0.61072908,  1.81211192, -0.55011263,\n",
       "                           0.59224252,  0.75936198, -0.97647202,  0.98687934,  0.3016817 ]),\n",
       "              'y': array([ 8.95676502e-01,  1.30271685e+00,  9.76101642e-01,  2.80754689e-01,\n",
       "                           1.66286038e-01,  4.83073987e-01,  2.47423182e-01,  1.01815788e-01,\n",
       "                           8.57912687e-01, -3.95794592e-01, -1.39296564e-01,  5.79894859e-01,\n",
       "                          -8.49468200e-02,  5.48867708e-01,  1.65797662e-01, -3.23969818e-01,\n",
       "                          -6.09361126e-01,  8.62038970e-01, -3.02042473e-01,  1.39728522e+00,\n",
       "                           1.05710297e+00,  4.46290153e-01,  1.01588641e+00, -1.12110147e-01,\n",
       "                           8.55213463e-01, -1.02457679e-01,  8.67682891e-01,  7.94216700e-01,\n",
       "                           4.59400469e-01,  7.56741666e-01,  9.20982998e-01, -1.64729837e-01,\n",
       "                           4.72726656e-01,  3.73867195e-02, -1.23232491e-01, -3.04171205e-01,\n",
       "                          -2.04263083e-01,  1.13052981e+00,  1.01221924e+00, -7.09509758e-02,\n",
       "                           1.31825405e-01,  3.07844103e-01,  3.04118060e-02,  4.77480270e-01,\n",
       "                           1.04646340e+00,  8.11853040e-01,  2.41093668e-01,  1.04966761e+00,\n",
       "                           1.86882595e-01, -1.07540976e-01, -2.10770022e-01, -3.46502525e-01,\n",
       "                          -3.76075277e-01,  6.92055325e-01,  8.53930735e-01,  2.84801371e-02,\n",
       "                          -2.15304911e-01,  3.57049546e-01,  6.38006337e-01, -6.04515343e-01,\n",
       "                           2.46243758e-01,  1.11798900e+00,  9.65635921e-01,  1.26746270e+00,\n",
       "                           4.22991878e-01,  3.13781170e-02, -3.52662177e-01,  4.91608299e-01,\n",
       "                           1.04758959e+00,  7.76299277e-01,  7.10105796e-01,  4.08723519e-01,\n",
       "                           8.97416399e-02, -4.93166179e-01, -3.66669160e-01, -5.52977376e-02,\n",
       "                           5.93118901e-01,  1.04503159e-01, -1.29355939e-03, -1.08716725e-01,\n",
       "                          -5.25859404e-02,  3.62101610e-01,  6.84687315e-01, -1.22552202e-01,\n",
       "                           2.71883094e-01,  5.97562281e-01,  6.06191800e-01, -1.73247735e-01,\n",
       "                          -1.41934849e-01,  8.72540820e-01, -5.56155777e-02,  9.17276323e-01,\n",
       "                           8.54102820e-02, -8.43174348e-02, -5.64113827e-01,  6.27124515e-01,\n",
       "                           1.07722614e-01,  4.42084952e-01, -6.51429811e-01, -4.02356158e-01,\n",
       "                           6.76901169e-01,  6.26934448e-01,  4.40131467e-01, -5.72951934e-01,\n",
       "                           2.76547398e-01,  1.12835077e+00,  4.39880646e-01, -1.34719371e-01,\n",
       "                           1.48935910e-01,  9.39175504e-02,  1.03706366e-01, -3.32122026e-01,\n",
       "                           5.55939460e-01,  8.26443689e-01,  1.05542037e+00, -4.98012648e-01,\n",
       "                           6.27313630e-01,  1.10288121e-02,  4.48665676e-01,  8.98269904e-01,\n",
       "                           6.72548646e-01,  3.28530778e-02, -5.50122171e-01, -5.26482279e-01,\n",
       "                          -4.31831643e-01,  4.20378766e-01, -1.83055312e-01, -4.25805639e-01,\n",
       "                          -5.10323198e-01, -3.12246583e-02,  7.96693007e-01,  9.22300096e-02,\n",
       "                          -9.63987055e-03,  5.51468553e-01,  9.53790352e-03,  1.04250894e+00,\n",
       "                          -5.89005437e-02,  2.49179428e-01, -6.88284440e-01,  5.34667518e-01,\n",
       "                          -7.67328228e-01, -4.19835169e-01, -5.52648582e-02, -7.57917988e-02,\n",
       "                           8.27541934e-01,  2.76803239e-01,  6.61983680e-01, -4.42786128e-01,\n",
       "                          -1.27738317e-02,  4.63710978e-01,  7.47544687e-01,  7.48051104e-01,\n",
       "                           8.37130021e-01,  8.33279422e-01,  6.76723456e-01,  2.01105398e-01,\n",
       "                          -8.72580477e-02,  9.96844701e-01, -9.41546901e-01,  1.45153766e-02,\n",
       "                           1.92049493e-01,  5.85451365e-01, -8.76116454e-02,  2.13837813e-02,\n",
       "                          -5.86054148e-01,  3.95119944e-01,  9.61960204e-01,  9.98725154e-02,\n",
       "                           1.67763889e-01,  9.31751591e-01,  6.88423021e-01,  1.16445600e+00,\n",
       "                           1.02240319e+00,  3.53953319e-01,  3.26688594e-01, -6.16580586e-01,\n",
       "                           2.52639694e-01,  3.31220690e-02,  7.11549555e-01,  1.21050094e+00,\n",
       "                          -2.98959425e-01, -6.04284386e-01, -5.45748891e-01, -4.59946460e-01,\n",
       "                          -6.39418951e-01,  3.38253353e-01,  6.85005047e-01, -1.71769176e-02,\n",
       "                           9.55617397e-01, -2.93420674e-01,  7.63525878e-01, -5.69513908e-01,\n",
       "                          -5.43282867e-01,  4.00014876e-01,  7.37285482e-01, -6.30330997e-01,\n",
       "                          -1.59939504e-01,  9.08485666e-01, -5.29767648e-01,  6.73980692e-01])},\n",
       "             {'colorscale': [[0, 'rgb(0,0,0)'], [1, 'rgb(0,0,0)']],\n",
       "              'contours': {'coloring': 'lines', 'end': 0.5, 'showlabels': False, 'start': 0.5},\n",
       "              'line': {'width': 5},\n",
       "              'ncontours': 1,\n",
       "              'showscale': False,\n",
       "              'type': 'contour',\n",
       "              'uid': '376b0348-4f30-4d9d-ab2c-a56535c061e9',\n",
       "              'x': array([-1.64483117, -1.62483117, -1.60483117, ...,  2.75516883,  2.77516883,\n",
       "                           2.79516883]),\n",
       "              'y': array([-1.44154690e+00, -1.42154690e+00, -1.40154690e+00, -1.38154690e+00,\n",
       "                          -1.36154690e+00, -1.34154690e+00, -1.32154690e+00, -1.30154690e+00,\n",
       "                          -1.28154690e+00, -1.26154690e+00, -1.24154690e+00, -1.22154690e+00,\n",
       "                          -1.20154690e+00, -1.18154690e+00, -1.16154690e+00, -1.14154690e+00,\n",
       "                          -1.12154690e+00, -1.10154690e+00, -1.08154690e+00, -1.06154690e+00,\n",
       "                          -1.04154690e+00, -1.02154690e+00, -1.00154690e+00, -9.81546901e-01,\n",
       "                          -9.61546901e-01, -9.41546901e-01, -9.21546901e-01, -9.01546901e-01,\n",
       "                          -8.81546901e-01, -8.61546901e-01, -8.41546901e-01, -8.21546901e-01,\n",
       "                          -8.01546901e-01, -7.81546901e-01, -7.61546901e-01, -7.41546901e-01,\n",
       "                          -7.21546901e-01, -7.01546901e-01, -6.81546901e-01, -6.61546901e-01,\n",
       "                          -6.41546901e-01, -6.21546901e-01, -6.01546901e-01, -5.81546901e-01,\n",
       "                          -5.61546901e-01, -5.41546901e-01, -5.21546901e-01, -5.01546901e-01,\n",
       "                          -4.81546901e-01, -4.61546901e-01, -4.41546901e-01, -4.21546901e-01,\n",
       "                          -4.01546901e-01, -3.81546901e-01, -3.61546901e-01, -3.41546901e-01,\n",
       "                          -3.21546901e-01, -3.01546901e-01, -2.81546901e-01, -2.61546901e-01,\n",
       "                          -2.41546901e-01, -2.21546901e-01, -2.01546901e-01, -1.81546901e-01,\n",
       "                          -1.61546901e-01, -1.41546901e-01, -1.21546901e-01, -1.01546901e-01,\n",
       "                          -8.15469010e-02, -6.15469010e-02, -4.15469010e-02, -2.15469010e-02,\n",
       "                          -1.54690100e-03,  1.84530990e-02,  3.84530990e-02,  5.84530990e-02,\n",
       "                           7.84530990e-02,  9.84530990e-02,  1.18453099e-01,  1.38453099e-01,\n",
       "                           1.58453099e-01,  1.78453099e-01,  1.98453099e-01,  2.18453099e-01,\n",
       "                           2.38453099e-01,  2.58453099e-01,  2.78453099e-01,  2.98453099e-01,\n",
       "                           3.18453099e-01,  3.38453099e-01,  3.58453099e-01,  3.78453099e-01,\n",
       "                           3.98453099e-01,  4.18453099e-01,  4.38453099e-01,  4.58453099e-01,\n",
       "                           4.78453099e-01,  4.98453099e-01,  5.18453099e-01,  5.38453099e-01,\n",
       "                           5.58453099e-01,  5.78453099e-01,  5.98453099e-01,  6.18453099e-01,\n",
       "                           6.38453099e-01,  6.58453099e-01,  6.78453099e-01,  6.98453099e-01,\n",
       "                           7.18453099e-01,  7.38453099e-01,  7.58453099e-01,  7.78453099e-01,\n",
       "                           7.98453099e-01,  8.18453099e-01,  8.38453099e-01,  8.58453099e-01,\n",
       "                           8.78453099e-01,  8.98453099e-01,  9.18453099e-01,  9.38453099e-01,\n",
       "                           9.58453099e-01,  9.78453099e-01,  9.98453099e-01,  1.01845310e+00,\n",
       "                           1.03845310e+00,  1.05845310e+00,  1.07845310e+00,  1.09845310e+00,\n",
       "                           1.11845310e+00,  1.13845310e+00,  1.15845310e+00,  1.17845310e+00,\n",
       "                           1.19845310e+00,  1.21845310e+00,  1.23845310e+00,  1.25845310e+00,\n",
       "                           1.27845310e+00,  1.29845310e+00,  1.31845310e+00,  1.33845310e+00,\n",
       "                           1.35845310e+00,  1.37845310e+00,  1.39845310e+00,  1.41845310e+00,\n",
       "                           1.43845310e+00,  1.45845310e+00,  1.47845310e+00,  1.49845310e+00,\n",
       "                           1.51845310e+00,  1.53845310e+00,  1.55845310e+00,  1.57845310e+00,\n",
       "                           1.59845310e+00,  1.61845310e+00,  1.63845310e+00,  1.65845310e+00,\n",
       "                           1.67845310e+00,  1.69845310e+00,  1.71845310e+00,  1.73845310e+00,\n",
       "                           1.75845310e+00,  1.77845310e+00,  1.79845310e+00,  1.81845310e+00,\n",
       "                           1.83845310e+00,  1.85845310e+00,  1.87845310e+00]),\n",
       "              'z': array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          ...,\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "                          [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]])}],\n",
       "    'layout': {'autosize': False,\n",
       "               'font': {'family': 'arial, monospace', 'size': 13},\n",
       "               'height': 480,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'gamma = 0.001, C = 0.1', 'x': 0.41, 'xanchor': 'center', 'y': 0.9, 'yanchor': 'top'},\n",
       "               'width': 640,\n",
       "               'xaxis': {'title': {'text': 'feature 1'}},\n",
       "               'yaxis': {'title': {'text': 'feature 2'}}}\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize RandomForestClassifier\n",
    "ML_algo = SVC(probability=True)\n",
    "\n",
    "# SVC parameter grid\n",
    "hyperparameters = {\n",
    "    'gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5],\n",
    "    'C': [1e-1, 1e0, 1e1]\n",
    "}\n",
    "\n",
    "plot_clf_contour(hyperparameters, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|so so |constant|yes|max_features,  max_depth| no|so so|\n",
    "| random forest classification \t|so so |step-like, difficult to tell|yes|max_features,  max_depth| no|so so|\n",
    "| SVM rbf regression               \t|no|non-linear extrapolation|yes|C, gamma|yes|so so|\n",
    "| SVM rbf classification           \t|<font color='red'>no</font>|<font color='red'>50-50</font>|<font color='red'>yes</font>|<font color='red'>C, gamma</font>|<font color='red'>yes</font>|<font color='red'>so so </font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz 3\n",
    "Bias variance trade off\n",
    "\n",
    "Which gamma value gives the best trade off between high bias and high variance? Work through the steps to answer the question.\n",
    "\n",
    "- Use random_state = 42 where-ever necessary.\n",
    "- Split X, y into X_train, X_val, y_train, y_val such that 70% of the points are in train.\n",
    "- Fit SVC models with C = 1, and gamma = 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3 on the training set.\n",
    "- Measure the validation accuracy for each gamma.\n",
    "- Which gamma value gives the highest validation accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "(200,)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_state = 42\n",
    "X,y = make_moons(noise=0.2, random_state=42, n_samples=200)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=random_state) # train_size = 0.7\n",
    "\n",
    "C = 1\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "val_accuracy = []\n",
    "\n",
    "\n",
    "for g in gamma:\n",
    "    m = SVC(gamma = g, C = 1, probability=True)\n",
    "    m.fit(X_train, y_train)\n",
    "    val_pred = m.predict(X_val)\n",
    "    val_accuracy.append(accuracy_score(y_val, val_pred))\n",
    "\n",
    "best_gamma = gamma[np.argmax(val_accuracy)]\n",
    "print(best_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.4666666666666667\n",
      "0.01 0.8333333333333334\n",
      "0.1 0.85\n",
      "1.0 0.9666666666666667\n",
      "10.0 0.95\n",
      "100.0 0.8833333333333333\n",
      "1000.0 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = make_moons(noise=0.2, random_state=42,n_samples=200)\n",
    "\n",
    "X_train,X_val, y_train, y_val = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "\n",
    "for g in gamma:\n",
    "    # set the hyperparameters\n",
    "    clf = SVC(gamma = g, C = 1, probability=True)\n",
    "    # fit the model\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(g,accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mud card"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
