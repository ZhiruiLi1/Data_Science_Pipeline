{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mud card\n",
    "- **Can we do more examples like the spam baseline question? I was confused with the baseline answer. I want to be able to understand this \"neither\" way of thinking for more scenarios.**\n",
    "    - yep, we will have more examples\n",
    "    - generally speaking, you need to check how frequently each class label occurs in your dataset\n",
    "    - the fraction of points that belong to the most frequent class is your baseline\n",
    "    - e.g., if 90% of your email are fine, and 10% are spam, your baseline accuracy is 90%\n",
    "    - if you were to predict 'no spam' to each email, you would be correct 90% of the time\n",
    "    - so a classifier is good if it's accuracy is better than the baseline\n",
    "- **I was wondering what are some of the best practices that should be applied to Exploratory Data Analysis (especially for large datasets)?**\n",
    "    - we will cover a couple of things during the next two lectures\n",
    "    - summary stats for each column is a great way to start\n",
    "    - figures for each column\n",
    "    - create a correlation coefficient matrix\n",
    "    - ceheck how strongly each feature correlates with the target variable\n",
    "- **Is the model the same as the parameter?**\n",
    "    - nope, models have parameters\n",
    "- **Will you further explain the different packages that we will be importing and using to create these models?**\n",
    "    - yes, we cover pandas today and next Tuesday for example\n",
    "- **The muddiest part of this lecture was how to go about splitting a dataset and how to choose an evaluation metric.**\n",
    "    - we will spend a week on each of those topics\n",
    "- **\"The sampling, what difference between curly X and X is, and what is S?**\n",
    "    - curly X is the domain set so all possible values of your features. If a data point is described by let's say d features, it could be a set of d dimensional real numbers\n",
    "    - X is sampled from curly X\n",
    "    - S is your training set which contains feature vectors (x_i) and and a true target variable (y_i)\n",
    "    - Check out chapter 2 of [this book](https://bruknow.library.brown.edu/permalink/01BU_INST/9mvq88/alma991027787129706966) for more info\n",
    "- **How do we define a \"large\" dataset? How many observations?**\n",
    "    - there is no clear answer to these types of questions\n",
    "    - some people would consider more than 10k points large, others might consider a dataset with more than 10m points to be large\n",
    "- **How does a model determine the Y target variable value on the decision boundary?**\n",
    "    - it could be random choice, one could return the most frequently occuring label in the training set, there might be other reasonable approaches too\n",
    "- **Were we expected to understand the pipeline or was this just an overview that we will dive into later?**\n",
    "    - Yep, it was just an overview and we will dive into each step later\n",
    "- **If you could explain more on the bias-variance tradeoff that would be great!**\n",
    "    - we will revisit it a couple of times during the term\n",
    "- **How did you determine the Cs in the example?**\n",
    "    - we will cover this later too\n",
    "    - some hyperparameters need to be uniformly spaced in log, other hyperparameters are linearly spaced\n",
    "    - we will learn how to decide\n",
    "- **I didn't quite fully follow the process of how we get the best C score. Do we just feed the C into the classifier, which is part of the packages I assume, and then use that classifier to predict and then check the output?**\n",
    "    - yes but we tried 13 different values for C\n",
    "    - we need to decide which of them gave the best model\n",
    "- **I'm a bit confused about whether the generalization error is calculated from the train set or the test set?**\n",
    "    - test set, always the test set\n",
    "    - the only purpose of the test set is to calculate the generalization error\n",
    "- **The muddiest part was hyper parameters. Could you please elaborate on what they are?**\n",
    "    - we will spend two weeks on them around mid-October"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Exploratory data analysis in python, part 1 </center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The steps\n",
    "\n",
    "<span style=\"background-color: #FFFF00\">**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors</span>\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "**4. Choose an evaluation metric**: depends on the priorities of the stakeholders\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Pandas </center>\n",
    "\n",
    "- data are often distributed over multiple files/databases (e.g., csv and excel files, sql databases)\n",
    "- each file/database is read into a pandas dataframe\n",
    "- you often need to filter dataframes (select specific rows/columns based on index or condition)\n",
    "- pandas dataframes can be merged and appended"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some notes and advice\n",
    "\n",
    "- **ALWAYS READ THE HELP OF THE METHODS/FUNCTIONS YOU USE!**\n",
    "\n",
    "- stackoverflow is your friend, use it! https://stackoverflow.com/\n",
    "\n",
    "- you can also use generative AI (like github copilot, bard, or chatGPT's code interpreter) to help you fix bugs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Data transformations: pandas data frames </center>\n",
    "### By the end of this lecture, you will be able to\n",
    "   - read in csv, excel, and sql data into a pandas data frame\n",
    "   - filter rows in various ways\n",
    "   - select columns\n",
    "   - merge and append data frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - **read in csv, excel, and sql data into a pandas data frame**\n",
    "   -  <font color='LIGHTGRAY'>filter rows in various ways</font>\n",
    "   -  <font color='LIGHTGRAY'>select columns</font>\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass  fnlwgt    education  education-num  \\\n",
      "0       39          State-gov   77516    Bachelors             13   \n",
      "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
      "2       38            Private  215646      HS-grad              9   \n",
      "3       53            Private  234721         11th              7   \n",
      "4       28            Private  338409    Bachelors             13   \n",
      "...    ...                ...     ...          ...            ...   \n",
      "32556   27            Private  257302   Assoc-acdm             12   \n",
      "32557   40            Private  154374      HS-grad              9   \n",
      "32558   58            Private  151910      HS-grad              9   \n",
      "32559   22            Private  201490      HS-grad              9   \n",
      "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
      "\n",
      "            marital-status          occupation    relationship    race  \\\n",
      "0            Never-married        Adm-clerical   Not-in-family   White   \n",
      "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
      "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
      "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
      "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
      "...                    ...                 ...             ...     ...   \n",
      "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
      "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
      "32558              Widowed        Adm-clerical       Unmarried   White   \n",
      "32559        Never-married        Adm-clerical       Own-child   White   \n",
      "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
      "0         Male          2174             0              40   United-States   \n",
      "1         Male             0             0              13   United-States   \n",
      "2         Male             0             0              40   United-States   \n",
      "3         Male             0             0              40   United-States   \n",
      "4       Female             0             0              40            Cuba   \n",
      "...        ...           ...           ...             ...             ...   \n",
      "32556   Female             0             0              38   United-States   \n",
      "32557     Male             0             0              40   United-States   \n",
      "32558   Female             0             0              40   United-States   \n",
      "32559     Male             0             0              20   United-States   \n",
      "32560   Female         15024             0              40   United-States   \n",
      "\n",
      "      gross-income  \n",
      "0            <=50K  \n",
      "1            <=50K  \n",
      "2            <=50K  \n",
      "3            <=50K  \n",
      "4            <=50K  \n",
      "...            ...  \n",
      "32556        <=50K  \n",
      "32557         >50K  \n",
      "32558        <=50K  \n",
      "32559        <=50K  \n",
      "32560         >50K  \n",
      "\n",
      "[32561 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# how to read in a database into a dataframe and basic dataframe structure\n",
    "import pandas as pd\n",
    "\n",
    "# load data from a csv file\n",
    "df = pd.read_csv('data/adult_data.csv') # there are also pd.read_excel(), and pd.read_sql()\n",
    "\n",
    "print(df)\n",
    "#help(df.head)\n",
    "#print(df.head(10)) # by default, shows the first five rows but check help(df.head) to specify the number of rows to show\n",
    "# print(df.shape) # the shape of your dataframe (number of rows, number of columns)\n",
    "#print(df.shape[0]) # number of rows\n",
    "#print(df.shape[1]) # number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>gross-income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country gross-income  \n",
       "0          2174             0              40   United-States        <=50K  \n",
       "1             0             0              13   United-States        <=50K  \n",
       "2             0             0              40   United-States        <=50K  \n",
       "3             0             0              40   United-States        <=50K  \n",
       "4             0             0              40            Cuba        <=50K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Packages\n",
    "\n",
    "A package is a collection of classes and functions.\n",
    "- a dataframe (pd.DataFrame()) is a pandas class\n",
    "    - a class is the blueprint of how the data should be organized \n",
    "    - classes have methods which can perform operations on the data (e.g., .head(), .shape)\n",
    "- df is an object, an instance of the class.\n",
    "    - we put data into the class \n",
    "    - methods are attached to objects \n",
    "       - you cannot call pd.head(), you can only call df.head()\n",
    "- read_csv is a function\n",
    "    - functions are called from the package\n",
    "    - you cannot call df.read_csv, you can only call pd.read_csv()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DataFrame structure: both rows and columns are indexed!\n",
    "- index column, no name\n",
    "    - contains the row names\n",
    "    - by default, index is a range object from 0 to number of rows - 1 \n",
    "    - any column can be turned into an index, so indices can be non-number, and also non-unique. more on this later.\n",
    "- columns with column names on top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Always print your dataframe to check if it looks ok!\n",
    "\n",
    "### Most common reasons it might not look ok:\n",
    "\n",
    "   - the first row is not the column name\n",
    "        - there are rows above the column names that need to be skipped\n",
    "        - there is no column name but by default, pandas assumes the first row is the column name. as a result, \n",
    "          the values of the first row end up as column names.\n",
    "   - character encoding is off\n",
    "   - separator is not comma but some other charachter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols=None, squeeze: 'bool | None' = None, prefix: 'str | lib.NoDefault' = <no_default>, mangle_dupe_cols: 'bool' = True, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters=None, true_values=None, false_values=None, skipinitialspace: 'bool' = False, skiprows=None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values=None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, skip_blank_lines: 'bool' = True, parse_dates=None, infer_datetime_format: 'bool' = False, keep_date_col: 'bool' = False, date_parser=None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, error_bad_lines: 'bool | None' = None, warn_bad_lines: 'bool | None' = None, on_bad_lines=None, delim_whitespace: 'bool' = False, low_memory=True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions' = None) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, None, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "            Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
      "            the data.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "           Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    \n",
      "        .. deprecated:: 1.5.0\n",
      "            Not implemented, and a new argument to specify the pattern for the\n",
      "            names of duplicated columns will be added instead\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "    \n",
      "            Support for defaultdict was added. Specify a defaultdict as input where\n",
      "            the default determines the dtype of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "           ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "           This behavior was previously only the case for ``engine=\"python\"``.\n",
      "    \n",
      "        .. versionchanged:: 1.3.0\n",
      "    \n",
      "           ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "           influence on how encoding errors are handled.\n",
      "    \n",
      "    encoding_errors : str, optional, default \"strict\"\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, optional, default ``None``\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
      "        returned.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    warn_bad_lines : bool, optional, default ``None``\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "    \n",
      "            - 'error', raise an Exception when a bad line is encountered.\n",
      "            - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
      "            - 'skip', skip bad lines without raising or warning when they are encountered.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            - callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new list of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine=\"python\"``\n",
      "    \n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "        'legacy' for the original lower precision pandas converter, and\n",
      "        'round_trip' for the round-trip converter.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the help to find the solution\n",
    "help(pd.read_csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "How should we read in adult_test.csv properly? Identify and fix the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>gross-income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
       "0   25     Private  226802           11th              7        Never-married   \n",
       "1   38     Private   89814        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private  160323   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?  103497   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country gross-income  \n",
       "0             0              40   United-States       <=50K.  \n",
       "1             0              50   United-States       <=50K.  \n",
       "2             0              40   United-States        >50K.  \n",
       "3             0              40   United-States        >50K.  \n",
       "4             0              30   United-States       <=50K.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/adult_test.csv\", header=2) # skiprows = 2\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>read in csv, excel, and sql data into a pandas data frame</font>\n",
    "   -  **filter rows in various ways**\n",
    "   -  <font color='LIGHTGRAY'>select columns</font>\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to select rows?\n",
    "\n",
    "##### 1) Integer-based indexing, numpy arrays are indexed the same way.\n",
    "##### 2) Select rows based on the value of the index column\n",
    "##### 3) select rows based on column condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1) Integer-based indexing, numpy arrays are indexed the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# df.iloc[] - for more info, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer\n",
    "# iloc is how numpy arrays are indexed (non-standard python indexing)\n",
    "\n",
    "# [start:stop:step] -  general indexing format\n",
    "\n",
    "# start stop step are optional\n",
    "#print(df.iloc[:])\n",
    "#print(df.iloc[::])\n",
    "#print(df.iloc[::1])\n",
    "\n",
    "# select one row - 0-based indexing\n",
    "#print(df.iloc[3])\n",
    "\n",
    "# indexing from the end of the data frame\n",
    "#print(df.iloc[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "9   42            Private  159449   Bachelors             13   \n",
      "\n",
      "        marital-status        occupation relationship    race      sex  \\\n",
      "1   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
      "4   Married-civ-spouse    Prof-specialty         Wife   Black   Female   \n",
      "9   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country gross-income  \n",
      "1             0             0              13   United-States        <=50K  \n",
      "4             0             0              40            Cuba        <=50K  \n",
      "9          5178             0              40   United-States         >50K  \n"
     ]
    }
   ],
   "source": [
    "# select a slice - stop index not included\n",
    "#print(df.iloc[3:7])\n",
    "\n",
    "# select every second element of the slice - stop index not included\n",
    "#print(df.iloc[3:7:2])\n",
    "\n",
    "#print(df.iloc[3:7:-2]) # return empty dataframe\n",
    "#print(df.iloc[7:3:-2])#  return rows with indices 7 and 5. 3 is the stop so it is not included\n",
    "\n",
    "# can be used to reverse rows\n",
    "#print(df.iloc[::-1])\n",
    "\n",
    "# here is where indexing gets non-standard python\n",
    "# select the 2nd, 5th, and 10th rows\n",
    "print(df.iloc[[1,4,9]]) # such indexing doesn't work with lists but it works with numpy arrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### 2) Select rows based on the value of the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=32561, step=1)\n"
     ]
    }
   ],
   "source": [
    "# df.loc[] - for more info, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-label\n",
    "\n",
    "print(df.index) # the default index when reading in a file is a range index. In this case,\n",
    "                 # .loc and .iloc works ALMOST the same.\n",
    "# one difference:\n",
    "# print(df.loc[3:9:2]) # this selects the 4th, 6th, 8th, 10th rows - the stop element is included!\n",
    "\n",
    "#help(df.set_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    25\n",
      "2    28\n",
      "4    18\n",
      "6    29\n",
      "Name: age, dtype: int64\n",
      "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
      "0   25     Private  226802           11th              7        Never-married   \n",
      "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
      "4   18           ?  103497   Some-college             10        Never-married   \n",
      "\n",
      "           occupation relationship    race      sex  capital-gain  \\\n",
      "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
      "2     Protective-serv      Husband   White     Male             0   \n",
      "4                   ?    Own-child   White   Female             0   \n",
      "\n",
      "   capital-loss  hours-per-week  native-country gross-income  \n",
      "0             0              40   United-States       <=50K.  \n",
      "2             0              40   United-States        >50K.  \n",
      "4             0              30   United-States       <=50K.  \n"
     ]
    }
   ],
   "source": [
    "print(df2.loc[0:6:2, \"age\"])\n",
    "print(df2.iloc[0:6:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                               25\n",
       "workclass                    Private\n",
       "fnlwgt                        226802\n",
       "education                       11th\n",
       "education-num                      7\n",
       "marital-status         Never-married\n",
       "occupation         Machine-op-inspct\n",
       "relationship               Own-child\n",
       "race                           Black\n",
       "sex                             Male\n",
       "capital-gain                       0\n",
       "capital-loss                       0\n",
       "hours-per-week                    40\n",
       "native-country         United-States\n",
       "gross-income                  <=50K.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age     workclass  fnlwgt      education  education-num  \\\n",
      "age                                                            \n",
      "30    30     State-gov  141297      Bachelors             13   \n",
      "30    30   Federal-gov   59951   Some-college             10   \n",
      "30    30       Private  188146        HS-grad              9   \n",
      "30    30       Private   59496      Bachelors             13   \n",
      "30    30       Private   54334            9th              5   \n",
      "\n",
      "          marital-status          occupation    relationship  \\\n",
      "age                                                            \n",
      "30    Married-civ-spouse      Prof-specialty         Husband   \n",
      "30    Married-civ-spouse        Adm-clerical       Own-child   \n",
      "30    Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "30    Married-civ-spouse               Sales         Husband   \n",
      "30         Never-married               Sales   Not-in-family   \n",
      "\n",
      "                    race    sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "age                                                                           \n",
      "30    Asian-Pac-Islander   Male             0             0              40   \n",
      "30                 White   Male             0             0              40   \n",
      "30                 White   Male          5013             0              40   \n",
      "30                 White   Male          2407             0              40   \n",
      "30                 White   Male             0             0              40   \n",
      "\n",
      "     native-country gross-income  \n",
      "age                               \n",
      "30            India         >50K  \n",
      "30    United-States        <=50K  \n",
      "30    United-States        <=50K  \n",
      "30    United-States        <=50K  \n",
      "30    United-States        <=50K  \n"
     ]
    }
   ],
   "source": [
    "df_index_age = df.set_index('age',drop=False)\n",
    "\n",
    "#print(df_index_age.index)\n",
    "#print(df_index_age.head())\n",
    "\n",
    "print(df_index_age.loc[30].head()) # collect everyone with age 30 - the index is non-unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>gross-income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age          workclass  fnlwgt   education  education-num  \\\n",
       "age                                                              \n",
       "39    39          State-gov   77516   Bachelors             13   \n",
       "50    50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "38    38            Private  215646     HS-grad              9   \n",
       "53    53            Private  234721        11th              7   \n",
       "28    28            Private  338409   Bachelors             13   \n",
       "\n",
       "          marital-status          occupation    relationship    race      sex  \\\n",
       "age                                                                             \n",
       "39         Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "50    Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "38              Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "53    Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "28    Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "     capital-gain  capital-loss  hours-per-week  native-country gross-income  \n",
       "age                                                                           \n",
       "39           2174             0              40   United-States        <=50K  \n",
       "50              0             0              13   United-States        <=50K  \n",
       "38              0             0              40   United-States        <=50K  \n",
       "53              0             0              40   United-States        <=50K  \n",
       "28              0             0              40            Cuba        <=50K  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_age.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3) select rows based on column condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass  fnlwgt      education  education-num  \\\n",
      "222     90            Private   51744        HS-grad              9   \n",
      "1040    90            Private  137018        HS-grad              9   \n",
      "1935    90            Private  221832      Bachelors             13   \n",
      "2303    90            Private   52386   Some-college             10   \n",
      "2891    90            Private  171956   Some-college             10   \n",
      "4070    90            Private  313986           11th              7   \n",
      "4109    90                  ?  256514      Bachelors             13   \n",
      "5104    90            Private   52386   Some-college             10   \n",
      "5272    90            Private  141758            9th              5   \n",
      "5370    90          Local-gov  227796        Masters             14   \n",
      "5406    90            Private   51744        Masters             14   \n",
      "6232    90   Self-emp-not-inc  155981      Bachelors             13   \n",
      "6624    90            Private  313986           11th              7   \n",
      "8562    49            Private  122066        HS-grad              9   \n",
      "8806    90            Private   87372    Prof-school             15   \n",
      "8963    90                  ?   77053        HS-grad              9   \n",
      "8973    90            Private   46786      Bachelors             13   \n",
      "10210   90   Self-emp-not-inc  282095   Some-college             10   \n",
      "10545   90            Private  175491        HS-grad              9   \n",
      "11512   90            Private   87285        HS-grad              9   \n",
      "11731   90                  ?   39824        HS-grad              9   \n",
      "11996   90            Private   40388      Bachelors             13   \n",
      "12451   90                  ?  225063   Some-college             10   \n",
      "12529   65            Private  172510   Some-college             10   \n",
      "12975   90            Private  250832           10th              6   \n",
      "13928   81   Self-emp-not-inc  123959      Bachelors             13   \n",
      "14159   90          Local-gov  187749     Assoc-acdm             12   \n",
      "15259   60            Private  114263      Bachelors             13   \n",
      "15356   90            Private   90523        HS-grad              9   \n",
      "15892   90            Private   88991      Bachelors             13   \n",
      "17144   28   Self-emp-not-inc  183523        HS-grad              9   \n",
      "17735   26            Private  358975   Some-college             10   \n",
      "18277   90            Private  311184      Bachelors             13   \n",
      "18413   90            Private  313749      Bachelors             13   \n",
      "18725   90          Local-gov  153602        HS-grad              9   \n",
      "18832   90            Private  115306        Masters             14   \n",
      "18839   66   Self-emp-not-inc  174995     Assoc-acdm             12   \n",
      "19212   90            Private  139660   Some-college             10   \n",
      "19489   90            Private   84553        HS-grad              9   \n",
      "19747   90            Private  226968        7th-8th              4   \n",
      "20610   90            Private  206667        Masters             14   \n",
      "21371   30            Private  207668      Bachelors             13   \n",
      "22220   90            Private   52386      Bachelors             13   \n",
      "22658   54            Private  188186        HS-grad              9   \n",
      "23023   24            Private  117779      Bachelors             13   \n",
      "24043   90   Self-emp-not-inc   82628        HS-grad              9   \n",
      "24238   90                  ?  166343        1st-4th              2   \n",
      "25303   90                  ?  175444        7th-8th              4   \n",
      "27041   57       Self-emp-inc  258883        HS-grad              9   \n",
      "27750   55            Private  143266      Assoc-voc             11   \n",
      "28463   90        Federal-gov  195433        HS-grad              9   \n",
      "30346   47            Private  180277        HS-grad              9   \n",
      "31030   90            Private   47929        HS-grad              9   \n",
      "31696   90                  ?  313986        HS-grad              9   \n",
      "32277   90            Private  313749        HS-grad              9   \n",
      "32367   90          Local-gov  214594        7th-8th              4   \n",
      "\n",
      "            marital-status          occupation     relationship  \\\n",
      "222          Never-married       Other-service    Not-in-family   \n",
      "1040         Never-married       Other-service    Not-in-family   \n",
      "1935    Married-civ-spouse     Exec-managerial          Husband   \n",
      "2303         Never-married       Other-service    Not-in-family   \n",
      "2891             Separated        Adm-clerical        Own-child   \n",
      "4070         Never-married   Handlers-cleaners        Own-child   \n",
      "4109               Widowed                   ?   Other-relative   \n",
      "5104         Never-married       Other-service    Not-in-family   \n",
      "5272         Never-married        Adm-clerical    Not-in-family   \n",
      "5370    Married-civ-spouse     Exec-managerial          Husband   \n",
      "5406         Never-married     Exec-managerial    Not-in-family   \n",
      "6232    Married-civ-spouse      Prof-specialty          Husband   \n",
      "6624    Married-civ-spouse        Craft-repair          Husband   \n",
      "8562    Married-civ-spouse     Exec-managerial          Husband   \n",
      "8806    Married-civ-spouse      Prof-specialty          Husband   \n",
      "8963               Widowed                   ?    Not-in-family   \n",
      "8973    Married-civ-spouse               Sales          Husband   \n",
      "10210   Married-civ-spouse     Farming-fishing          Husband   \n",
      "10545   Married-civ-spouse        Craft-repair          Husband   \n",
      "11512        Never-married       Other-service        Own-child   \n",
      "11731              Widowed                   ?    Not-in-family   \n",
      "11996        Never-married     Exec-managerial    Not-in-family   \n",
      "12451        Never-married                   ?        Own-child   \n",
      "12529              Widowed      Prof-specialty    Not-in-family   \n",
      "12975   Married-civ-spouse     Exec-managerial          Husband   \n",
      "13928              Widowed      Prof-specialty    Not-in-family   \n",
      "14159   Married-civ-spouse        Adm-clerical          Husband   \n",
      "15259             Divorced     Exec-managerial    Not-in-family   \n",
      "15356              Widowed    Transport-moving        Unmarried   \n",
      "15892   Married-civ-spouse     Exec-managerial             Wife   \n",
      "17144   Married-civ-spouse        Craft-repair          Husband   \n",
      "17735        Never-married     Priv-house-serv    Not-in-family   \n",
      "18277   Married-civ-spouse               Sales          Husband   \n",
      "18413        Never-married      Prof-specialty        Own-child   \n",
      "18725   Married-civ-spouse       Other-service          Husband   \n",
      "18832        Never-married     Exec-managerial        Own-child   \n",
      "18839   Married-civ-spouse        Craft-repair          Husband   \n",
      "19212             Divorced               Sales        Unmarried   \n",
      "19489   Married-civ-spouse   Machine-op-inspct          Husband   \n",
      "19747   Married-civ-spouse   Machine-op-inspct          Husband   \n",
      "20610   Married-civ-spouse      Prof-specialty             Wife   \n",
      "21371        Never-married        Tech-support    Not-in-family   \n",
      "22220        Never-married      Prof-specialty    Not-in-family   \n",
      "22658        Never-married       Other-service   Other-relative   \n",
      "23023        Never-married      Prof-specialty    Not-in-family   \n",
      "24043        Never-married     Exec-managerial    Not-in-family   \n",
      "24238              Widowed                   ?    Not-in-family   \n",
      "25303            Separated                   ?    Not-in-family   \n",
      "27041   Married-civ-spouse    Transport-moving          Husband   \n",
      "27750   Married-civ-spouse        Craft-repair          Husband   \n",
      "28463   Married-civ-spouse        Craft-repair          Husband   \n",
      "30346   Married-civ-spouse        Adm-clerical             Wife   \n",
      "31030   Married-civ-spouse   Machine-op-inspct          Husband   \n",
      "31696   Married-civ-spouse                   ?          Husband   \n",
      "32277              Widowed        Adm-clerical        Unmarried   \n",
      "32367   Married-civ-spouse     Protective-serv          Husband   \n",
      "\n",
      "                      race      sex  capital-gain  capital-loss  \\\n",
      "222                  Black     Male             0          2206   \n",
      "1040                 White   Female             0             0   \n",
      "1935                 White     Male             0             0   \n",
      "2303    Asian-Pac-Islander     Male             0             0   \n",
      "2891                 White   Female             0             0   \n",
      "4070                 White     Male             0             0   \n",
      "4109                 White   Female           991             0   \n",
      "5104    Asian-Pac-Islander     Male             0             0   \n",
      "5272                 White   Female             0             0   \n",
      "5370                 White     Male         20051             0   \n",
      "5406                 Black     Male             0             0   \n",
      "6232                 White     Male         10566             0   \n",
      "6624                 White     Male             0             0   \n",
      "8562                 White     Male             0             0   \n",
      "8806                 White     Male         20051             0   \n",
      "8963                 White   Female             0          4356   \n",
      "8973                 White     Male          9386             0   \n",
      "10210                White     Male             0             0   \n",
      "10545                White     Male          9386             0   \n",
      "11512                White   Female             0             0   \n",
      "11731                White     Male           401             0   \n",
      "11996                White     Male             0             0   \n",
      "12451   Asian-Pac-Islander     Male             0             0   \n",
      "12529                White   Female          1848             0   \n",
      "12975                White     Male             0             0   \n",
      "13928                White   Female             0          1668   \n",
      "14159   Asian-Pac-Islander     Male             0             0   \n",
      "15259                White   Female             0             0   \n",
      "15356                White     Male             0             0   \n",
      "15892                White   Female             0             0   \n",
      "17144                White     Male             0             0   \n",
      "17735                White   Female             0             0   \n",
      "18277                White     Male             0             0   \n",
      "18413                White   Female             0             0   \n",
      "18725                White     Male          6767             0   \n",
      "18832                White   Female             0             0   \n",
      "18839                White     Male          2290             0   \n",
      "19212                Black   Female             0             0   \n",
      "19489                White     Male             0             0   \n",
      "19747                White     Male             0             0   \n",
      "20610                White   Female             0             0   \n",
      "21371                White     Male             0             0   \n",
      "22220   Asian-Pac-Islander     Male             0             0   \n",
      "22658                White   Female             0             0   \n",
      "23023                White     Male             0             0   \n",
      "24043                White     Male          2964             0   \n",
      "24238                Black   Female             0             0   \n",
      "25303                White   Female             0             0   \n",
      "27041                White     Male          5178             0   \n",
      "27750                White     Male             0             0   \n",
      "28463                White     Male             0             0   \n",
      "30346                White   Female             0             0   \n",
      "31030                White     Male             0             0   \n",
      "31696                White     Male             0             0   \n",
      "32277                White   Female             0             0   \n",
      "32367                White     Male          2653             0   \n",
      "\n",
      "       hours-per-week  native-country gross-income  \n",
      "222                40   United-States        <=50K  \n",
      "1040               40   United-States        <=50K  \n",
      "1935               45   United-States        <=50K  \n",
      "2303               35   United-States        <=50K  \n",
      "2891               40     Puerto-Rico        <=50K  \n",
      "4070               40   United-States        <=50K  \n",
      "4109               10   United-States        <=50K  \n",
      "5104               35   United-States        <=50K  \n",
      "5272               40   United-States        <=50K  \n",
      "5370               60   United-States         >50K  \n",
      "5406               50   United-States         >50K  \n",
      "6232               50   United-States        <=50K  \n",
      "6624               40   United-States        <=50K  \n",
      "8562               30         Hungary        <=50K  \n",
      "8806               72   United-States         >50K  \n",
      "8963               40   United-States        <=50K  \n",
      "8973               15   United-States         >50K  \n",
      "10210              40   United-States        <=50K  \n",
      "10545              50         Ecuador         >50K  \n",
      "11512              24   United-States        <=50K  \n",
      "11731               4   United-States        <=50K  \n",
      "11996              55   United-States        <=50K  \n",
      "12451              10           South        <=50K  \n",
      "12529              20         Hungary        <=50K  \n",
      "12975              40   United-States        <=50K  \n",
      "13928               3         Hungary        <=50K  \n",
      "14159              20     Philippines        <=50K  \n",
      "15259              40         Hungary         >50K  \n",
      "15356              99   United-States        <=50K  \n",
      "15892              40         England         >50K  \n",
      "17144              50         Hungary        <=50K  \n",
      "17735              50         Hungary        <=50K  \n",
      "18277              20               ?        <=50K  \n",
      "18413              10   United-States        <=50K  \n",
      "18725              40   United-States        <=50K  \n",
      "18832              40   United-States        <=50K  \n",
      "18839              30         Hungary        <=50K  \n",
      "19212              37   United-States        <=50K  \n",
      "19489              40   United-States        <=50K  \n",
      "19747              40   United-States        <=50K  \n",
      "20610              40   United-States         >50K  \n",
      "21371              60         Hungary        <=50K  \n",
      "22220              40   United-States        <=50K  \n",
      "22658              20         Hungary        <=50K  \n",
      "23023              10         Hungary        <=50K  \n",
      "24043              12   United-States        <=50K  \n",
      "24238              40   United-States        <=50K  \n",
      "25303              15   United-States        <=50K  \n",
      "27041              60         Hungary         >50K  \n",
      "27750              50         Hungary         >50K  \n",
      "28463              30   United-States        <=50K  \n",
      "30346              40         Hungary        <=50K  \n",
      "31030              40   United-States        <=50K  \n",
      "31696              40   United-States         >50K  \n",
      "32277              25   United-States        <=50K  \n",
      "32367              40   United-States        <=50K  \n"
     ]
    }
   ],
   "source": [
    "# one condition\n",
    "# print(df[df['age']==30].head())\n",
    "# here is the condition: it's a boolean series - series is basically a dataframe with one column\n",
    "# print(df['age']==30)\n",
    "\n",
    "# multiple conditions can be combined with & (and) | (or)\n",
    "#print(df[(df['age']>30)&(df['age']<35)].head())\n",
    "print(df[(df['age']==90)|(df['native-country']==' Hungary')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'gross-income'],\n",
      "      dtype='object')\n",
      "[' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df[\"education\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Exercise 2\n",
    "How many people in adult_data.csv work at least 60 hours a week and have a doctorate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df[\"hours-per-week\"] >= 60) & (df['education'] == ' Doctorate')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>read in csv, excel, and sql data into a pandas data frame</font>\n",
    "   -  <font color='LIGHTGRAY'>filter rows in various ways</font>\n",
    "   -  **select columns**\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               workclass       marital-status    relationship\n",
      "0              State-gov        Never-married   Not-in-family\n",
      "1       Self-emp-not-inc   Married-civ-spouse         Husband\n",
      "2                Private             Divorced   Not-in-family\n",
      "3                Private   Married-civ-spouse         Husband\n",
      "4                Private   Married-civ-spouse            Wife\n",
      "...                  ...                  ...             ...\n",
      "32556            Private   Married-civ-spouse            Wife\n",
      "32557            Private   Married-civ-spouse         Husband\n",
      "32558            Private              Widowed       Unmarried\n",
      "32559            Private        Never-married       Own-child\n",
      "32560       Self-emp-inc   Married-civ-spouse            Wife\n",
      "\n",
      "[32561 rows x 3 columns]\n",
      "       age  fnlwgt  education-num          occupation    race  capital-gain  \\\n",
      "0       39   77516             13        Adm-clerical   White          2174   \n",
      "1       50   83311             13     Exec-managerial   White             0   \n",
      "2       38  215646              9   Handlers-cleaners   White             0   \n",
      "3       53  234721              7   Handlers-cleaners   Black             0   \n",
      "4       28  338409             13      Prof-specialty   Black             0   \n",
      "...    ...     ...            ...                 ...     ...           ...   \n",
      "32556   27  257302             12        Tech-support   White             0   \n",
      "32557   40  154374              9   Machine-op-inspct   White             0   \n",
      "32558   58  151910              9        Adm-clerical   White             0   \n",
      "32559   22  201490              9        Adm-clerical   White             0   \n",
      "32560   52  287927              9     Exec-managerial   White         15024   \n",
      "\n",
      "       hours-per-week gross-income  \n",
      "0                  40        <=50K  \n",
      "1                  13        <=50K  \n",
      "2                  40        <=50K  \n",
      "3                  40        <=50K  \n",
      "4                  40        <=50K  \n",
      "...               ...          ...  \n",
      "32556              38        <=50K  \n",
      "32557              40         >50K  \n",
      "32558              40        <=50K  \n",
      "32559              20        <=50K  \n",
      "32560              40         >50K  \n",
      "\n",
      "[32561 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "columns =  df.columns\n",
    "#print(columns)\n",
    "\n",
    "# select columns by column name\n",
    "# print(df[['age','hours-per-week']])\n",
    "# print(columns[[1,5,7]])\n",
    "# print(df[columns[[1,5,7]]])\n",
    "\n",
    "# select columns by index using iloc\n",
    "#print(df.iloc[:,3])\n",
    "\n",
    "# select columns by index - not standard python indexing\n",
    "#print(df.iloc[:,[3,5,6]])\n",
    "\n",
    "# select columns by index -  standard python indexing\n",
    "print(df.iloc[:,::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Never-married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>Private</td>\n",
       "      <td>Widowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>Private</td>\n",
       "      <td>Never-married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               workclass       marital-status\n",
       "0              State-gov        Never-married\n",
       "1       Self-emp-not-inc   Married-civ-spouse\n",
       "2                Private             Divorced\n",
       "3                Private   Married-civ-spouse\n",
       "4                Private   Married-civ-spouse\n",
       "...                  ...                  ...\n",
       "32556            Private   Married-civ-spouse\n",
       "32557            Private   Married-civ-spouse\n",
       "32558            Private              Widowed\n",
       "32559            Private        Never-married\n",
       "32560       Self-emp-inc   Married-civ-spouse\n",
       "\n",
       "[32561 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[[1,5]]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>read in csv, excel, and sql data into a pandas data frame</font>\n",
    "   -  <font color='LIGHTGRAY'>filter rows in various ways</font>\n",
    "   -  <font color='LIGHTGRAY'>select columns</font>\n",
    "   -  **merge and append data frames**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to merge dataframes?\n",
    "\n",
    "Merge - info on data points are distributed in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  col1 col2\n",
      "0  ID1     5    y\n",
      "1  ID2     8    j\n",
      "2  ID3     2    w\n",
      "3  ID4     6    b\n",
      "4  ID5     0    a\n",
      "5  ID6     2    b\n",
      "6  ID7     5    t\n",
      "     ID  col3 col2\n",
      "0   ID2    12    q\n",
      "1   ID5    76    u\n",
      "2   ID6    34    e\n",
      "3  ID10    98    l\n",
      "4  ID11    65    p\n"
     ]
    }
   ],
   "source": [
    "# We have two datasets from two hospitals\n",
    "\n",
    "hospital1 = {'ID':['ID1','ID2','ID3','ID4','ID5','ID6','ID7'],'col1':[5,8,2,6,0,2,5],'col2':['y','j','w','b','a','b','t']}\n",
    "df1 = pd.DataFrame(data=hospital1)\n",
    "print(df1)\n",
    "\n",
    "hospital2 = {'ID':['ID2','ID5','ID6','ID10','ID11'],'col3':[12,76,34,98,65],'col2':['q','u','e','l','p']}\n",
    "df2 = pd.DataFrame(data=hospital2)\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  col1 col2_x  col3 col2_y\n",
      "0   ID1   5.0      y   NaN    NaN\n",
      "1   ID2   8.0      j  12.0      q\n",
      "2   ID3   2.0      w   NaN    NaN\n",
      "3   ID4   6.0      b   NaN    NaN\n",
      "4   ID5   0.0      a  76.0      u\n",
      "5   ID6   2.0      b  34.0      e\n",
      "6   ID7   5.0      t   NaN    NaN\n",
      "7  ID10   NaN    NaN  98.0      l\n",
      "8  ID11   NaN    NaN  65.0      p\n"
     ]
    }
   ],
   "source": [
    "# we are interested in only patients from hospital1\n",
    "# df_left = df1.merge(df2,how='left',on='ID') # IDs from the left dataframe (df1) are kept\n",
    "# print(df_left)\n",
    "\n",
    "# we are interested in only patients from hospital2\n",
    "#df_right = df1.merge(df2,how='right',on='ID') # IDs from the right dataframe (df2) are kept\n",
    "#print(df_right)\n",
    "\n",
    "# we are interested in patiens who were in both hospitals\n",
    "#df_inner = df1.merge(df2,how='inner',on='ID') # merging on IDs present in both dataframes\n",
    "#print(df_inner)\n",
    "\n",
    "# we are interested in all patients who visited at least one of the hospitals\n",
    "df_outer = df1.merge(df2,how='outer',on='ID')  # merging on IDs present in any dataframe\n",
    "print(df_outer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to append dataframes?\n",
    "\n",
    "Append - new data comes in over a period of time. E.g., one file per month/quarter/fiscal year etc.\n",
    "\n",
    "\n",
    "You want to combine these files into one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  col1 col2  col3\n",
      "0   ID1   5.0    y   NaN\n",
      "1   ID2   8.0    j   NaN\n",
      "2   ID3   2.0    w   NaN\n",
      "3   ID4   6.0    b   NaN\n",
      "4   ID5   0.0    a   NaN\n",
      "5   ID6   2.0    b   NaN\n",
      "6   ID7   5.0    t   NaN\n",
      "0   ID2   NaN    q  12.0\n",
      "1   ID5   NaN    u  76.0\n",
      "2   ID6   NaN    e  34.0\n",
      "3  ID10   NaN    l  98.0\n",
      "4  ID11   NaN    p  65.0\n",
      "      ID  col1 col2  col3\n",
      "0    ID1   5.0    y   NaN\n",
      "1    ID2   8.0    j   NaN\n",
      "2    ID3   2.0    w   NaN\n",
      "3    ID4   6.0    b   NaN\n",
      "4    ID5   0.0    a   NaN\n",
      "5    ID6   2.0    b   NaN\n",
      "6    ID7   5.0    t   NaN\n",
      "7    ID2   NaN    q  12.0\n",
      "8    ID5   NaN    u  76.0\n",
      "9    ID6   NaN    e  34.0\n",
      "10  ID10   NaN    l  98.0\n",
      "11  ID11   NaN    p  65.0\n"
     ]
    }
   ],
   "source": [
    "df_append = pd.concat([df1,df2]) # note that rows with ID2, ID5, and ID6  are duplicated! Indices are duplicated too.\n",
    "print(df_append)\n",
    "\n",
    "df_append2 = pd.concat([df1,df2],ignore_index=True) # note that rows with ID2, ID5, and ID6  are duplicated! \n",
    "print(df_append2)\n",
    "\n",
    "# d3 = {'ID':['ID23','ID94','ID56','ID17'],'col1':['rt','h','st','ne'],'col2':[23,86,23,78]}\n",
    "# df3 = pd.DataFrame(data=d3)\n",
    "# print(df3)\n",
    "\n",
    "# df_append = pd.concat([df1,df2,df3],ignore_index=True) # multiple dataframes can be appended\n",
    "# print(df_append)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data_1 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "\n",
    "raw_data_2 = {\n",
    "        'subject_id': ['6', '7', '8', '9', '10'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "\n",
    "raw_data_3 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "\n",
    "# Create three data frames from raw_data_1, 2, and 3.\n",
    "# Append the first two data frames and assign it to df_append.\n",
    "# Merge the third data frame with df_append such that only subject_ids from df_append are present. \n",
    "# Assign the new data frame to df_merge. \n",
    "# How many rows and columns do we have in df_merge?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id first_name last_name  test_id\n",
      "0          1       Alex  Anderson     51.0\n",
      "1          2        Amy  Ackerman     15.0\n",
      "2          3      Allen       Ali     15.0\n",
      "3          4      Alice      Aoni     61.0\n",
      "4          5     Ayoung   Atiches     16.0\n",
      "5          6      Billy    Bonder      NaN\n",
      "6          7      Brian     Black     14.0\n",
      "7          8       Bran   Balwner     15.0\n",
      "8          9      Bryce     Brice      1.0\n",
      "9         10      Betty    Btisan     61.0\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(raw_data_1)\n",
    "df2 = pd.DataFrame(raw_data_2)\n",
    "df3 = pd.DataFrame(raw_data_3)\n",
    "df_append = pd.concat((df1, df2), ignore_index=True) # normally use [df1, df2]\n",
    "df_merge = df_append.merge(df3, how=\"left\", on='subject_id')\n",
    "print(df_merge)\n",
    "print(df_merge.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Always check that the resulting dataframe is what you wanted to end up with!\n",
    "- small toy datasets are ideal to test your code.\n",
    "\n",
    "### If you need to do a more complicated dataframe operation, check out pd.concat()!\n",
    "\n",
    "### We will learn how to add/delete/modify columns later when we learn about feature engineering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### By now, you are able to\n",
    "   - read in csv, excel, and sql data into a pandas data frame\n",
    "   - filter rows in various ways\n",
    "   - select columns\n",
    "   - merge and append data frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
